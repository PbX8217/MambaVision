2025/12/11 00:24:08 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.25 (main, Nov  3 2025, 22:33:05) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 940171453
    GPU 0: NVIDIA A800 80GB PCIe
    CUDA_HOME: /usr/local/cuda
    NVCC: Cuda compilation tools, release 12.1, V12.1.105
    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
    PyTorch: 2.1.2+cu121
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.2+cu121
    OpenCV: 4.11.0
    MMEngine: 0.10.3

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 940171453
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2025/12/11 00:24:09 - mmengine - INFO - Config:
accum_steps = 1
auto_scale_lr = dict(base_batch_size=16, enable=False)
backend_args = None
batch_size_per_gpu = 16
data_root = './coco/'
dataset_type = 'CocoDataset'
default_hooks = dict(
    checkpoint=dict(interval=1, type='CheckpointHook'),
    logger=dict(interval=50, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='DetVisualizationHook'))
default_scope = 'mmdet'
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)
log_root = './log_dirs/mamba_vision_s_object_detection'
max_epochs = 12
model = dict(
    backbone=dict(
        depth=50,
        depths=(
            3,
            3,
            7,
            5,
        ),
        dim=96,
        drop_path_rate=0.3,
        frozen_stages=1,
        in_dim=64,
        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),
        layer_scale=None,
        mlp_ratio=4,
        norm_cfg=dict(requires_grad=True, type='BN'),
        norm_eval=True,
        norm_layer='ln2d',
        num_heads=(
            2,
            4,
            8,
            16,
        ),
        num_stages=4,
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        pretrained='../models/mamba_vision_S-224/model_best.pth.tar',
        style='pytorch',
        type='MM_mamba_vision',
        window_size=(
            8,
            8,
            112,
            56,
        )),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_mask=True,
        pad_size_divisor=32,
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='DetDataPreprocessor'),
    neck=dict(
        in_channels=[
            96,
            192,
            384,
            768,
        ],
        num_outs=5,
        out_channels=256,
        type='FPN'),
    roi_head=dict(
        bbox_head=dict(
            bbox_coder=dict(
                target_means=[
                    0.0,
                    0.0,
                    0.0,
                    0.0,
                ],
                target_stds=[
                    0.1,
                    0.1,
                    0.2,
                    0.2,
                ],
                type='DeltaXYWHBBoxCoder'),
            conv_out_channels=256,
            fc_out_channels=1024,
            in_channels=256,
            loss_bbox=dict(loss_weight=10.0, type='GIoULoss'),
            loss_cls=dict(
                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
            norm_cfg=dict(requires_grad=True, type='SyncBN'),
            num_classes=80,
            num_shared_convs=4,
            num_shared_fcs=1,
            reg_class_agnostic=False,
            reg_decoded_bbox=True,
            roi_feat_size=7,
            type='ConvFCBBoxHead'),
        bbox_roi_extractor=dict(
            featmap_strides=[
                4,
                8,
                16,
                32,
            ],
            out_channels=256,
            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),
            type='SingleRoIExtractor'),
        mask_head=dict(
            conv_out_channels=256,
            in_channels=256,
            loss_mask=dict(
                loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),
            num_classes=80,
            num_convs=4,
            type='FCNMaskHead'),
        mask_roi_extractor=dict(
            featmap_strides=[
                4,
                8,
                16,
                32,
            ],
            out_channels=256,
            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),
            type='SingleRoIExtractor'),
        type='StandardRoIHead'),
    rpn_head=dict(
        anchor_generator=dict(
            ratios=[
                0.5,
                1.0,
                2.0,
            ],
            scales=[
                8,
            ],
            strides=[
                4,
                8,
                16,
                32,
                64,
            ],
            type='AnchorGenerator'),
        bbox_coder=dict(
            target_means=[
                0.0,
                0.0,
                0.0,
                0.0,
            ],
            target_stds=[
                1.0,
                1.0,
                1.0,
                1.0,
            ],
            type='DeltaXYWHBBoxCoder'),
        feat_channels=256,
        in_channels=256,
        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),
        loss_cls=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),
        type='RPNHead'),
    test_cfg=dict(
        rcnn=dict(
            mask_thr_binary=0.5,
            max_per_img=100,
            nms=dict(iou_threshold=0.5, type='nms'),
            score_thr=0.05),
        rpn=dict(
            max_per_img=1000,
            min_bbox_size=0,
            nms=dict(iou_threshold=0.7, type='nms'),
            nms_pre=1000)),
    train_cfg=dict(
        rcnn=dict(
            assigner=dict(
                ignore_iof_thr=-1,
                match_low_quality=True,
                min_pos_iou=0.5,
                neg_iou_thr=0.5,
                pos_iou_thr=0.5,
                type='MaxIoUAssigner'),
            debug=False,
            mask_size=28,
            pos_weight=-1,
            sampler=dict(
                add_gt_as_proposals=True,
                neg_pos_ub=-1,
                num=512,
                pos_fraction=0.25,
                type='RandomSampler')),
        rpn=dict(
            allowed_border=-1,
            assigner=dict(
                ignore_iof_thr=-1,
                match_low_quality=True,
                min_pos_iou=0.3,
                neg_iou_thr=0.3,
                pos_iou_thr=0.7,
                type='MaxIoUAssigner'),
            debug=False,
            pos_weight=-1,
            sampler=dict(
                add_gt_as_proposals=False,
                neg_pos_ub=-1,
                num=256,
                pos_fraction=0.5,
                type='RandomSampler')),
        rpn_proposal=dict(
            max_per_img=1000,
            min_bbox_size=0,
            nms=dict(iou_threshold=0.7, type='nms'),
            nms_pre=2000)),
    type='MaskRCNN')
num_gpus = 1
optim_wrapper = dict(
    accumulative_counts=1,
    loss_scale='dynamic',
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ), lr=0.0001, type='AdamW', weight_decay=0.05),
    paramwise_cfg=dict(custom_keys=dict(norm=dict(decay_mult=0.0))),
    type='AmpOptimWrapper')
param_scheduler = [
    dict(
        begin=0, by_epoch=False, end=1000, start_factor=0.001,
        type='LinearLR'),
    dict(
        begin=0,
        by_epoch=True,
        end=12,
        gamma=0.1,
        milestones=[
            8,
            11,
        ],
        type='MultiStepLR'),
]
resume = False
run_name = 'mamba_vision_s_object_detection'
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=16,
    dataset=dict(
        ann_file='annotations/instances_val2017.json',
        backend_args=None,
        data_prefix=dict(img='val2017/'),
        data_root='./coco/',
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                1333,
                800,
            ), type='Resize'),
            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackDetInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=16,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    ann_file='./coco/annotations/instances_val2017.json',
    backend_args=None,
    format_only=False,
    metric=[
        'bbox',
        'segm',
    ],
    type='CocoMetric')
test_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        1333,
        800,
    ), type='Resize'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(
        meta_keys=(
            'img_id',
            'img_path',
            'ori_shape',
            'img_shape',
            'scale_factor',
        ),
        type='PackDetInputs'),
]
total_batch_size = 16
train_cfg = dict(max_epochs=12, type='EpochBasedTrainLoop', val_interval=1)
train_dataloader = dict(
    batch_sampler=dict(type='AspectRatioBatchSampler'),
    batch_size=16,
    dataset=dict(
        ann_file='annotations/instances_train2017.json',
        backend_args=None,
        data_prefix=dict(img='train2017/'),
        data_root='./coco/',
        filter_cfg=dict(filter_empty_gt=True, min_size=32),
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
            dict(prob=0.5, type='RandomFlip'),
            dict(
                transforms=[
                    [
                        dict(
                            keep_ratio=True,
                            scales=[
                                (
                                    480,
                                    1333,
                                ),
                                (
                                    512,
                                    1333,
                                ),
                                (
                                    544,
                                    1333,
                                ),
                                (
                                    576,
                                    1333,
                                ),
                                (
                                    608,
                                    1333,
                                ),
                                (
                                    640,
                                    1333,
                                ),
                                (
                                    672,
                                    1333,
                                ),
                                (
                                    704,
                                    1333,
                                ),
                                (
                                    736,
                                    1333,
                                ),
                                (
                                    768,
                                    1333,
                                ),
                                (
                                    800,
                                    1333,
                                ),
                            ],
                            type='RandomChoiceResize'),
                    ],
                    [
                        dict(
                            keep_ratio=True,
                            scales=[
                                (
                                    400,
                                    1333,
                                ),
                                (
                                    500,
                                    1333,
                                ),
                                (
                                    600,
                                    1333,
                                ),
                            ],
                            type='RandomChoiceResize'),
                        dict(
                            allow_negative_crop=True,
                            crop_size=(
                                384,
                                600,
                            ),
                            crop_type='absolute_range',
                            type='RandomCrop'),
                        dict(
                            keep_ratio=True,
                            scales=[
                                (
                                    480,
                                    1333,
                                ),
                                (
                                    512,
                                    1333,
                                ),
                                (
                                    544,
                                    1333,
                                ),
                                (
                                    576,
                                    1333,
                                ),
                                (
                                    608,
                                    1333,
                                ),
                                (
                                    640,
                                    1333,
                                ),
                                (
                                    672,
                                    1333,
                                ),
                                (
                                    704,
                                    1333,
                                ),
                                (
                                    736,
                                    1333,
                                ),
                                (
                                    768,
                                    1333,
                                ),
                                (
                                    800,
                                    1333,
                                ),
                            ],
                            type='RandomChoiceResize'),
                    ],
                ],
                type='RandomChoice'),
            dict(type='PackDetInputs'),
        ],
        type='CocoDataset'),
    num_workers=16,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=True, type='DefaultSampler'))
train_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(prob=0.5, type='RandomFlip'),
    dict(
        transforms=[
            [
                dict(
                    keep_ratio=True,
                    scales=[
                        (
                            480,
                            1333,
                        ),
                        (
                            512,
                            1333,
                        ),
                        (
                            544,
                            1333,
                        ),
                        (
                            576,
                            1333,
                        ),
                        (
                            608,
                            1333,
                        ),
                        (
                            640,
                            1333,
                        ),
                        (
                            672,
                            1333,
                        ),
                        (
                            704,
                            1333,
                        ),
                        (
                            736,
                            1333,
                        ),
                        (
                            768,
                            1333,
                        ),
                        (
                            800,
                            1333,
                        ),
                    ],
                    type='RandomChoiceResize'),
            ],
            [
                dict(
                    keep_ratio=True,
                    scales=[
                        (
                            400,
                            1333,
                        ),
                        (
                            500,
                            1333,
                        ),
                        (
                            600,
                            1333,
                        ),
                    ],
                    type='RandomChoiceResize'),
                dict(
                    allow_negative_crop=True,
                    crop_size=(
                        384,
                        600,
                    ),
                    crop_type='absolute_range',
                    type='RandomCrop'),
                dict(
                    keep_ratio=True,
                    scales=[
                        (
                            480,
                            1333,
                        ),
                        (
                            512,
                            1333,
                        ),
                        (
                            544,
                            1333,
                        ),
                        (
                            576,
                            1333,
                        ),
                        (
                            608,
                            1333,
                        ),
                        (
                            640,
                            1333,
                        ),
                        (
                            672,
                            1333,
                        ),
                        (
                            704,
                            1333,
                        ),
                        (
                            736,
                            1333,
                        ),
                        (
                            768,
                            1333,
                        ),
                        (
                            800,
                            1333,
                        ),
                    ],
                    type='RandomChoiceResize'),
            ],
        ],
        type='RandomChoice'),
    dict(type='PackDetInputs'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=16,
    dataset=dict(
        ann_file='annotations/instances_val2017.json',
        backend_args=None,
        data_prefix=dict(img='val2017/'),
        data_root='./coco/',
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                1333,
                800,
            ), type='Resize'),
            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackDetInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=16,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    ann_file='./coco/annotations/instances_val2017.json',
    backend_args=None,
    format_only=False,
    metric=[
        'bbox',
        'segm',
    ],
    type='CocoMetric')
vis_backends = [
    dict(
        save_dir='./log_dirs/mamba_vision_s_object_detection',
        type='TensorboardVisBackend'),
    dict(
        save_dir='./log_dirs/mamba_vision_s_object_detection',
        type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='DetLocalVisualizer',
    vis_backends=[
        dict(
            save_dir='./log_dirs/mamba_vision_s_object_detection',
            type='TensorboardVisBackend'),
        dict(
            save_dir='./log_dirs/mamba_vision_s_object_detection',
            type='LocalVisBackend'),
    ])
work_dir = './work_dirs/mamba_vision_s_object_detection'

2025/12/11 00:24:14 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2025/12/11 00:24:14 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm1.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm1.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm1.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm1.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm1.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm1.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm2.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm2.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm2.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm2.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm2.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm2.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.1.norm1.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.1.norm1.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.1.norm1.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.1.norm1.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.1.norm1.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.1.norm1.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.1.norm2.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.1.norm2.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.1.norm2.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.1.norm2.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.1.norm2.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.1.norm2.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.2.norm1.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.2.norm1.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.2.norm1.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.2.norm1.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.2.norm1.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.2.norm1.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.2.norm2.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.2.norm2.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.2.norm2.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.2.norm2.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.2.norm2.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.2.norm2.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm1.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm1.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm1.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm1.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm1.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm1.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm2.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm2.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm2.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm2.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm2.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm2.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm1.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm1.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm1.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm1.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm1.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm1.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm2.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm2.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm2.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm2.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm2.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm2.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm1.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm1.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm1.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm1.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm1.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm1.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm2.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm2.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm2.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm2.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm2.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm2.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm1.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm1.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm1.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm1.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm1.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm1.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm2.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm2.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm2.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm2.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm2.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm2.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm1.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm1.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm1.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm1.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm1.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm1.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm2.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm2.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm2.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm2.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm2.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm2.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm1.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm1.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm1.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm1.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm1.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm1.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm2.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm2.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm2.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm2.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm2.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm2.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm1.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm1.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm1.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm1.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm1.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm1.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm2.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm2.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm2.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm2.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm2.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm2.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm1.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm1.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm1.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm1.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm1.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm1.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm2.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm2.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm2.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm2.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm2.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm2.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm1.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm1.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm1.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm1.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm1.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm1.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm2.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm2.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm2.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm2.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm2.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm2.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm1.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm1.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm1.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm1.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm1.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm1.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm2.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm2.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm2.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm2.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm2.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm2.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm1.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm1.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm1.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm1.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm1.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm1.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm2.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm2.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm2.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm2.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm2.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm2.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm1.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm1.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm1.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm1.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm1.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm1.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm2.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm2.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm2.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm2.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm2.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm2.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm1.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm1.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm1.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm1.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm1.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm1.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm2.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm2.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm2.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm2.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm2.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm2.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm1.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm1.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm1.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm1.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm1.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm1.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm2.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm2.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm2.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm2.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm2.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm2.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.4.norm1.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.4.norm1.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.4.norm1.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.4.norm1.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.4.norm1.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.4.norm1.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.4.norm2.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.4.norm2.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.4.norm2.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.4.norm2.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.4.norm2.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.4.norm2.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm0.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm0.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm0.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm0.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm0.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm0.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm1.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm1.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm1.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm1.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm1.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm1.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm2.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm2.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm2.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm2.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm2.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm2.bias:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm3.weight:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm3.weight:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm3.weight:decay_mult=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm3.bias:lr=0.0001
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm3.bias:weight_decay=0.0
2025/12/11 00:24:54 - mmengine - INFO - paramwise_options -- backbone.outnorm3.bias:decay_mult=0.0
Name of parameter - Initialization information

backbone.patch_embed.conv_down.0.weight - torch.Size([64, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.patch_embed.conv_down.1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.patch_embed.conv_down.1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.patch_embed.conv_down.3.weight - torch.Size([96, 64, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.patch_embed.conv_down.4.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.patch_embed.conv_down.4.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.conv1.weight - torch.Size([96, 96, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.conv1.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.norm1.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.norm1.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.conv2.weight - torch.Size([96, 96, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.conv2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.norm2.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.norm2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.1.conv1.weight - torch.Size([96, 96, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.1.conv1.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.1.norm1.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.1.norm1.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.1.conv2.weight - torch.Size([96, 96, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.1.conv2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.1.norm2.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.1.norm2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.2.conv1.weight - torch.Size([96, 96, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.2.conv1.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.2.norm1.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.2.norm1.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.2.conv2.weight - torch.Size([96, 96, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.2.conv2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.2.norm2.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.2.norm2.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.downsample.reduction.0.weight - torch.Size([192, 96, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.conv1.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.conv1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.conv2.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.conv2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.norm2.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.norm2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.conv1.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.conv1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.conv2.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.conv2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.norm2.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.norm2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.conv1.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.conv1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.conv2.weight - torch.Size([192, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.conv2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.norm2.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.norm2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.downsample.reduction.0.weight - torch.Size([384, 192, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mixer.A_log - torch.Size([192, 8]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mixer.D - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mixer.in_proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mixer.x_proj.weight - torch.Size([40, 192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mixer.dt_proj.weight - torch.Size([192, 24]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mixer.dt_proj.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mixer.out_proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mixer.conv1d_x.weight - torch.Size([192, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mixer.conv1d_z.weight - torch.Size([192, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mlp.fc1.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mlp.fc1.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mlp.fc2.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mlp.fc2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mixer.A_log - torch.Size([192, 8]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mixer.D - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mixer.in_proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mixer.x_proj.weight - torch.Size([40, 192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mixer.dt_proj.weight - torch.Size([192, 24]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mixer.dt_proj.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mixer.out_proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mixer.conv1d_x.weight - torch.Size([192, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mixer.conv1d_z.weight - torch.Size([192, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mlp.fc1.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mlp.fc1.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mlp.fc2.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mlp.fc2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mixer.A_log - torch.Size([192, 8]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mixer.D - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mixer.in_proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mixer.x_proj.weight - torch.Size([40, 192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mixer.dt_proj.weight - torch.Size([192, 24]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mixer.dt_proj.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mixer.out_proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mixer.conv1d_x.weight - torch.Size([192, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mixer.conv1d_z.weight - torch.Size([192, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mlp.fc1.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mlp.fc1.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mlp.fc2.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mlp.fc2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mixer.A_log - torch.Size([192, 8]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mixer.D - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mixer.in_proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mixer.x_proj.weight - torch.Size([40, 192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mixer.dt_proj.weight - torch.Size([192, 24]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mixer.dt_proj.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mixer.out_proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mixer.conv1d_x.weight - torch.Size([192, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mixer.conv1d_z.weight - torch.Size([192, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mlp.fc1.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mlp.fc1.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mlp.fc2.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mlp.fc2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mixer.qkv.weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mixer.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mixer.proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mixer.proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mlp.fc1.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mlp.fc1.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mlp.fc2.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mlp.fc2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mixer.qkv.weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mixer.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mixer.proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mixer.proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mlp.fc1.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mlp.fc1.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mlp.fc2.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mlp.fc2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mixer.qkv.weight - torch.Size([1152, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mixer.qkv.bias - torch.Size([1152]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mixer.proj.weight - torch.Size([384, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mixer.proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mlp.fc1.weight - torch.Size([1536, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mlp.fc1.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mlp.fc2.weight - torch.Size([384, 1536]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mlp.fc2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.downsample.reduction.0.weight - torch.Size([768, 384, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mixer.A_log - torch.Size([384, 8]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mixer.D - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mixer.in_proj.weight - torch.Size([768, 768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mixer.x_proj.weight - torch.Size([64, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mixer.dt_proj.weight - torch.Size([384, 48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mixer.dt_proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mixer.out_proj.weight - torch.Size([768, 768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mixer.conv1d_x.weight - torch.Size([384, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mixer.conv1d_z.weight - torch.Size([384, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mlp.fc1.weight - torch.Size([3072, 768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mlp.fc1.bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mlp.fc2.weight - torch.Size([768, 3072]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mlp.fc2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mixer.A_log - torch.Size([384, 8]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mixer.D - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mixer.in_proj.weight - torch.Size([768, 768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mixer.x_proj.weight - torch.Size([64, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mixer.dt_proj.weight - torch.Size([384, 48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mixer.dt_proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mixer.out_proj.weight - torch.Size([768, 768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mixer.conv1d_x.weight - torch.Size([384, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mixer.conv1d_z.weight - torch.Size([384, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mlp.fc1.weight - torch.Size([3072, 768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mlp.fc1.bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mlp.fc2.weight - torch.Size([768, 3072]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mlp.fc2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mixer.A_log - torch.Size([384, 8]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mixer.D - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mixer.in_proj.weight - torch.Size([768, 768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mixer.x_proj.weight - torch.Size([64, 384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mixer.dt_proj.weight - torch.Size([384, 48]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mixer.dt_proj.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mixer.out_proj.weight - torch.Size([768, 768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mixer.conv1d_x.weight - torch.Size([384, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mixer.conv1d_z.weight - torch.Size([384, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mlp.fc1.weight - torch.Size([3072, 768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mlp.fc1.bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mlp.fc2.weight - torch.Size([768, 3072]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mlp.fc2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mixer.qkv.weight - torch.Size([2304, 768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mixer.qkv.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mixer.proj.weight - torch.Size([768, 768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mixer.proj.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mlp.fc1.weight - torch.Size([3072, 768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mlp.fc1.bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mlp.fc2.weight - torch.Size([768, 3072]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mlp.fc2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.4.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.4.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.4.mixer.qkv.weight - torch.Size([2304, 768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.4.mixer.qkv.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.4.mixer.proj.weight - torch.Size([768, 768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.4.mixer.proj.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.4.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.4.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.4.mlp.fc1.weight - torch.Size([3072, 768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.4.mlp.fc1.bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.4.mlp.fc2.weight - torch.Size([768, 3072]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.4.mlp.fc2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm0.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm0.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.lateral_convs.0.conv.weight - torch.Size([256, 96, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.lateral_convs.1.conv.weight - torch.Size([256, 192, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.lateral_convs.2.conv.weight - torch.Size([256, 384, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.lateral_convs.3.conv.weight - torch.Size([256, 768, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_conv.bias - torch.Size([256]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.bias - torch.Size([3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.weight - torch.Size([12, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.bias - torch.Size([12]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.fc_cls.weight - torch.Size([81, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.fc_cls.bias - torch.Size([81]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.fc_reg.weight - torch.Size([320, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.fc_reg.bias - torch.Size([320]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.shared_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.mask_head.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.mask_head.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.mask_head.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.mask_head.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.mask_head.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.mask_head.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.mask_head.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.mask_head.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.mask_head.upsample.weight - torch.Size([256, 256, 2, 2]): 
Initialized by user-defined `init_weights` in FCNMaskHead  

roi_head.mask_head.upsample.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in FCNMaskHead  

roi_head.mask_head.conv_logits.weight - torch.Size([80, 256, 1, 1]): 
Initialized by user-defined `init_weights` in FCNMaskHead  

roi_head.mask_head.conv_logits.bias - torch.Size([80]): 
Initialized by user-defined `init_weights` in FCNMaskHead  
2025/12/11 00:24:58 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2025/12/11 00:24:58 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2025/12/11 00:24:58 - mmengine - INFO - Checkpoints will be saved to /home/chenhao/MambaVision/work_dirs/mamba_vision_s_object_detection.
2025/12/11 00:26:59 - mmengine - INFO - Epoch(train)  [1][  50/7330]  base_lr: 5.0000e-06 lr: 5.0000e-06  eta: 2 days, 10:48:34  time: 2.4083  data_time: 0.1029  memory: 41424  loss: 5.0433  loss_rpn_cls: 0.6767  loss_rpn_bbox: 0.0862  loss_cls: 3.3593  acc: 98.2788  loss_bbox: 0.0098  loss_mask: 0.9114
2025/12/11 00:29:04 - mmengine - INFO - Epoch(train)  [1][ 100/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2 days, 11:58:07  time: 2.5060  data_time: 0.0052  memory: 42467  loss: 2.0414  loss_rpn_cls: 0.5268  loss_rpn_bbox: 0.0846  loss_cls: 0.5573  acc: 94.9829  loss_bbox: 0.1129  loss_mask: 0.7599
2025/12/11 00:30:57 - mmengine - INFO - Epoch(train)  [1][ 150/7330]  base_lr: 1.5000e-05 lr: 1.5000e-05  eta: 2 days, 10:19:42  time: 2.2596  data_time: 0.0053  memory: 42265  loss: 1.6650  loss_rpn_cls: 0.2957  loss_rpn_bbox: 0.0872  loss_cls: 0.3956  acc: 93.6279  loss_bbox: 0.1739  loss_mask: 0.7126
2025/12/11 00:33:15 - mmengine - INFO - Epoch(train)  [1][ 200/7330]  base_lr: 2.0000e-05 lr: 2.0000e-05  eta: 2 days, 12:35:10  time: 2.7673  data_time: 0.0050  memory: 42267  loss: 1.6069  loss_rpn_cls: 0.2402  loss_rpn_bbox: 0.0829  loss_cls: 0.3958  acc: 93.5181  loss_bbox: 0.1927  loss_mask: 0.6953
2025/12/11 00:34:55 - mmengine - INFO - Epoch(train)  [1][ 250/7330]  base_lr: 2.5000e-05 lr: 2.5000e-05  eta: 2 days, 10:09:00  time: 1.9924  data_time: 0.0061  memory: 41844  loss: 1.5720  loss_rpn_cls: 0.2066  loss_rpn_bbox: 0.0809  loss_cls: 0.4002  acc: 93.9697  loss_bbox: 0.1988  loss_mask: 0.6855
2025/12/11 00:36:41 - mmengine - INFO - Epoch(train)  [1][ 300/7330]  base_lr: 3.0000e-05 lr: 3.0000e-05  eta: 2 days, 8:59:35  time: 2.1098  data_time: 0.0052  memory: 42142  loss: 1.5134  loss_rpn_cls: 0.1723  loss_rpn_bbox: 0.0775  loss_cls: 0.3902  acc: 94.3726  loss_bbox: 0.2032  loss_mask: 0.6703
2025/12/11 00:38:25 - mmengine - INFO - Epoch(train)  [1][ 350/7330]  base_lr: 3.5000e-05 lr: 3.5000e-05  eta: 2 days, 8:03:52  time: 2.0828  data_time: 0.0052  memory: 41368  loss: 1.5484  loss_rpn_cls: 0.1601  loss_rpn_bbox: 0.0808  loss_cls: 0.4273  acc: 93.6035  loss_bbox: 0.2300  loss_mask: 0.6501
2025/12/11 00:39:59 - mmengine - INFO - Epoch(train)  [1][ 400/7330]  base_lr: 4.0000e-05 lr: 4.0000e-05  eta: 2 days, 6:46:52  time: 1.8922  data_time: 0.0047  memory: 42878  loss: 1.5138  loss_rpn_cls: 0.1442  loss_rpn_bbox: 0.0763  loss_cls: 0.4252  acc: 92.2974  loss_bbox: 0.2457  loss_mask: 0.6224
2025/12/11 00:41:40 - mmengine - INFO - Epoch(train)  [1][ 450/7330]  base_lr: 4.5000e-05 lr: 4.5000e-05  eta: 2 days, 6:05:45  time: 2.0101  data_time: 0.0048  memory: 42026  loss: 1.5729  loss_rpn_cls: 0.1305  loss_rpn_bbox: 0.0751  loss_cls: 0.4774  acc: 90.8813  loss_bbox: 0.2902  loss_mask: 0.5998
2025/12/11 00:43:16 - mmengine - INFO - Epoch(train)  [1][ 500/7330]  base_lr: 5.0000e-05 lr: 5.0000e-05  eta: 2 days, 5:20:30  time: 1.9277  data_time: 0.0055  memory: 42413  loss: 1.5749  loss_rpn_cls: 0.1155  loss_rpn_bbox: 0.0708  loss_cls: 0.4927  acc: 91.4307  loss_bbox: 0.3115  loss_mask: 0.5844
2025/12/11 00:45:22 - mmengine - INFO - Epoch(train)  [1][ 550/7330]  base_lr: 5.5000e-05 lr: 5.5000e-05  eta: 2 days, 6:01:28  time: 2.5187  data_time: 0.0054  memory: 41561  loss: 1.6339  loss_rpn_cls: 0.1091  loss_rpn_bbox: 0.0764  loss_cls: 0.5359  acc: 88.7573  loss_bbox: 0.3572  loss_mask: 0.5553
2025/12/11 00:46:57 - mmengine - INFO - Epoch(train)  [1][ 600/7330]  base_lr: 6.0000e-05 lr: 6.0000e-05  eta: 2 days, 5:19:43  time: 1.8963  data_time: 0.0047  memory: 44371  loss: 1.5833  loss_rpn_cls: 0.1030  loss_rpn_bbox: 0.0739  loss_cls: 0.5117  acc: 90.1978  loss_bbox: 0.3594  loss_mask: 0.5353
2025/12/11 00:48:40 - mmengine - INFO - Epoch(train)  [1][ 650/7330]  base_lr: 6.5000e-05 lr: 6.5000e-05  eta: 2 days, 5:03:14  time: 2.0667  data_time: 0.0056  memory: 42713  loss: 1.5666  loss_rpn_cls: 0.1006  loss_rpn_bbox: 0.0747  loss_cls: 0.5100  acc: 87.8906  loss_bbox: 0.3709  loss_mask: 0.5104
2025/12/11 00:50:45 - mmengine - INFO - Epoch(train)  [1][ 700/7330]  base_lr: 7.0000e-05 lr: 7.0000e-05  eta: 2 days, 5:32:59  time: 2.4915  data_time: 0.0051  memory: 44165  loss: 1.5424  loss_rpn_cls: 0.0990  loss_rpn_bbox: 0.0736  loss_cls: 0.4965  acc: 92.1021  loss_bbox: 0.3754  loss_mask: 0.4980
2025/12/11 00:52:30 - mmengine - INFO - Epoch(train)  [1][ 750/7330]  base_lr: 7.5000e-05 lr: 7.5000e-05  eta: 2 days, 5:20:06  time: 2.0952  data_time: 0.0045  memory: 43473  loss: 1.4438  loss_rpn_cls: 0.0860  loss_rpn_bbox: 0.0624  loss_cls: 0.4613  acc: 89.7095  loss_bbox: 0.3522  loss_mask: 0.4819
2025/12/11 00:54:42 - mmengine - INFO - Epoch(train)  [1][ 800/7330]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 2 days, 5:59:02  time: 2.6508  data_time: 0.0046  memory: 43151  loss: 1.4583  loss_rpn_cls: 0.0862  loss_rpn_bbox: 0.0639  loss_cls: 0.4675  acc: 88.5376  loss_bbox: 0.3737  loss_mask: 0.4670
2025/12/11 00:56:51 - mmengine - INFO - Epoch(train)  [1][ 850/7330]  base_lr: 8.5000e-05 lr: 8.5000e-05  eta: 2 days, 6:26:45  time: 2.5761  data_time: 0.0065  memory: 42259  loss: 1.4414  loss_rpn_cls: 0.0866  loss_rpn_bbox: 0.0686  loss_cls: 0.4490  acc: 88.3667  loss_bbox: 0.3801  loss_mask: 0.4571
2025/12/11 00:58:27 - mmengine - INFO - Epoch(train)  [1][ 900/7330]  base_lr: 9.0000e-05 lr: 9.0000e-05  eta: 2 days, 5:57:54  time: 1.9154  data_time: 0.0051  memory: 41913  loss: 1.4161  loss_rpn_cls: 0.0853  loss_rpn_bbox: 0.0672  loss_cls: 0.4452  acc: 91.8335  loss_bbox: 0.3793  loss_mask: 0.4391
2025/12/11 01:00:06 - mmengine - INFO - Epoch(train)  [1][ 950/7330]  base_lr: 9.5000e-05 lr: 9.5000e-05  eta: 2 days, 5:37:06  time: 1.9834  data_time: 0.0044  memory: 42521  loss: 1.3951  loss_rpn_cls: 0.0792  loss_rpn_bbox: 0.0652  loss_cls: 0.4304  acc: 88.2080  loss_bbox: 0.3888  loss_mask: 0.4316
2025/12/11 01:01:56 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 01:01:56 - mmengine - INFO - Epoch(train)  [1][1000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 5:34:41  time: 2.2105  data_time: 0.0045  memory: 41884  loss: 1.3562  loss_rpn_cls: 0.0771  loss_rpn_bbox: 0.0618  loss_cls: 0.4167  acc: 89.2944  loss_bbox: 0.3707  loss_mask: 0.4298
2025/12/11 01:03:36 - mmengine - INFO - Epoch(train)  [1][1050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 5:17:35  time: 1.9971  data_time: 0.0046  memory: 42750  loss: 1.3742  loss_rpn_cls: 0.0800  loss_rpn_bbox: 0.0670  loss_cls: 0.4238  acc: 89.9658  loss_bbox: 0.3774  loss_mask: 0.4260
2025/12/11 01:06:12 - mmengine - INFO - Epoch(train)  [1][1100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:15:53  time: 3.1212  data_time: 0.0047  memory: 43074  loss: 1.3621  loss_rpn_cls: 0.0804  loss_rpn_bbox: 0.0671  loss_cls: 0.4158  acc: 91.6626  loss_bbox: 0.3828  loss_mask: 0.4161
2025/12/11 01:08:09 - mmengine - INFO - Epoch(train)  [1][1150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:19:29  time: 2.3361  data_time: 0.0045  memory: 42013  loss: 1.2861  loss_rpn_cls: 0.0763  loss_rpn_bbox: 0.0633  loss_cls: 0.3867  acc: 89.0137  loss_bbox: 0.3528  loss_mask: 0.4070
2025/12/11 01:10:07 - mmengine - INFO - Epoch(train)  [1][1200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:24:20  time: 2.3645  data_time: 0.0038  memory: 42956  loss: 1.3126  loss_rpn_cls: 0.0802  loss_rpn_bbox: 0.0617  loss_cls: 0.3944  acc: 88.4277  loss_bbox: 0.3676  loss_mask: 0.4087
2025/12/11 01:12:20 - mmengine - INFO - Epoch(train)  [1][1250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:45:13  time: 2.6514  data_time: 0.0041  memory: 42860  loss: 1.3042  loss_rpn_cls: 0.0760  loss_rpn_bbox: 0.0649  loss_cls: 0.3904  acc: 89.9536  loss_bbox: 0.3595  loss_mask: 0.4133
2025/12/11 01:14:16 - mmengine - INFO - Epoch(train)  [1][1300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:45:39  time: 2.3152  data_time: 0.0049  memory: 42246  loss: 1.2693  loss_rpn_cls: 0.0741  loss_rpn_bbox: 0.0662  loss_cls: 0.3741  acc: 87.3535  loss_bbox: 0.3650  loss_mask: 0.3899
2025/12/11 01:16:27 - mmengine - INFO - Epoch(train)  [1][1350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 7:02:55  time: 2.6332  data_time: 0.0056  memory: 42206  loss: 1.2659  loss_rpn_cls: 0.0665  loss_rpn_bbox: 0.0639  loss_cls: 0.3792  acc: 90.6128  loss_bbox: 0.3688  loss_mask: 0.3874
2025/12/11 01:18:23 - mmengine - INFO - Epoch(train)  [1][1400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 7:02:41  time: 2.3206  data_time: 0.0045  memory: 42761  loss: 1.2605  loss_rpn_cls: 0.0709  loss_rpn_bbox: 0.0639  loss_cls: 0.3703  acc: 89.7095  loss_bbox: 0.3700  loss_mask: 0.3855
2025/12/11 01:20:17 - mmengine - INFO - Epoch(train)  [1][1450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 7:00:24  time: 2.2817  data_time: 0.0043  memory: 42852  loss: 1.2095  loss_rpn_cls: 0.0687  loss_rpn_bbox: 0.0564  loss_cls: 0.3501  acc: 89.3311  loss_bbox: 0.3531  loss_mask: 0.3811
2025/12/11 01:22:21 - mmengine - INFO - Epoch(train)  [1][1500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 7:07:21  time: 2.4734  data_time: 0.0039  memory: 42564  loss: 1.2009  loss_rpn_cls: 0.0628  loss_rpn_bbox: 0.0570  loss_cls: 0.3528  acc: 91.6870  loss_bbox: 0.3504  loss_mask: 0.3779
2025/12/11 01:24:04 - mmengine - INFO - Epoch(train)  [1][1550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:54:35  time: 2.0615  data_time: 0.0047  memory: 42687  loss: 1.2297  loss_rpn_cls: 0.0697  loss_rpn_bbox: 0.0634  loss_cls: 0.3613  acc: 89.8804  loss_bbox: 0.3574  loss_mask: 0.3779
2025/12/11 01:25:42 - mmengine - INFO - Epoch(train)  [1][1600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:37:33  time: 1.9516  data_time: 0.0043  memory: 43018  loss: 1.2076  loss_rpn_cls: 0.0643  loss_rpn_bbox: 0.0587  loss_cls: 0.3533  acc: 91.6138  loss_bbox: 0.3546  loss_mask: 0.3766
2025/12/11 01:28:02 - mmengine - INFO - Epoch(train)  [1][1650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:58:59  time: 2.8123  data_time: 0.0049  memory: 42347  loss: 1.1729  loss_rpn_cls: 0.0670  loss_rpn_bbox: 0.0587  loss_cls: 0.3391  acc: 92.4927  loss_bbox: 0.3383  loss_mask: 0.3699
2025/12/11 01:29:47 - mmengine - INFO - Epoch(train)  [1][1700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:48:14  time: 2.0845  data_time: 0.0042  memory: 42242  loss: 1.2222  loss_rpn_cls: 0.0697  loss_rpn_bbox: 0.0629  loss_cls: 0.3550  acc: 90.6006  loss_bbox: 0.3618  loss_mask: 0.3727
2025/12/11 01:31:34 - mmengine - INFO - Epoch(train)  [1][1750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:40:58  time: 2.1566  data_time: 0.0055  memory: 42548  loss: 1.1826  loss_rpn_cls: 0.0651  loss_rpn_bbox: 0.0596  loss_cls: 0.3462  acc: 93.0298  loss_bbox: 0.3439  loss_mask: 0.3677
2025/12/11 01:33:29 - mmengine - INFO - Epoch(train)  [1][1800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:39:02  time: 2.2824  data_time: 0.0048  memory: 43445  loss: 1.2314  loss_rpn_cls: 0.0707  loss_rpn_bbox: 0.0656  loss_cls: 0.3597  acc: 90.9668  loss_bbox: 0.3634  loss_mask: 0.3720
2025/12/11 01:35:11 - mmengine - INFO - Epoch(train)  [1][1850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:28:01  time: 2.0488  data_time: 0.0040  memory: 42745  loss: 1.1770  loss_rpn_cls: 0.0683  loss_rpn_bbox: 0.0617  loss_cls: 0.3347  acc: 88.7085  loss_bbox: 0.3443  loss_mask: 0.3680
2025/12/11 01:37:03 - mmengine - INFO - Epoch(train)  [1][1900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:24:26  time: 2.2321  data_time: 0.0038  memory: 44761  loss: 1.1838  loss_rpn_cls: 0.0672  loss_rpn_bbox: 0.0605  loss_cls: 0.3457  acc: 90.4297  loss_bbox: 0.3542  loss_mask: 0.3562
2025/12/11 01:38:51 - mmengine - INFO - Epoch(train)  [1][1950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:18:15  time: 2.1594  data_time: 0.0040  memory: 42636  loss: 1.1419  loss_rpn_cls: 0.0606  loss_rpn_bbox: 0.0567  loss_cls: 0.3303  acc: 90.0879  loss_bbox: 0.3361  loss_mask: 0.3582
2025/12/11 01:40:32 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 01:40:32 - mmengine - INFO - Epoch(train)  [1][2000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:07:54  time: 2.0369  data_time: 0.0046  memory: 43444  loss: 1.1196  loss_rpn_cls: 0.0609  loss_rpn_bbox: 0.0534  loss_cls: 0.3171  acc: 89.5630  loss_bbox: 0.3311  loss_mask: 0.3571
2025/12/11 01:42:29 - mmengine - INFO - Epoch(train)  [1][2050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:08:06  time: 2.3267  data_time: 0.0048  memory: 44003  loss: 1.1525  loss_rpn_cls: 0.0646  loss_rpn_bbox: 0.0587  loss_cls: 0.3304  acc: 91.3818  loss_bbox: 0.3421  loss_mask: 0.3565
2025/12/11 01:44:31 - mmengine - INFO - Epoch(train)  [1][2100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:11:58  time: 2.4375  data_time: 0.0040  memory: 43793  loss: 1.1367  loss_rpn_cls: 0.0620  loss_rpn_bbox: 0.0570  loss_cls: 0.3261  acc: 89.3799  loss_bbox: 0.3373  loss_mask: 0.3544
2025/12/11 01:46:55 - mmengine - INFO - Epoch(train)  [1][2150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:30:48  time: 2.8959  data_time: 0.0053  memory: 42250  loss: 1.1412  loss_rpn_cls: 0.0630  loss_rpn_bbox: 0.0556  loss_cls: 0.3242  acc: 90.4419  loss_bbox: 0.3443  loss_mask: 0.3541
2025/12/11 01:48:32 - mmengine - INFO - Epoch(train)  [1][2200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:17:36  time: 1.9393  data_time: 0.0042  memory: 42559  loss: 1.1520  loss_rpn_cls: 0.0633  loss_rpn_bbox: 0.0583  loss_cls: 0.3268  acc: 91.6260  loss_bbox: 0.3476  loss_mask: 0.3561
2025/12/11 01:50:09 - mmengine - INFO - Epoch(train)  [1][2250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:04:57  time: 1.9404  data_time: 0.0042  memory: 42381  loss: 1.0962  loss_rpn_cls: 0.0566  loss_rpn_bbox: 0.0529  loss_cls: 0.3137  acc: 87.8052  loss_bbox: 0.3217  loss_mask: 0.3513
2025/12/11 01:52:34 - mmengine - INFO - Epoch(train)  [1][2300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:22:12  time: 2.8882  data_time: 0.0047  memory: 42777  loss: 1.1084  loss_rpn_cls: 0.0591  loss_rpn_bbox: 0.0543  loss_cls: 0.3192  acc: 94.0552  loss_bbox: 0.3314  loss_mask: 0.3443
2025/12/11 01:54:59 - mmengine - INFO - Epoch(train)  [1][2350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:39:14  time: 2.9089  data_time: 0.0044  memory: 43345  loss: 1.1312  loss_rpn_cls: 0.0688  loss_rpn_bbox: 0.0585  loss_cls: 0.3248  acc: 90.9668  loss_bbox: 0.3332  loss_mask: 0.3460
2025/12/11 01:57:16 - mmengine - INFO - Epoch(train)  [1][2400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:50:25  time: 2.7390  data_time: 0.0038  memory: 43359  loss: 1.1148  loss_rpn_cls: 0.0619  loss_rpn_bbox: 0.0568  loss_cls: 0.3148  acc: 86.5234  loss_bbox: 0.3364  loss_mask: 0.3449
2025/12/11 01:59:05 - mmengine - INFO - Epoch(train)  [1][2450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:44:30  time: 2.1706  data_time: 0.0044  memory: 42153  loss: 1.1164  loss_rpn_cls: 0.0623  loss_rpn_bbox: 0.0576  loss_cls: 0.3159  acc: 88.6353  loss_bbox: 0.3325  loss_mask: 0.3481
2025/12/11 02:01:03 - mmengine - INFO - Epoch(train)  [1][2500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:44:12  time: 2.3614  data_time: 0.0043  memory: 42099  loss: 1.1133  loss_rpn_cls: 0.0581  loss_rpn_bbox: 0.0572  loss_cls: 0.3209  acc: 90.2100  loss_bbox: 0.3345  loss_mask: 0.3427
2025/12/11 02:02:55 - mmengine - INFO - Epoch(train)  [1][2550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:40:17  time: 2.2343  data_time: 0.0045  memory: 41776  loss: 1.1079  loss_rpn_cls: 0.0617  loss_rpn_bbox: 0.0569  loss_cls: 0.3133  acc: 89.3433  loss_bbox: 0.3299  loss_mask: 0.3460
2025/12/11 02:04:59 - mmengine - INFO - Epoch(train)  [1][2600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:43:34  time: 2.4944  data_time: 0.0043  memory: 42237  loss: 1.1156  loss_rpn_cls: 0.0639  loss_rpn_bbox: 0.0609  loss_cls: 0.3131  acc: 87.0728  loss_bbox: 0.3288  loss_mask: 0.3489
2025/12/11 02:06:49 - mmengine - INFO - Epoch(train)  [1][2650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:38:20  time: 2.1847  data_time: 0.0045  memory: 41570  loss: 1.1012  loss_rpn_cls: 0.0603  loss_rpn_bbox: 0.0552  loss_cls: 0.3138  acc: 87.4268  loss_bbox: 0.3267  loss_mask: 0.3452
2025/12/11 02:09:04 - mmengine - INFO - Epoch(train)  [1][2700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:46:55  time: 2.7053  data_time: 0.0039  memory: 42063  loss: 1.0813  loss_rpn_cls: 0.0584  loss_rpn_bbox: 0.0544  loss_cls: 0.3021  acc: 92.7490  loss_bbox: 0.3217  loss_mask: 0.3446
2025/12/11 02:10:58 - mmengine - INFO - Epoch(train)  [1][2750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:44:14  time: 2.2833  data_time: 0.0040  memory: 41887  loss: 1.0862  loss_rpn_cls: 0.0563  loss_rpn_bbox: 0.0543  loss_cls: 0.3097  acc: 88.6597  loss_bbox: 0.3290  loss_mask: 0.3370
2025/12/11 02:12:38 - mmengine - INFO - Epoch(train)  [1][2800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:34:23  time: 2.0003  data_time: 0.0044  memory: 43498  loss: 1.0680  loss_rpn_cls: 0.0616  loss_rpn_bbox: 0.0567  loss_cls: 0.2982  acc: 93.0054  loss_bbox: 0.3167  loss_mask: 0.3348
2025/12/11 02:14:24 - mmengine - INFO - Epoch(train)  [1][2850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:27:43  time: 2.1160  data_time: 0.0042  memory: 42007  loss: 1.0719  loss_rpn_cls: 0.0571  loss_rpn_bbox: 0.0552  loss_cls: 0.3049  acc: 91.1011  loss_bbox: 0.3235  loss_mask: 0.3312
2025/12/11 02:16:07 - mmengine - INFO - Epoch(train)  [1][2900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:20:04  time: 2.0696  data_time: 0.0046  memory: 42032  loss: 1.0684  loss_rpn_cls: 0.0610  loss_rpn_bbox: 0.0536  loss_cls: 0.2984  acc: 87.5610  loss_bbox: 0.3236  loss_mask: 0.3319
2025/12/11 02:17:44 - mmengine - INFO - Epoch(train)  [1][2950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:09:13  time: 1.9275  data_time: 0.0041  memory: 43539  loss: 1.0570  loss_rpn_cls: 0.0549  loss_rpn_bbox: 0.0507  loss_cls: 0.3003  acc: 92.0776  loss_bbox: 0.3168  loss_mask: 0.3343
2025/12/11 02:19:37 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 02:19:37 - mmengine - INFO - Epoch(train)  [1][3000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:06:48  time: 2.2718  data_time: 0.0040  memory: 43629  loss: 1.0793  loss_rpn_cls: 0.0610  loss_rpn_bbox: 0.0572  loss_cls: 0.3067  acc: 90.2344  loss_bbox: 0.3243  loss_mask: 0.3301
2025/12/11 02:21:39 - mmengine - INFO - Epoch(train)  [1][3050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:08:20  time: 2.4414  data_time: 0.0042  memory: 41525  loss: 1.0723  loss_rpn_cls: 0.0575  loss_rpn_bbox: 0.0551  loss_cls: 0.3002  acc: 90.7104  loss_bbox: 0.3274  loss_mask: 0.3319
2025/12/11 02:23:25 - mmengine - INFO - Epoch(train)  [1][3100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:02:09  time: 2.1082  data_time: 0.0041  memory: 42990  loss: 1.0679  loss_rpn_cls: 0.0591  loss_rpn_bbox: 0.0538  loss_cls: 0.3011  acc: 93.1885  loss_bbox: 0.3206  loss_mask: 0.3333
2025/12/11 02:25:21 - mmengine - INFO - Epoch(train)  [1][3150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 6:01:01  time: 2.3272  data_time: 0.0041  memory: 43401  loss: 1.0811  loss_rpn_cls: 0.0552  loss_rpn_bbox: 0.0552  loss_cls: 0.3053  acc: 87.0972  loss_bbox: 0.3288  loss_mask: 0.3366
2025/12/11 02:26:57 - mmengine - INFO - Epoch(train)  [1][3200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 5:50:48  time: 1.9162  data_time: 0.0040  memory: 42670  loss: 1.0783  loss_rpn_cls: 0.0559  loss_rpn_bbox: 0.0543  loss_cls: 0.3043  acc: 88.4033  loss_bbox: 0.3250  loss_mask: 0.3388
2025/12/11 02:28:41 - mmengine - INFO - Epoch(train)  [1][3250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 5:44:17  time: 2.0754  data_time: 0.0048  memory: 43649  loss: 1.0516  loss_rpn_cls: 0.0564  loss_rpn_bbox: 0.0555  loss_cls: 0.2939  acc: 93.8354  loss_bbox: 0.3200  loss_mask: 0.3258
2025/12/11 02:30:17 - mmengine - INFO - Epoch(train)  [1][3300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 5:34:47  time: 1.9280  data_time: 0.0044  memory: 44793  loss: 1.0506  loss_rpn_cls: 0.0557  loss_rpn_bbox: 0.0520  loss_cls: 0.2947  acc: 90.5029  loss_bbox: 0.3168  loss_mask: 0.3314
2025/12/11 02:32:00 - mmengine - INFO - Epoch(train)  [1][3350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 5:28:15  time: 2.0582  data_time: 0.0041  memory: 41897  loss: 1.0802  loss_rpn_cls: 0.0579  loss_rpn_bbox: 0.0545  loss_cls: 0.3041  acc: 90.7959  loss_bbox: 0.3320  loss_mask: 0.3316
2025/12/11 02:33:35 - mmengine - INFO - Epoch(train)  [1][3400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 5:18:29  time: 1.8954  data_time: 0.0041  memory: 41541  loss: 1.0740  loss_rpn_cls: 0.0604  loss_rpn_bbox: 0.0558  loss_cls: 0.3034  acc: 89.3799  loss_bbox: 0.3190  loss_mask: 0.3354
2025/12/11 02:35:12 - mmengine - INFO - Epoch(train)  [1][3450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 5:10:04  time: 1.9498  data_time: 0.0045  memory: 43618  loss: 1.0653  loss_rpn_cls: 0.0595  loss_rpn_bbox: 0.0540  loss_cls: 0.2956  acc: 88.7085  loss_bbox: 0.3174  loss_mask: 0.3388
2025/12/11 02:36:49 - mmengine - INFO - Epoch(train)  [1][3500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 5:01:30  time: 1.9328  data_time: 0.0042  memory: 43825  loss: 1.0575  loss_rpn_cls: 0.0558  loss_rpn_bbox: 0.0527  loss_cls: 0.2957  acc: 90.9058  loss_bbox: 0.3204  loss_mask: 0.3329
2025/12/11 02:38:25 - mmengine - INFO - Epoch(train)  [1][3550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 4:53:02  time: 1.9276  data_time: 0.0039  memory: 44313  loss: 1.0538  loss_rpn_cls: 0.0540  loss_rpn_bbox: 0.0525  loss_cls: 0.3004  acc: 90.3076  loss_bbox: 0.3178  loss_mask: 0.3291
2025/12/11 02:40:03 - mmengine - INFO - Epoch(train)  [1][3600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 4:45:07  time: 1.9462  data_time: 0.0045  memory: 43703  loss: 1.0449  loss_rpn_cls: 0.0588  loss_rpn_bbox: 0.0535  loss_cls: 0.2901  acc: 90.7715  loss_bbox: 0.3122  loss_mask: 0.3303
2025/12/11 02:41:39 - mmengine - INFO - Epoch(train)  [1][3650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 4:36:57  time: 1.9250  data_time: 0.0045  memory: 42384  loss: 1.0560  loss_rpn_cls: 0.0576  loss_rpn_bbox: 0.0564  loss_cls: 0.2984  acc: 87.1948  loss_bbox: 0.3186  loss_mask: 0.3249
2025/12/11 02:43:15 - mmengine - INFO - Epoch(train)  [1][3700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 4:28:59  time: 1.9255  data_time: 0.0045  memory: 44687  loss: 1.0478  loss_rpn_cls: 0.0563  loss_rpn_bbox: 0.0557  loss_cls: 0.2934  acc: 89.1968  loss_bbox: 0.3180  loss_mask: 0.3244
2025/12/11 02:44:53 - mmengine - INFO - Epoch(train)  [1][3750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 4:21:38  time: 1.9495  data_time: 0.0049  memory: 41472  loss: 1.0265  loss_rpn_cls: 0.0558  loss_rpn_bbox: 0.0525  loss_cls: 0.2878  acc: 89.3311  loss_bbox: 0.3083  loss_mask: 0.3221
2025/12/11 02:46:28 - mmengine - INFO - Epoch(train)  [1][3800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 4:13:42  time: 1.9091  data_time: 0.0044  memory: 41823  loss: 1.0136  loss_rpn_cls: 0.0546  loss_rpn_bbox: 0.0498  loss_cls: 0.2846  acc: 91.0034  loss_bbox: 0.2976  loss_mask: 0.3270
2025/12/11 02:48:05 - mmengine - INFO - Epoch(train)  [1][3850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 4:06:36  time: 1.9467  data_time: 0.0047  memory: 42458  loss: 1.0699  loss_rpn_cls: 0.0553  loss_rpn_bbox: 0.0554  loss_cls: 0.3040  acc: 92.9321  loss_bbox: 0.3251  loss_mask: 0.3302
2025/12/11 02:49:40 - mmengine - INFO - Epoch(train)  [1][3900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 3:58:49  time: 1.9002  data_time: 0.0042  memory: 42282  loss: 1.0486  loss_rpn_cls: 0.0559  loss_rpn_bbox: 0.0550  loss_cls: 0.2946  acc: 93.2495  loss_bbox: 0.3222  loss_mask: 0.3208
2025/12/11 02:51:17 - mmengine - INFO - Epoch(train)  [1][3950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 3:51:43  time: 1.9301  data_time: 0.0056  memory: 43448  loss: 1.0645  loss_rpn_cls: 0.0579  loss_rpn_bbox: 0.0553  loss_cls: 0.3037  acc: 92.4194  loss_bbox: 0.3232  loss_mask: 0.3244
2025/12/11 02:53:09 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 02:53:09 - mmengine - INFO - Epoch(train)  [1][4000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 3:50:07  time: 2.2374  data_time: 0.0047  memory: 42844  loss: 1.0203  loss_rpn_cls: 0.0518  loss_rpn_bbox: 0.0524  loss_cls: 0.2822  acc: 91.4062  loss_bbox: 0.3091  loss_mask: 0.3249
2025/12/11 02:55:18 - mmengine - INFO - Epoch(train)  [1][4050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 3:54:24  time: 2.5780  data_time: 0.0047  memory: 42770  loss: 1.0255  loss_rpn_cls: 0.0527  loss_rpn_bbox: 0.0522  loss_cls: 0.2867  acc: 92.6147  loss_bbox: 0.3039  loss_mask: 0.3299
2025/12/11 02:57:03 - mmengine - INFO - Epoch(train)  [1][4100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 3:50:21  time: 2.0977  data_time: 0.0045  memory: 42744  loss: 1.0673  loss_rpn_cls: 0.0589  loss_rpn_bbox: 0.0550  loss_cls: 0.3002  acc: 92.4438  loss_bbox: 0.3250  loss_mask: 0.3282
2025/12/11 02:58:37 - mmengine - INFO - Epoch(train)  [1][4150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 3:42:46  time: 1.8852  data_time: 0.0044  memory: 42097  loss: 1.0256  loss_rpn_cls: 0.0554  loss_rpn_bbox: 0.0517  loss_cls: 0.2904  acc: 91.6016  loss_bbox: 0.3051  loss_mask: 0.3230
2025/12/11 03:00:34 - mmengine - INFO - Epoch(train)  [1][4200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 3:43:05  time: 2.3515  data_time: 0.0075  memory: 42217  loss: 1.0442  loss_rpn_cls: 0.0575  loss_rpn_bbox: 0.0549  loss_cls: 0.2905  acc: 90.9424  loss_bbox: 0.3156  loss_mask: 0.3257
2025/12/11 03:02:10 - mmengine - INFO - Epoch(train)  [1][4250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 3:36:15  time: 1.9198  data_time: 0.0045  memory: 42124  loss: 1.0337  loss_rpn_cls: 0.0549  loss_rpn_bbox: 0.0543  loss_cls: 0.2843  acc: 89.5020  loss_bbox: 0.3145  loss_mask: 0.3258
2025/12/11 03:03:46 - mmengine - INFO - Epoch(train)  [1][4300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 3:29:22  time: 1.9084  data_time: 0.0042  memory: 41924  loss: 1.0564  loss_rpn_cls: 0.0569  loss_rpn_bbox: 0.0568  loss_cls: 0.2940  acc: 93.1274  loss_bbox: 0.3232  loss_mask: 0.3255
2025/12/11 03:05:30 - mmengine - INFO - Epoch(train)  [1][4350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 3:25:19  time: 2.0781  data_time: 0.0045  memory: 41991  loss: 1.0549  loss_rpn_cls: 0.0579  loss_rpn_bbox: 0.0544  loss_cls: 0.2991  acc: 91.3818  loss_bbox: 0.3233  loss_mask: 0.3203
2025/12/11 03:07:05 - mmengine - INFO - Epoch(train)  [1][4400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 3:18:40  time: 1.9101  data_time: 0.0043  memory: 42119  loss: 1.0013  loss_rpn_cls: 0.0522  loss_rpn_bbox: 0.0507  loss_cls: 0.2776  acc: 94.4824  loss_bbox: 0.3030  loss_mask: 0.3177
2025/12/11 03:08:41 - mmengine - INFO - Epoch(train)  [1][4450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 3:12:05  time: 1.9083  data_time: 0.0042  memory: 42441  loss: 0.9971  loss_rpn_cls: 0.0511  loss_rpn_bbox: 0.0509  loss_cls: 0.2674  acc: 92.4561  loss_bbox: 0.3080  loss_mask: 0.3198
2025/12/11 03:10:17 - mmengine - INFO - Epoch(train)  [1][4500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 3:05:55  time: 1.9268  data_time: 0.0046  memory: 42313  loss: 1.0130  loss_rpn_cls: 0.0527  loss_rpn_bbox: 0.0520  loss_cls: 0.2814  acc: 89.7461  loss_bbox: 0.3117  loss_mask: 0.3153
2025/12/11 03:11:52 - mmengine - INFO - Epoch(train)  [1][4550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 2:59:34  time: 1.9084  data_time: 0.0042  memory: 41850  loss: 0.9981  loss_rpn_cls: 0.0512  loss_rpn_bbox: 0.0515  loss_cls: 0.2764  acc: 90.1367  loss_bbox: 0.3051  loss_mask: 0.3138
2025/12/11 03:13:40 - mmengine - INFO - Epoch(train)  [1][4600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 2:57:05  time: 2.1584  data_time: 0.0048  memory: 43507  loss: 1.0302  loss_rpn_cls: 0.0539  loss_rpn_bbox: 0.0543  loss_cls: 0.2881  acc: 90.4907  loss_bbox: 0.3164  loss_mask: 0.3175
2025/12/11 03:15:27 - mmengine - INFO - Epoch(train)  [1][4650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 2:54:20  time: 2.1394  data_time: 0.0046  memory: 41780  loss: 1.0367  loss_rpn_cls: 0.0565  loss_rpn_bbox: 0.0541  loss_cls: 0.2951  acc: 93.2129  loss_bbox: 0.3141  loss_mask: 0.3168
2025/12/11 03:17:05 - mmengine - INFO - Epoch(train)  [1][4700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 2:48:47  time: 1.9476  data_time: 0.0050  memory: 43019  loss: 1.0112  loss_rpn_cls: 0.0569  loss_rpn_bbox: 0.0540  loss_cls: 0.2783  acc: 93.9209  loss_bbox: 0.3092  loss_mask: 0.3127
2025/12/11 03:18:41 - mmengine - INFO - Epoch(train)  [1][4750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 2:42:58  time: 1.9242  data_time: 0.0045  memory: 43624  loss: 1.0132  loss_rpn_cls: 0.0545  loss_rpn_bbox: 0.0517  loss_cls: 0.2786  acc: 91.3086  loss_bbox: 0.3078  loss_mask: 0.3205
2025/12/11 03:20:20 - mmengine - INFO - Epoch(train)  [1][4800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 2:37:58  time: 1.9747  data_time: 0.0068  memory: 42273  loss: 1.0429  loss_rpn_cls: 0.0561  loss_rpn_bbox: 0.0570  loss_cls: 0.2928  acc: 93.5425  loss_bbox: 0.3198  loss_mask: 0.3173
2025/12/11 03:21:58 - mmengine - INFO - Epoch(train)  [1][4850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 2:32:55  time: 1.9661  data_time: 0.0048  memory: 43010  loss: 1.0592  loss_rpn_cls: 0.0581  loss_rpn_bbox: 0.0563  loss_cls: 0.2946  acc: 92.3218  loss_bbox: 0.3314  loss_mask: 0.3189
2025/12/11 03:23:38 - mmengine - INFO - Epoch(train)  [1][4900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 2:28:22  time: 1.9960  data_time: 0.0048  memory: 43361  loss: 1.0019  loss_rpn_cls: 0.0548  loss_rpn_bbox: 0.0519  loss_cls: 0.2769  acc: 90.1855  loss_bbox: 0.3028  loss_mask: 0.3154
2025/12/11 03:25:15 - mmengine - INFO - Epoch(train)  [1][4950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 2:23:14  time: 1.9511  data_time: 0.0046  memory: 44141  loss: 1.0046  loss_rpn_cls: 0.0550  loss_rpn_bbox: 0.0521  loss_cls: 0.2763  acc: 91.1133  loss_bbox: 0.3033  loss_mask: 0.3179
2025/12/11 03:26:52 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 03:26:52 - mmengine - INFO - Epoch(train)  [1][5000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 2:17:52  time: 1.9284  data_time: 0.0048  memory: 42292  loss: 0.9925  loss_rpn_cls: 0.0499  loss_rpn_bbox: 0.0518  loss_cls: 0.2744  acc: 92.7246  loss_bbox: 0.3064  loss_mask: 0.3100
2025/12/11 03:28:28 - mmengine - INFO - Epoch(train)  [1][5050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 2:12:30  time: 1.9233  data_time: 0.0047  memory: 43245  loss: 0.9901  loss_rpn_cls: 0.0505  loss_rpn_bbox: 0.0490  loss_cls: 0.2763  acc: 93.2739  loss_bbox: 0.3016  loss_mask: 0.3126
2025/12/11 03:30:04 - mmengine - INFO - Epoch(train)  [1][5100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 2:07:20  time: 1.9327  data_time: 0.0048  memory: 43370  loss: 1.0347  loss_rpn_cls: 0.0515  loss_rpn_bbox: 0.0521  loss_cls: 0.2930  acc: 90.7227  loss_bbox: 0.3190  loss_mask: 0.3191
2025/12/11 03:31:42 - mmengine - INFO - Epoch(train)  [1][5150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 2:02:22  time: 1.9424  data_time: 0.0043  memory: 43698  loss: 1.0280  loss_rpn_cls: 0.0561  loss_rpn_bbox: 0.0552  loss_cls: 0.2857  acc: 92.5049  loss_bbox: 0.3168  loss_mask: 0.3141
2025/12/11 03:33:19 - mmengine - INFO - Epoch(train)  [1][5200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 1:57:32  time: 1.9479  data_time: 0.0049  memory: 44101  loss: 0.9677  loss_rpn_cls: 0.0473  loss_rpn_bbox: 0.0504  loss_cls: 0.2665  acc: 92.2485  loss_bbox: 0.2962  loss_mask: 0.3074
2025/12/11 03:34:55 - mmengine - INFO - Epoch(train)  [1][5250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 1:52:29  time: 1.9262  data_time: 0.0045  memory: 41712  loss: 1.0044  loss_rpn_cls: 0.0533  loss_rpn_bbox: 0.0541  loss_cls: 0.2734  acc: 93.4448  loss_bbox: 0.3032  loss_mask: 0.3204
2025/12/11 03:36:30 - mmengine - INFO - Epoch(train)  [1][5300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 1:46:57  time: 1.8845  data_time: 0.0042  memory: 41498  loss: 0.9961  loss_rpn_cls: 0.0540  loss_rpn_bbox: 0.0522  loss_cls: 0.2751  acc: 91.5771  loss_bbox: 0.3017  loss_mask: 0.3132
2025/12/11 03:38:13 - mmengine - INFO - Epoch(train)  [1][5350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 1:43:47  time: 2.0622  data_time: 0.0052  memory: 43601  loss: 0.9865  loss_rpn_cls: 0.0541  loss_rpn_bbox: 0.0532  loss_cls: 0.2697  acc: 94.4214  loss_bbox: 0.2955  loss_mask: 0.3140
2025/12/11 03:40:03 - mmengine - INFO - Epoch(train)  [1][5400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 1:42:33  time: 2.2130  data_time: 0.0046  memory: 43242  loss: 1.0113  loss_rpn_cls: 0.0567  loss_rpn_bbox: 0.0537  loss_cls: 0.2797  acc: 92.0288  loss_bbox: 0.3085  loss_mask: 0.3126
2025/12/11 03:41:56 - mmengine - INFO - Epoch(train)  [1][5450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 1:41:51  time: 2.2548  data_time: 0.0043  memory: 43037  loss: 1.0159  loss_rpn_cls: 0.0554  loss_rpn_bbox: 0.0536  loss_cls: 0.2832  acc: 89.6362  loss_bbox: 0.3092  loss_mask: 0.3144
2025/12/11 03:43:35 - mmengine - INFO - Epoch(train)  [1][5500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 1:37:38  time: 1.9753  data_time: 0.0045  memory: 43610  loss: 0.9872  loss_rpn_cls: 0.0499  loss_rpn_bbox: 0.0533  loss_cls: 0.2680  acc: 90.3442  loss_bbox: 0.3049  loss_mask: 0.3111
2025/12/11 03:45:11 - mmengine - INFO - Epoch(train)  [1][5550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 1:32:52  time: 1.9276  data_time: 0.0044  memory: 41638  loss: 0.9920  loss_rpn_cls: 0.0499  loss_rpn_bbox: 0.0507  loss_cls: 0.2729  acc: 89.8682  loss_bbox: 0.3076  loss_mask: 0.3109
2025/12/11 03:46:49 - mmengine - INFO - Epoch(train)  [1][5600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 1:28:25  time: 1.9484  data_time: 0.0046  memory: 42481  loss: 0.9480  loss_rpn_cls: 0.0462  loss_rpn_bbox: 0.0452  loss_cls: 0.2672  acc: 92.3096  loss_bbox: 0.2867  loss_mask: 0.3027
2025/12/11 03:48:26 - mmengine - INFO - Epoch(train)  [1][5650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 1:24:04  time: 1.9531  data_time: 0.0046  memory: 42451  loss: 0.9888  loss_rpn_cls: 0.0524  loss_rpn_bbox: 0.0538  loss_cls: 0.2748  acc: 90.8447  loss_bbox: 0.2961  loss_mask: 0.3118
2025/12/11 03:50:02 - mmengine - INFO - Epoch(train)  [1][5700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 1:19:24  time: 1.9220  data_time: 0.0047  memory: 42374  loss: 0.9549  loss_rpn_cls: 0.0460  loss_rpn_bbox: 0.0473  loss_cls: 0.2670  acc: 91.6138  loss_bbox: 0.2894  loss_mask: 0.3053
2025/12/11 03:51:42 - mmengine - INFO - Epoch(train)  [1][5750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 1:15:41  time: 1.9968  data_time: 0.0046  memory: 43191  loss: 1.0323  loss_rpn_cls: 0.0524  loss_rpn_bbox: 0.0542  loss_cls: 0.2911  acc: 92.4438  loss_bbox: 0.3188  loss_mask: 0.3157
2025/12/11 03:53:18 - mmengine - INFO - Epoch(train)  [1][5800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 1:11:01  time: 1.9150  data_time: 0.0047  memory: 42911  loss: 0.9727  loss_rpn_cls: 0.0501  loss_rpn_bbox: 0.0493  loss_cls: 0.2697  acc: 89.1479  loss_bbox: 0.2953  loss_mask: 0.3083
2025/12/11 03:54:55 - mmengine - INFO - Epoch(train)  [1][5850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 1:06:42  time: 1.9387  data_time: 0.0042  memory: 42258  loss: 0.9975  loss_rpn_cls: 0.0499  loss_rpn_bbox: 0.0502  loss_cls: 0.2785  acc: 92.9443  loss_bbox: 0.3019  loss_mask: 0.3170
2025/12/11 03:56:31 - mmengine - INFO - Epoch(train)  [1][5900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 1:02:11  time: 1.9195  data_time: 0.0046  memory: 42372  loss: 0.9913  loss_rpn_cls: 0.0519  loss_rpn_bbox: 0.0525  loss_cls: 0.2794  acc: 89.7095  loss_bbox: 0.3005  loss_mask: 0.3069
2025/12/11 03:58:21 - mmengine - INFO - Epoch(train)  [1][5950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 1:01:01  time: 2.2046  data_time: 0.0046  memory: 42014  loss: 1.0137  loss_rpn_cls: 0.0552  loss_rpn_bbox: 0.0516  loss_cls: 0.2831  acc: 90.3198  loss_bbox: 0.3105  loss_mask: 0.3133
2025/12/11 03:59:54 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 03:59:54 - mmengine - INFO - Epoch(train)  [1][6000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 0:55:59  time: 1.8680  data_time: 0.0043  memory: 42653  loss: 0.9483  loss_rpn_cls: 0.0472  loss_rpn_bbox: 0.0457  loss_cls: 0.2652  acc: 94.4824  loss_bbox: 0.2829  loss_mask: 0.3072
2025/12/11 04:01:30 - mmengine - INFO - Epoch(train)  [1][6050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 0:51:31  time: 1.9116  data_time: 0.0054  memory: 42868  loss: 0.9762  loss_rpn_cls: 0.0530  loss_rpn_bbox: 0.0494  loss_cls: 0.2678  acc: 92.7246  loss_bbox: 0.3000  loss_mask: 0.3060
2025/12/11 04:03:04 - mmengine - INFO - Epoch(train)  [1][6100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 0:46:48  time: 1.8852  data_time: 0.0041  memory: 43629  loss: 0.9641  loss_rpn_cls: 0.0467  loss_rpn_bbox: 0.0506  loss_cls: 0.2624  acc: 89.1113  loss_bbox: 0.2974  loss_mask: 0.3071
2025/12/11 04:04:43 - mmengine - INFO - Epoch(train)  [1][6150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 0:43:04  time: 1.9703  data_time: 0.0043  memory: 42417  loss: 0.9798  loss_rpn_cls: 0.0504  loss_rpn_bbox: 0.0501  loss_cls: 0.2722  acc: 90.3809  loss_bbox: 0.3023  loss_mask: 0.3049
2025/12/11 04:06:20 - mmengine - INFO - Epoch(train)  [1][6200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 0:39:10  time: 1.9511  data_time: 0.0045  memory: 43239  loss: 0.9882  loss_rpn_cls: 0.0540  loss_rpn_bbox: 0.0534  loss_cls: 0.2789  acc: 89.7217  loss_bbox: 0.2991  loss_mask: 0.3029
2025/12/11 04:07:57 - mmengine - INFO - Epoch(train)  [1][6250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 0:35:09  time: 1.9375  data_time: 0.0047  memory: 42804  loss: 0.9704  loss_rpn_cls: 0.0509  loss_rpn_bbox: 0.0515  loss_cls: 0.2736  acc: 93.6646  loss_bbox: 0.2903  loss_mask: 0.3041
2025/12/11 04:09:33 - mmengine - INFO - Epoch(train)  [1][6300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 0:30:50  time: 1.9058  data_time: 0.0043  memory: 43290  loss: 0.9669  loss_rpn_cls: 0.0498  loss_rpn_bbox: 0.0510  loss_cls: 0.2625  acc: 92.4683  loss_bbox: 0.2962  loss_mask: 0.3075
2025/12/11 04:11:08 - mmengine - INFO - Epoch(train)  [1][6350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 0:26:33  time: 1.9053  data_time: 0.0048  memory: 42848  loss: 0.9615  loss_rpn_cls: 0.0495  loss_rpn_bbox: 0.0497  loss_cls: 0.2674  acc: 94.1895  loss_bbox: 0.2857  loss_mask: 0.3092
2025/12/11 04:12:45 - mmengine - INFO - Epoch(train)  [1][6400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 0:22:43  time: 1.9439  data_time: 0.0045  memory: 43003  loss: 1.0123  loss_rpn_cls: 0.0495  loss_rpn_bbox: 0.0535  loss_cls: 0.2876  acc: 93.5181  loss_bbox: 0.3154  loss_mask: 0.3064
2025/12/11 04:14:22 - mmengine - INFO - Epoch(train)  [1][6450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 0:18:53  time: 1.9410  data_time: 0.0049  memory: 42354  loss: 1.0072  loss_rpn_cls: 0.0509  loss_rpn_bbox: 0.0533  loss_cls: 0.2829  acc: 89.1357  loss_bbox: 0.3068  loss_mask: 0.3133
2025/12/11 04:15:57 - mmengine - INFO - Epoch(train)  [1][6500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 0:14:34  time: 1.8901  data_time: 0.0045  memory: 42087  loss: 0.9351  loss_rpn_cls: 0.0451  loss_rpn_bbox: 0.0466  loss_cls: 0.2531  acc: 92.6392  loss_bbox: 0.2879  loss_mask: 0.3023
2025/12/11 04:17:33 - mmengine - INFO - Epoch(train)  [1][6550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 0:10:46  time: 1.9367  data_time: 0.0045  memory: 43219  loss: 0.9625  loss_rpn_cls: 0.0485  loss_rpn_bbox: 0.0490  loss_cls: 0.2655  acc: 90.1978  loss_bbox: 0.2911  loss_mask: 0.3083
2025/12/11 04:19:15 - mmengine - INFO - Epoch(train)  [1][6600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 0:07:59  time: 2.0320  data_time: 0.0049  memory: 43113  loss: 0.9721  loss_rpn_cls: 0.0489  loss_rpn_bbox: 0.0491  loss_cls: 0.2706  acc: 92.9077  loss_bbox: 0.3003  loss_mask: 0.3032
2025/12/11 04:20:54 - mmengine - INFO - Epoch(train)  [1][6650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 0:04:44  time: 1.9864  data_time: 0.0055  memory: 45866  loss: 0.9976  loss_rpn_cls: 0.0533  loss_rpn_bbox: 0.0513  loss_cls: 0.2747  acc: 92.1875  loss_bbox: 0.3100  loss_mask: 0.3083
2025/12/11 04:22:34 - mmengine - INFO - Epoch(train)  [1][6700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 2 days, 0:01:32  time: 1.9862  data_time: 0.0052  memory: 43548  loss: 0.9633  loss_rpn_cls: 0.0458  loss_rpn_bbox: 0.0481  loss_cls: 0.2682  acc: 92.9443  loss_bbox: 0.2960  loss_mask: 0.3051
2025/12/11 04:24:15 - mmengine - INFO - Epoch(train)  [1][6750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 23:58:43  time: 2.0237  data_time: 0.0055  memory: 43393  loss: 0.9734  loss_rpn_cls: 0.0538  loss_rpn_bbox: 0.0531  loss_cls: 0.2622  acc: 93.6768  loss_bbox: 0.2948  loss_mask: 0.3095
2025/12/11 04:25:57 - mmengine - INFO - Epoch(train)  [1][6800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 23:56:02  time: 2.0351  data_time: 0.0056  memory: 44022  loss: 0.9661  loss_rpn_cls: 0.0530  loss_rpn_bbox: 0.0517  loss_cls: 0.2706  acc: 89.0503  loss_bbox: 0.2955  loss_mask: 0.2952
2025/12/11 04:27:45 - mmengine - INFO - Epoch(train)  [1][6850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 23:54:37  time: 2.1623  data_time: 0.0059  memory: 43089  loss: 0.9666  loss_rpn_cls: 0.0508  loss_rpn_bbox: 0.0504  loss_cls: 0.2633  acc: 92.9810  loss_bbox: 0.2968  loss_mask: 0.3053
2025/12/11 04:29:23 - mmengine - INFO - Epoch(train)  [1][6900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 23:51:21  time: 1.9753  data_time: 0.0053  memory: 44217  loss: 0.9702  loss_rpn_cls: 0.0559  loss_rpn_bbox: 0.0530  loss_cls: 0.2659  acc: 94.0063  loss_bbox: 0.2914  loss_mask: 0.3040
2025/12/11 04:31:02 - mmengine - INFO - Epoch(train)  [1][6950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 23:48:06  time: 1.9719  data_time: 0.0050  memory: 41423  loss: 0.9814  loss_rpn_cls: 0.0490  loss_rpn_bbox: 0.0493  loss_cls: 0.2743  acc: 87.7930  loss_bbox: 0.3011  loss_mask: 0.3077
2025/12/11 04:32:39 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 04:32:39 - mmengine - INFO - Epoch(train)  [1][7000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 23:44:28  time: 1.9319  data_time: 0.0046  memory: 42532  loss: 0.9584  loss_rpn_cls: 0.0539  loss_rpn_bbox: 0.0520  loss_cls: 0.2587  acc: 92.0166  loss_bbox: 0.2903  loss_mask: 0.3035
2025/12/11 04:34:18 - mmengine - INFO - Epoch(train)  [1][7050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 23:41:26  time: 1.9898  data_time: 0.0045  memory: 43640  loss: 0.9642  loss_rpn_cls: 0.0496  loss_rpn_bbox: 0.0482  loss_cls: 0.2671  acc: 90.9668  loss_bbox: 0.2952  loss_mask: 0.3041
2025/12/11 04:35:55 - mmengine - INFO - Epoch(train)  [1][7100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 23:37:50  time: 1.9289  data_time: 0.0045  memory: 43343  loss: 0.9690  loss_rpn_cls: 0.0540  loss_rpn_bbox: 0.0521  loss_cls: 0.2661  acc: 92.3340  loss_bbox: 0.2982  loss_mask: 0.2985
2025/12/11 04:37:32 - mmengine - INFO - Epoch(train)  [1][7150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 23:34:21  time: 1.9396  data_time: 0.0045  memory: 43317  loss: 0.9516  loss_rpn_cls: 0.0487  loss_rpn_bbox: 0.0487  loss_cls: 0.2633  acc: 92.1753  loss_bbox: 0.2880  loss_mask: 0.3030
2025/12/11 04:39:13 - mmengine - INFO - Epoch(train)  [1][7200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 23:31:42  time: 2.0239  data_time: 0.0045  memory: 43042  loss: 1.0049  loss_rpn_cls: 0.0521  loss_rpn_bbox: 0.0541  loss_cls: 0.2797  acc: 92.2729  loss_bbox: 0.3110  loss_mask: 0.3081
2025/12/11 04:40:48 - mmengine - INFO - Epoch(train)  [1][7250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 23:28:01  time: 1.9116  data_time: 0.0042  memory: 42702  loss: 0.9516  loss_rpn_cls: 0.0454  loss_rpn_bbox: 0.0479  loss_cls: 0.2639  acc: 91.7969  loss_bbox: 0.2926  loss_mask: 0.3017
2025/12/11 04:42:25 - mmengine - INFO - Epoch(train)  [1][7300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 23:24:32  time: 1.9317  data_time: 0.0045  memory: 43898  loss: 0.9736  loss_rpn_cls: 0.0494  loss_rpn_bbox: 0.0504  loss_cls: 0.2662  acc: 89.3555  loss_bbox: 0.2988  loss_mask: 0.3088
2025/12/11 04:43:22 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 04:43:22 - mmengine - INFO - Saving checkpoint at 1 epochs
2025/12/11 04:45:36 - mmengine - INFO - Epoch(val)  [1][ 50/313]    eta: 0:10:59  time: 2.5089  data_time: 0.1634  memory: 41935  
2025/12/11 04:47:27 - mmengine - INFO - Epoch(val)  [1][100/313]    eta: 0:08:22  time: 2.2105  data_time: 0.0016  memory: 8289  
2025/12/11 04:49:21 - mmengine - INFO - Epoch(val)  [1][150/313]    eta: 0:06:20  time: 2.2822  data_time: 0.0018  memory: 8289  
2025/12/11 04:51:11 - mmengine - INFO - Epoch(val)  [1][200/313]    eta: 0:04:19  time: 2.2012  data_time: 0.0015  memory: 8289  
2025/12/11 04:52:59 - mmengine - INFO - Epoch(val)  [1][250/313]    eta: 0:02:23  time: 2.1672  data_time: 0.0013  memory: 8289  
2025/12/11 04:54:48 - mmengine - INFO - Epoch(val)  [1][300/313]    eta: 0:00:29  time: 2.1830  data_time: 0.0013  memory: 8289  
2025/12/11 04:55:31 - mmengine - INFO - Evaluating bbox...
2025/12/11 04:56:12 - mmengine - INFO - bbox_mAP_copypaste: 0.303 0.522 0.319 0.181 0.333 0.394
2025/12/11 04:56:12 - mmengine - INFO - Evaluating segm...
2025/12/11 04:56:56 - mmengine - INFO - segm_mAP_copypaste: 0.288 0.496 0.298 0.132 0.316 0.427
2025/12/11 04:56:57 - mmengine - INFO - Epoch(val) [1][313/313]    coco/bbox_mAP: 0.3030  coco/bbox_mAP_50: 0.5220  coco/bbox_mAP_75: 0.3190  coco/bbox_mAP_s: 0.1810  coco/bbox_mAP_m: 0.3330  coco/bbox_mAP_l: 0.3940  coco/segm_mAP: 0.2880  coco/segm_mAP_50: 0.4960  coco/segm_mAP_75: 0.2980  coco/segm_mAP_s: 0.1320  coco/segm_mAP_m: 0.3160  coco/segm_mAP_l: 0.4270  data_time: 0.0273  time: 2.2525
2025/12/11 04:58:37 - mmengine - INFO - Epoch(train)  [2][  50/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 23:19:34  time: 1.9988  data_time: 0.0732  memory: 44057  loss: 0.9385  loss_rpn_cls: 0.0459  loss_rpn_bbox: 0.0507  loss_cls: 0.2536  acc: 94.2383  loss_bbox: 0.2926  loss_mask: 0.2956
2025/12/11 05:00:14 - mmengine - INFO - Epoch(train)  [2][ 100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 23:16:13  time: 1.9396  data_time: 0.0049  memory: 43040  loss: 0.9620  loss_rpn_cls: 0.0462  loss_rpn_bbox: 0.0490  loss_cls: 0.2625  acc: 90.7593  loss_bbox: 0.3017  loss_mask: 0.3026
2025/12/11 05:01:50 - mmengine - INFO - Epoch(train)  [2][ 150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 23:12:39  time: 1.9115  data_time: 0.0047  memory: 43627  loss: 0.9155  loss_rpn_cls: 0.0458  loss_rpn_bbox: 0.0477  loss_cls: 0.2400  acc: 93.1885  loss_bbox: 0.2870  loss_mask: 0.2950
2025/12/11 05:03:26 - mmengine - INFO - Epoch(train)  [2][ 200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 23:09:17  time: 1.9319  data_time: 0.0050  memory: 41747  loss: 0.9576  loss_rpn_cls: 0.0527  loss_rpn_bbox: 0.0482  loss_cls: 0.2627  acc: 93.3838  loss_bbox: 0.2977  loss_mask: 0.2963
2025/12/11 05:05:01 - mmengine - INFO - Epoch(train)  [2][ 250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 23:05:35  time: 1.8906  data_time: 0.0048  memory: 43319  loss: 0.9449  loss_rpn_cls: 0.0465  loss_rpn_bbox: 0.0486  loss_cls: 0.2560  acc: 93.2129  loss_bbox: 0.2949  loss_mask: 0.2990
2025/12/11 05:06:35 - mmengine - INFO - Epoch(train)  [2][ 300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 23:01:46  time: 1.8747  data_time: 0.0043  memory: 41721  loss: 0.9502  loss_rpn_cls: 0.0471  loss_rpn_bbox: 0.0491  loss_cls: 0.2612  acc: 91.6870  loss_bbox: 0.2945  loss_mask: 0.2983
2025/12/11 05:08:09 - mmengine - INFO - Epoch(train)  [2][ 350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 22:58:01  time: 1.8783  data_time: 0.0044  memory: 42252  loss: 0.9402  loss_rpn_cls: 0.0459  loss_rpn_bbox: 0.0498  loss_cls: 0.2529  acc: 90.3687  loss_bbox: 0.2875  loss_mask: 0.3042
2025/12/11 05:09:42 - mmengine - INFO - Epoch(train)  [2][ 400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 22:54:08  time: 1.8592  data_time: 0.0042  memory: 43551  loss: 0.9298  loss_rpn_cls: 0.0484  loss_rpn_bbox: 0.0505  loss_cls: 0.2525  acc: 93.6646  loss_bbox: 0.2831  loss_mask: 0.2953
2025/12/11 05:11:16 - mmengine - INFO - Epoch(train)  [2][ 450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 22:50:28  time: 1.8830  data_time: 0.0045  memory: 43480  loss: 0.9496  loss_rpn_cls: 0.0459  loss_rpn_bbox: 0.0474  loss_cls: 0.2628  acc: 92.0410  loss_bbox: 0.2962  loss_mask: 0.2972
2025/12/11 05:12:50 - mmengine - INFO - Epoch(train)  [2][ 500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 22:46:52  time: 1.8857  data_time: 0.0046  memory: 42161  loss: 0.9357  loss_rpn_cls: 0.0458  loss_rpn_bbox: 0.0472  loss_cls: 0.2548  acc: 92.1265  loss_bbox: 0.2935  loss_mask: 0.2943
2025/12/11 05:14:25 - mmengine - INFO - Epoch(train)  [2][ 550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 22:43:18  time: 1.8887  data_time: 0.0042  memory: 42587  loss: 0.9610  loss_rpn_cls: 0.0474  loss_rpn_bbox: 0.0499  loss_cls: 0.2625  acc: 92.6147  loss_bbox: 0.3009  loss_mask: 0.3003
2025/12/11 05:15:58 - mmengine - INFO - Epoch(train)  [2][ 600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 22:39:38  time: 1.8721  data_time: 0.0041  memory: 42303  loss: 0.9445  loss_rpn_cls: 0.0497  loss_rpn_bbox: 0.0529  loss_cls: 0.2559  acc: 91.2598  loss_bbox: 0.2931  loss_mask: 0.2929
2025/12/11 05:17:33 - mmengine - INFO - Epoch(train)  [2][ 650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 22:36:09  time: 1.8911  data_time: 0.0045  memory: 44500  loss: 0.9416  loss_rpn_cls: 0.0468  loss_rpn_bbox: 0.0475  loss_cls: 0.2524  acc: 90.9790  loss_bbox: 0.2901  loss_mask: 0.3049
2025/12/11 05:18:11 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 05:19:08 - mmengine - INFO - Epoch(train)  [2][ 700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 22:32:51  time: 1.9101  data_time: 0.0043  memory: 43238  loss: 0.9627  loss_rpn_cls: 0.0465  loss_rpn_bbox: 0.0512  loss_cls: 0.2627  acc: 92.8711  loss_bbox: 0.2997  loss_mask: 0.3025
2025/12/11 05:20:43 - mmengine - INFO - Epoch(train)  [2][ 750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 22:29:24  time: 1.8899  data_time: 0.0042  memory: 43799  loss: 0.9293  loss_rpn_cls: 0.0476  loss_rpn_bbox: 0.0493  loss_cls: 0.2482  acc: 91.5527  loss_bbox: 0.2889  loss_mask: 0.2953
2025/12/11 05:22:18 - mmengine - INFO - Epoch(train)  [2][ 800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 22:26:05  time: 1.9033  data_time: 0.0043  memory: 44722  loss: 0.9451  loss_rpn_cls: 0.0477  loss_rpn_bbox: 0.0520  loss_cls: 0.2585  acc: 91.3208  loss_bbox: 0.2915  loss_mask: 0.2954
2025/12/11 05:23:54 - mmengine - INFO - Epoch(train)  [2][ 850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 22:22:58  time: 1.9257  data_time: 0.0047  memory: 43633  loss: 0.9571  loss_rpn_cls: 0.0510  loss_rpn_bbox: 0.0527  loss_cls: 0.2593  acc: 89.9780  loss_bbox: 0.2941  loss_mask: 0.3000
2025/12/11 05:25:28 - mmengine - INFO - Epoch(train)  [2][ 900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 22:19:34  time: 1.8874  data_time: 0.0043  memory: 42091  loss: 0.9466  loss_rpn_cls: 0.0498  loss_rpn_bbox: 0.0490  loss_cls: 0.2592  acc: 90.3442  loss_bbox: 0.2907  loss_mask: 0.2980
2025/12/11 05:27:03 - mmengine - INFO - Epoch(train)  [2][ 950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 22:16:09  time: 1.8823  data_time: 0.0042  memory: 42844  loss: 0.9370  loss_rpn_cls: 0.0471  loss_rpn_bbox: 0.0477  loss_cls: 0.2538  acc: 92.2485  loss_bbox: 0.2920  loss_mask: 0.2964
2025/12/11 05:28:37 - mmengine - INFO - Epoch(train)  [2][1000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 22:12:51  time: 1.8965  data_time: 0.0045  memory: 43860  loss: 0.9386  loss_rpn_cls: 0.0437  loss_rpn_bbox: 0.0477  loss_cls: 0.2627  acc: 88.0981  loss_bbox: 0.2910  loss_mask: 0.2934
2025/12/11 05:30:12 - mmengine - INFO - Epoch(train)  [2][1050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 22:09:31  time: 1.8869  data_time: 0.0044  memory: 44136  loss: 0.9627  loss_rpn_cls: 0.0483  loss_rpn_bbox: 0.0518  loss_cls: 0.2640  acc: 92.2363  loss_bbox: 0.2997  loss_mask: 0.2989
2025/12/11 05:31:47 - mmengine - INFO - Epoch(train)  [2][1100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 22:06:21  time: 1.9075  data_time: 0.0044  memory: 45414  loss: 0.9642  loss_rpn_cls: 0.0483  loss_rpn_bbox: 0.0517  loss_cls: 0.2669  acc: 92.1875  loss_bbox: 0.2984  loss_mask: 0.2990
2025/12/11 05:33:22 - mmengine - INFO - Epoch(train)  [2][1150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 22:03:05  time: 1.8904  data_time: 0.0044  memory: 42700  loss: 0.9516  loss_rpn_cls: 0.0479  loss_rpn_bbox: 0.0503  loss_cls: 0.2641  acc: 93.5669  loss_bbox: 0.2920  loss_mask: 0.2972
2025/12/11 05:34:55 - mmengine - INFO - Epoch(train)  [2][1200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 21:59:40  time: 1.8714  data_time: 0.0043  memory: 43264  loss: 0.9405  loss_rpn_cls: 0.0468  loss_rpn_bbox: 0.0473  loss_cls: 0.2607  acc: 90.8691  loss_bbox: 0.2868  loss_mask: 0.2989
2025/12/11 05:36:30 - mmengine - INFO - Epoch(train)  [2][1250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 21:56:25  time: 1.8873  data_time: 0.0043  memory: 43578  loss: 0.9308  loss_rpn_cls: 0.0464  loss_rpn_bbox: 0.0480  loss_cls: 0.2509  acc: 91.1499  loss_bbox: 0.2867  loss_mask: 0.2989
2025/12/11 05:38:04 - mmengine - INFO - Epoch(train)  [2][1300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 21:53:15  time: 1.8961  data_time: 0.0041  memory: 42993  loss: 0.9337  loss_rpn_cls: 0.0481  loss_rpn_bbox: 0.0486  loss_cls: 0.2567  acc: 91.8579  loss_bbox: 0.2862  loss_mask: 0.2940
2025/12/11 05:39:40 - mmengine - INFO - Epoch(train)  [2][1350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 21:50:11  time: 1.9077  data_time: 0.0043  memory: 42784  loss: 0.9773  loss_rpn_cls: 0.0495  loss_rpn_bbox: 0.0533  loss_cls: 0.2684  acc: 88.6963  loss_bbox: 0.3066  loss_mask: 0.2994
2025/12/11 05:41:14 - mmengine - INFO - Epoch(train)  [2][1400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 21:47:01  time: 1.8931  data_time: 0.0044  memory: 42211  loss: 0.9371  loss_rpn_cls: 0.0480  loss_rpn_bbox: 0.0498  loss_cls: 0.2567  acc: 92.1143  loss_bbox: 0.2896  loss_mask: 0.2930
2025/12/11 05:42:49 - mmengine - INFO - Epoch(train)  [2][1450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 21:43:54  time: 1.8954  data_time: 0.0043  memory: 43934  loss: 0.9231  loss_rpn_cls: 0.0475  loss_rpn_bbox: 0.0484  loss_cls: 0.2553  acc: 88.9404  loss_bbox: 0.2837  loss_mask: 0.2882
2025/12/11 05:44:25 - mmengine - INFO - Epoch(train)  [2][1500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 21:40:58  time: 1.9196  data_time: 0.0046  memory: 43762  loss: 0.9304  loss_rpn_cls: 0.0463  loss_rpn_bbox: 0.0479  loss_cls: 0.2542  acc: 91.0156  loss_bbox: 0.2873  loss_mask: 0.2947
2025/12/11 05:45:59 - mmengine - INFO - Epoch(train)  [2][1550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 21:37:40  time: 1.8666  data_time: 0.0043  memory: 42714  loss: 0.9532  loss_rpn_cls: 0.0490  loss_rpn_bbox: 0.0497  loss_cls: 0.2640  acc: 90.0513  loss_bbox: 0.2938  loss_mask: 0.2967
2025/12/11 05:47:33 - mmengine - INFO - Epoch(train)  [2][1600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 21:34:34  time: 1.8918  data_time: 0.0043  memory: 43234  loss: 0.9236  loss_rpn_cls: 0.0418  loss_rpn_bbox: 0.0469  loss_cls: 0.2544  acc: 90.9790  loss_bbox: 0.2843  loss_mask: 0.2962
2025/12/11 05:49:10 - mmengine - INFO - Epoch(train)  [2][1650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 21:31:51  time: 1.9412  data_time: 0.0097  memory: 42720  loss: 0.9350  loss_rpn_cls: 0.0479  loss_rpn_bbox: 0.0487  loss_cls: 0.2566  acc: 93.8477  loss_bbox: 0.2860  loss_mask: 0.2958
2025/12/11 05:49:49 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 05:50:46 - mmengine - INFO - Epoch(train)  [2][1700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 21:28:56  time: 1.9119  data_time: 0.0044  memory: 43474  loss: 0.9423  loss_rpn_cls: 0.0474  loss_rpn_bbox: 0.0503  loss_cls: 0.2567  acc: 92.1753  loss_bbox: 0.2916  loss_mask: 0.2962
2025/12/11 05:52:21 - mmengine - INFO - Epoch(train)  [2][1750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 21:25:55  time: 1.8956  data_time: 0.0044  memory: 45456  loss: 0.9423  loss_rpn_cls: 0.0477  loss_rpn_bbox: 0.0496  loss_cls: 0.2606  acc: 93.9819  loss_bbox: 0.2924  loss_mask: 0.2919
2025/12/11 05:53:56 - mmengine - INFO - Epoch(train)  [2][1800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 21:22:57  time: 1.9033  data_time: 0.0046  memory: 42005  loss: 0.9624  loss_rpn_cls: 0.0513  loss_rpn_bbox: 0.0510  loss_cls: 0.2674  acc: 92.3584  loss_bbox: 0.2934  loss_mask: 0.2993
2025/12/11 05:55:30 - mmengine - INFO - Epoch(train)  [2][1850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 21:19:56  time: 1.8917  data_time: 0.0043  memory: 42935  loss: 0.9236  loss_rpn_cls: 0.0479  loss_rpn_bbox: 0.0491  loss_cls: 0.2504  acc: 94.3237  loss_bbox: 0.2826  loss_mask: 0.2936
2025/12/11 05:57:05 - mmengine - INFO - Epoch(train)  [2][1900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 21:16:59  time: 1.8996  data_time: 0.0044  memory: 42155  loss: 0.9210  loss_rpn_cls: 0.0453  loss_rpn_bbox: 0.0481  loss_cls: 0.2515  acc: 93.2251  loss_bbox: 0.2857  loss_mask: 0.2903
2025/12/11 05:58:41 - mmengine - INFO - Epoch(train)  [2][1950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 21:14:06  time: 1.9068  data_time: 0.0046  memory: 42616  loss: 0.9581  loss_rpn_cls: 0.0484  loss_rpn_bbox: 0.0532  loss_cls: 0.2626  acc: 91.9312  loss_bbox: 0.2958  loss_mask: 0.2982
2025/12/11 06:00:16 - mmengine - INFO - Epoch(train)  [2][2000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 21:11:14  time: 1.9069  data_time: 0.0044  memory: 42172  loss: 0.9373  loss_rpn_cls: 0.0446  loss_rpn_bbox: 0.0486  loss_cls: 0.2554  acc: 93.2983  loss_bbox: 0.2929  loss_mask: 0.2958
2025/12/11 06:01:53 - mmengine - INFO - Epoch(train)  [2][2050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 21:08:41  time: 1.9491  data_time: 0.0049  memory: 41949  loss: 0.9379  loss_rpn_cls: 0.0443  loss_rpn_bbox: 0.0485  loss_cls: 0.2583  acc: 88.8184  loss_bbox: 0.2953  loss_mask: 0.2914
2025/12/11 06:03:27 - mmengine - INFO - Epoch(train)  [2][2100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 21:05:37  time: 1.8760  data_time: 0.0043  memory: 41309  loss: 0.9358  loss_rpn_cls: 0.0479  loss_rpn_bbox: 0.0485  loss_cls: 0.2577  acc: 91.1133  loss_bbox: 0.2914  loss_mask: 0.2904
2025/12/11 06:05:02 - mmengine - INFO - Epoch(train)  [2][2150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 21:02:45  time: 1.9002  data_time: 0.0045  memory: 43032  loss: 0.9381  loss_rpn_cls: 0.0454  loss_rpn_bbox: 0.0490  loss_cls: 0.2579  acc: 92.9199  loss_bbox: 0.2927  loss_mask: 0.2931
2025/12/11 06:06:39 - mmengine - INFO - Epoch(train)  [2][2200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 21:00:04  time: 1.9270  data_time: 0.0046  memory: 43186  loss: 0.9618  loss_rpn_cls: 0.0484  loss_rpn_bbox: 0.0507  loss_cls: 0.2674  acc: 91.2842  loss_bbox: 0.2996  loss_mask: 0.2957
2025/12/11 06:08:13 - mmengine - INFO - Epoch(train)  [2][2250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 20:57:07  time: 1.8859  data_time: 0.0043  memory: 43641  loss: 0.9255  loss_rpn_cls: 0.0464  loss_rpn_bbox: 0.0491  loss_cls: 0.2526  acc: 91.4307  loss_bbox: 0.2855  loss_mask: 0.2919
2025/12/11 06:09:48 - mmengine - INFO - Epoch(train)  [2][2300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 20:54:17  time: 1.8986  data_time: 0.0046  memory: 42081  loss: 0.9125  loss_rpn_cls: 0.0459  loss_rpn_bbox: 0.0493  loss_cls: 0.2452  acc: 91.8457  loss_bbox: 0.2807  loss_mask: 0.2913
2025/12/11 06:11:23 - mmengine - INFO - Epoch(train)  [2][2350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 20:51:28  time: 1.9019  data_time: 0.0045  memory: 43926  loss: 0.9348  loss_rpn_cls: 0.0458  loss_rpn_bbox: 0.0476  loss_cls: 0.2572  acc: 92.9077  loss_bbox: 0.2907  loss_mask: 0.2936
2025/12/11 06:12:57 - mmengine - INFO - Epoch(train)  [2][2400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 20:48:28  time: 1.8722  data_time: 0.0044  memory: 41928  loss: 0.9124  loss_rpn_cls: 0.0475  loss_rpn_bbox: 0.0460  loss_cls: 0.2544  acc: 92.8955  loss_bbox: 0.2788  loss_mask: 0.2857
2025/12/11 06:14:31 - mmengine - INFO - Epoch(train)  [2][2450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 20:45:37  time: 1.8920  data_time: 0.0044  memory: 44419  loss: 0.9099  loss_rpn_cls: 0.0466  loss_rpn_bbox: 0.0473  loss_cls: 0.2483  acc: 92.3218  loss_bbox: 0.2828  loss_mask: 0.2847
2025/12/11 06:16:05 - mmengine - INFO - Epoch(train)  [2][2500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 20:42:44  time: 1.8845  data_time: 0.0047  memory: 44237  loss: 0.8935  loss_rpn_cls: 0.0409  loss_rpn_bbox: 0.0450  loss_cls: 0.2433  acc: 91.3940  loss_bbox: 0.2793  loss_mask: 0.2849
2025/12/11 06:17:40 - mmengine - INFO - Epoch(train)  [2][2550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 20:39:53  time: 1.8900  data_time: 0.0047  memory: 42704  loss: 0.9485  loss_rpn_cls: 0.0493  loss_rpn_bbox: 0.0512  loss_cls: 0.2636  acc: 93.2373  loss_bbox: 0.2911  loss_mask: 0.2933
2025/12/11 06:19:15 - mmengine - INFO - Epoch(train)  [2][2600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 20:37:06  time: 1.8961  data_time: 0.0044  memory: 44297  loss: 0.9045  loss_rpn_cls: 0.0455  loss_rpn_bbox: 0.0489  loss_cls: 0.2476  acc: 92.9321  loss_bbox: 0.2802  loss_mask: 0.2824
2025/12/11 06:20:49 - mmengine - INFO - Epoch(train)  [2][2650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 20:34:17  time: 1.8883  data_time: 0.0041  memory: 43214  loss: 0.9552  loss_rpn_cls: 0.0471  loss_rpn_bbox: 0.0499  loss_cls: 0.2616  acc: 91.5161  loss_bbox: 0.3030  loss_mask: 0.2936
2025/12/11 06:21:26 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 06:22:23 - mmengine - INFO - Epoch(train)  [2][2700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 20:31:20  time: 1.8681  data_time: 0.0044  memory: 43795  loss: 0.8956  loss_rpn_cls: 0.0456  loss_rpn_bbox: 0.0487  loss_cls: 0.2398  acc: 91.5283  loss_bbox: 0.2750  loss_mask: 0.2866
2025/12/11 06:23:57 - mmengine - INFO - Epoch(train)  [2][2750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 20:28:34  time: 1.8915  data_time: 0.0045  memory: 44388  loss: 0.9376  loss_rpn_cls: 0.0479  loss_rpn_bbox: 0.0510  loss_cls: 0.2533  acc: 92.2363  loss_bbox: 0.2831  loss_mask: 0.3024
2025/12/11 06:25:31 - mmengine - INFO - Epoch(train)  [2][2800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 20:25:42  time: 1.8753  data_time: 0.0043  memory: 44047  loss: 0.9239  loss_rpn_cls: 0.0480  loss_rpn_bbox: 0.0496  loss_cls: 0.2509  acc: 90.5640  loss_bbox: 0.2876  loss_mask: 0.2878
2025/12/11 06:27:04 - mmengine - INFO - Epoch(train)  [2][2850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 20:22:48  time: 1.8684  data_time: 0.0044  memory: 42486  loss: 0.8919  loss_rpn_cls: 0.0417  loss_rpn_bbox: 0.0466  loss_cls: 0.2454  acc: 92.0288  loss_bbox: 0.2737  loss_mask: 0.2845
2025/12/11 06:28:38 - mmengine - INFO - Epoch(train)  [2][2900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 20:19:59  time: 1.8814  data_time: 0.0043  memory: 41288  loss: 0.9254  loss_rpn_cls: 0.0452  loss_rpn_bbox: 0.0477  loss_cls: 0.2514  acc: 91.6260  loss_bbox: 0.2857  loss_mask: 0.2954
2025/12/11 06:30:13 - mmengine - INFO - Epoch(train)  [2][2950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 20:17:18  time: 1.8990  data_time: 0.0066  memory: 43366  loss: 0.9197  loss_rpn_cls: 0.0429  loss_rpn_bbox: 0.0484  loss_cls: 0.2476  acc: 94.7510  loss_bbox: 0.2861  loss_mask: 0.2947
2025/12/11 06:31:48 - mmengine - INFO - Epoch(train)  [2][3000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 20:14:35  time: 1.8923  data_time: 0.0044  memory: 41639  loss: 0.9175  loss_rpn_cls: 0.0439  loss_rpn_bbox: 0.0479  loss_cls: 0.2512  acc: 91.4917  loss_bbox: 0.2866  loss_mask: 0.2880
2025/12/11 06:33:23 - mmengine - INFO - Epoch(train)  [2][3050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 20:11:55  time: 1.8963  data_time: 0.0044  memory: 43755  loss: 0.9219  loss_rpn_cls: 0.0475  loss_rpn_bbox: 0.0498  loss_cls: 0.2549  acc: 91.0278  loss_bbox: 0.2879  loss_mask: 0.2817
2025/12/11 06:34:56 - mmengine - INFO - Epoch(train)  [2][3100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 20:09:04  time: 1.8664  data_time: 0.0044  memory: 41364  loss: 0.8976  loss_rpn_cls: 0.0421  loss_rpn_bbox: 0.0476  loss_cls: 0.2447  acc: 89.7705  loss_bbox: 0.2798  loss_mask: 0.2834
2025/12/11 06:36:31 - mmengine - INFO - Epoch(train)  [2][3150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 20:06:22  time: 1.8903  data_time: 0.0042  memory: 41941  loss: 0.9176  loss_rpn_cls: 0.0459  loss_rpn_bbox: 0.0495  loss_cls: 0.2517  acc: 91.4673  loss_bbox: 0.2798  loss_mask: 0.2907
2025/12/11 06:38:04 - mmengine - INFO - Epoch(train)  [2][3200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 20:03:32  time: 1.8645  data_time: 0.0041  memory: 42701  loss: 0.8991  loss_rpn_cls: 0.0462  loss_rpn_bbox: 0.0466  loss_cls: 0.2422  acc: 91.8091  loss_bbox: 0.2786  loss_mask: 0.2856
2025/12/11 06:39:38 - mmengine - INFO - Epoch(train)  [2][3250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 20:00:52  time: 1.8919  data_time: 0.0047  memory: 42749  loss: 0.9384  loss_rpn_cls: 0.0469  loss_rpn_bbox: 0.0497  loss_cls: 0.2613  acc: 89.7949  loss_bbox: 0.2871  loss_mask: 0.2934
2025/12/11 06:41:12 - mmengine - INFO - Epoch(train)  [2][3300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:58:06  time: 1.8725  data_time: 0.0045  memory: 41560  loss: 0.8987  loss_rpn_cls: 0.0432  loss_rpn_bbox: 0.0459  loss_cls: 0.2453  acc: 93.4082  loss_bbox: 0.2789  loss_mask: 0.2854
2025/12/11 06:42:49 - mmengine - INFO - Epoch(train)  [2][3350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:55:48  time: 1.9475  data_time: 0.0050  memory: 41387  loss: 0.9286  loss_rpn_cls: 0.0473  loss_rpn_bbox: 0.0512  loss_cls: 0.2524  acc: 92.1021  loss_bbox: 0.2874  loss_mask: 0.2903
2025/12/11 06:44:28 - mmengine - INFO - Epoch(train)  [2][3400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:53:38  time: 1.9699  data_time: 0.0051  memory: 44463  loss: 0.9105  loss_rpn_cls: 0.0461  loss_rpn_bbox: 0.0475  loss_cls: 0.2468  acc: 92.0166  loss_bbox: 0.2795  loss_mask: 0.2906
2025/12/11 06:46:06 - mmengine - INFO - Epoch(train)  [2][3450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:51:25  time: 1.9607  data_time: 0.0050  memory: 42368  loss: 0.9217  loss_rpn_cls: 0.0454  loss_rpn_bbox: 0.0500  loss_cls: 0.2504  acc: 93.6646  loss_bbox: 0.2835  loss_mask: 0.2925
2025/12/11 06:47:42 - mmengine - INFO - Epoch(train)  [2][3500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:48:59  time: 1.9240  data_time: 0.0048  memory: 44260  loss: 0.8779  loss_rpn_cls: 0.0426  loss_rpn_bbox: 0.0430  loss_cls: 0.2374  acc: 90.8081  loss_bbox: 0.2735  loss_mask: 0.2813
2025/12/11 06:49:17 - mmengine - INFO - Epoch(train)  [2][3550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:46:27  time: 1.9045  data_time: 0.0048  memory: 41657  loss: 0.9106  loss_rpn_cls: 0.0448  loss_rpn_bbox: 0.0468  loss_cls: 0.2502  acc: 93.6157  loss_bbox: 0.2865  loss_mask: 0.2824
2025/12/11 06:50:52 - mmengine - INFO - Epoch(train)  [2][3600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:43:52  time: 1.8950  data_time: 0.0045  memory: 42357  loss: 0.8948  loss_rpn_cls: 0.0442  loss_rpn_bbox: 0.0457  loss_cls: 0.2452  acc: 91.6504  loss_bbox: 0.2779  loss_mask: 0.2819
2025/12/11 06:52:31 - mmengine - INFO - Epoch(train)  [2][3650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:41:45  time: 1.9732  data_time: 0.0050  memory: 42910  loss: 0.9168  loss_rpn_cls: 0.0427  loss_rpn_bbox: 0.0470  loss_cls: 0.2502  acc: 93.7744  loss_bbox: 0.2866  loss_mask: 0.2903
2025/12/11 06:53:10 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 06:54:07 - mmengine - INFO - Epoch(train)  [2][3700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:39:24  time: 1.9313  data_time: 0.0048  memory: 43937  loss: 0.8977  loss_rpn_cls: 0.0459  loss_rpn_bbox: 0.0474  loss_cls: 0.2444  acc: 87.9883  loss_bbox: 0.2771  loss_mask: 0.2828
2025/12/11 06:55:44 - mmengine - INFO - Epoch(train)  [2][3750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:37:03  time: 1.9310  data_time: 0.0048  memory: 43881  loss: 0.8837  loss_rpn_cls: 0.0432  loss_rpn_bbox: 0.0449  loss_cls: 0.2393  acc: 91.4917  loss_bbox: 0.2723  loss_mask: 0.2840
2025/12/11 06:57:24 - mmengine - INFO - Epoch(train)  [2][3800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:35:08  time: 2.0048  data_time: 0.0053  memory: 43349  loss: 0.9023  loss_rpn_cls: 0.0440  loss_rpn_bbox: 0.0474  loss_cls: 0.2430  acc: 90.7349  loss_bbox: 0.2829  loss_mask: 0.2850
2025/12/11 06:59:00 - mmengine - INFO - Epoch(train)  [2][3850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:32:45  time: 1.9246  data_time: 0.0050  memory: 43894  loss: 0.9042  loss_rpn_cls: 0.0442  loss_rpn_bbox: 0.0462  loss_cls: 0.2516  acc: 89.7705  loss_bbox: 0.2769  loss_mask: 0.2853
2025/12/11 07:00:36 - mmengine - INFO - Epoch(train)  [2][3900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:30:18  time: 1.9091  data_time: 0.0047  memory: 42125  loss: 0.9192  loss_rpn_cls: 0.0427  loss_rpn_bbox: 0.0491  loss_cls: 0.2506  acc: 92.0532  loss_bbox: 0.2848  loss_mask: 0.2921
2025/12/11 07:02:13 - mmengine - INFO - Epoch(train)  [2][3950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:28:02  time: 1.9414  data_time: 0.0051  memory: 42643  loss: 0.9199  loss_rpn_cls: 0.0471  loss_rpn_bbox: 0.0475  loss_cls: 0.2520  acc: 94.3359  loss_bbox: 0.2864  loss_mask: 0.2869
2025/12/11 07:03:48 - mmengine - INFO - Epoch(train)  [2][4000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:25:35  time: 1.9089  data_time: 0.0046  memory: 41936  loss: 0.9482  loss_rpn_cls: 0.0489  loss_rpn_bbox: 0.0506  loss_cls: 0.2584  acc: 89.9902  loss_bbox: 0.2990  loss_mask: 0.2914
2025/12/11 07:05:24 - mmengine - INFO - Epoch(train)  [2][4050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:23:12  time: 1.9166  data_time: 0.0045  memory: 42998  loss: 0.8816  loss_rpn_cls: 0.0472  loss_rpn_bbox: 0.0473  loss_cls: 0.2347  acc: 90.2954  loss_bbox: 0.2662  loss_mask: 0.2863
2025/12/11 07:07:00 - mmengine - INFO - Epoch(train)  [2][4100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:20:51  time: 1.9231  data_time: 0.0043  memory: 43188  loss: 0.9154  loss_rpn_cls: 0.0476  loss_rpn_bbox: 0.0490  loss_cls: 0.2458  acc: 93.2739  loss_bbox: 0.2859  loss_mask: 0.2871
2025/12/11 07:08:37 - mmengine - INFO - Epoch(train)  [2][4150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:18:35  time: 1.9380  data_time: 0.0050  memory: 41919  loss: 0.9224  loss_rpn_cls: 0.0443  loss_rpn_bbox: 0.0473  loss_cls: 0.2557  acc: 89.9658  loss_bbox: 0.2882  loss_mask: 0.2868
2025/12/11 07:10:15 - mmengine - INFO - Epoch(train)  [2][4200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:16:25  time: 1.9528  data_time: 0.0046  memory: 44089  loss: 0.9278  loss_rpn_cls: 0.0452  loss_rpn_bbox: 0.0486  loss_cls: 0.2543  acc: 90.5029  loss_bbox: 0.2918  loss_mask: 0.2879
2025/12/11 07:11:53 - mmengine - INFO - Epoch(train)  [2][4250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:14:15  time: 1.9542  data_time: 0.0054  memory: 42795  loss: 0.9013  loss_rpn_cls: 0.0441  loss_rpn_bbox: 0.0475  loss_cls: 0.2469  acc: 91.4185  loss_bbox: 0.2784  loss_mask: 0.2843
2025/12/11 07:13:31 - mmengine - INFO - Epoch(train)  [2][4300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:12:07  time: 1.9581  data_time: 0.0057  memory: 42403  loss: 0.9108  loss_rpn_cls: 0.0447  loss_rpn_bbox: 0.0471  loss_cls: 0.2483  acc: 94.5801  loss_bbox: 0.2822  loss_mask: 0.2886
2025/12/11 07:15:07 - mmengine - INFO - Epoch(train)  [2][4350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:09:52  time: 1.9357  data_time: 0.0047  memory: 42827  loss: 0.9174  loss_rpn_cls: 0.0426  loss_rpn_bbox: 0.0476  loss_cls: 0.2531  acc: 90.8203  loss_bbox: 0.2871  loss_mask: 0.2871
2025/12/11 07:16:42 - mmengine - INFO - Epoch(train)  [2][4400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:07:22  time: 1.8903  data_time: 0.0046  memory: 43121  loss: 0.9146  loss_rpn_cls: 0.0449  loss_rpn_bbox: 0.0471  loss_cls: 0.2514  acc: 92.3706  loss_bbox: 0.2823  loss_mask: 0.2889
2025/12/11 07:18:19 - mmengine - INFO - Epoch(train)  [2][4450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:05:12  time: 1.9490  data_time: 0.0049  memory: 42841  loss: 0.9443  loss_rpn_cls: 0.0508  loss_rpn_bbox: 0.0503  loss_cls: 0.2584  acc: 92.3706  loss_bbox: 0.2917  loss_mask: 0.2930
2025/12/11 07:19:56 - mmengine - INFO - Epoch(train)  [2][4500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:02:58  time: 1.9336  data_time: 0.0049  memory: 42990  loss: 0.8824  loss_rpn_cls: 0.0422  loss_rpn_bbox: 0.0449  loss_cls: 0.2388  acc: 93.1519  loss_bbox: 0.2702  loss_mask: 0.2863
2025/12/11 07:21:31 - mmengine - INFO - Epoch(train)  [2][4550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 19:00:33  time: 1.9027  data_time: 0.0047  memory: 42061  loss: 0.8738  loss_rpn_cls: 0.0416  loss_rpn_bbox: 0.0460  loss_cls: 0.2332  acc: 92.4438  loss_bbox: 0.2712  loss_mask: 0.2819
2025/12/11 07:23:11 - mmengine - INFO - Epoch(train)  [2][4600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:58:40  time: 1.9981  data_time: 0.0057  memory: 42563  loss: 0.8920  loss_rpn_cls: 0.0418  loss_rpn_bbox: 0.0469  loss_cls: 0.2429  acc: 94.5435  loss_bbox: 0.2751  loss_mask: 0.2853
2025/12/11 07:24:47 - mmengine - INFO - Epoch(train)  [2][4650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:56:24  time: 1.9278  data_time: 0.0045  memory: 41568  loss: 0.8988  loss_rpn_cls: 0.0434  loss_rpn_bbox: 0.0496  loss_cls: 0.2458  acc: 91.0889  loss_bbox: 0.2746  loss_mask: 0.2854
2025/12/11 07:25:26 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 07:26:24 - mmengine - INFO - Epoch(train)  [2][4700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:54:08  time: 1.9258  data_time: 0.0048  memory: 42481  loss: 0.8786  loss_rpn_cls: 0.0421  loss_rpn_bbox: 0.0463  loss_cls: 0.2340  acc: 93.6523  loss_bbox: 0.2736  loss_mask: 0.2827
2025/12/11 07:28:01 - mmengine - INFO - Epoch(train)  [2][4750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:52:01  time: 1.9534  data_time: 0.0052  memory: 43562  loss: 0.9218  loss_rpn_cls: 0.0475  loss_rpn_bbox: 0.0499  loss_cls: 0.2526  acc: 94.1406  loss_bbox: 0.2830  loss_mask: 0.2887
2025/12/11 07:29:39 - mmengine - INFO - Epoch(train)  [2][4800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:49:52  time: 1.9472  data_time: 0.0050  memory: 41914  loss: 0.9067  loss_rpn_cls: 0.0455  loss_rpn_bbox: 0.0497  loss_cls: 0.2478  acc: 91.9434  loss_bbox: 0.2798  loss_mask: 0.2839
2025/12/11 07:31:16 - mmengine - INFO - Epoch(train)  [2][4850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:47:43  time: 1.9451  data_time: 0.0049  memory: 42597  loss: 0.9028  loss_rpn_cls: 0.0413  loss_rpn_bbox: 0.0464  loss_cls: 0.2507  acc: 93.8721  loss_bbox: 0.2803  loss_mask: 0.2842
2025/12/11 07:32:55 - mmengine - INFO - Epoch(train)  [2][4900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:45:42  time: 1.9704  data_time: 0.0054  memory: 43434  loss: 0.9119  loss_rpn_cls: 0.0469  loss_rpn_bbox: 0.0517  loss_cls: 0.2545  acc: 91.4551  loss_bbox: 0.2843  loss_mask: 0.2744
2025/12/11 07:34:32 - mmengine - INFO - Epoch(train)  [2][4950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:43:33  time: 1.9454  data_time: 0.0052  memory: 42242  loss: 0.8942  loss_rpn_cls: 0.0448  loss_rpn_bbox: 0.0479  loss_cls: 0.2435  acc: 93.2739  loss_bbox: 0.2736  loss_mask: 0.2844
2025/12/11 07:36:13 - mmengine - INFO - Epoch(train)  [2][5000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:41:46  time: 2.0151  data_time: 0.0058  memory: 43934  loss: 0.9073  loss_rpn_cls: 0.0437  loss_rpn_bbox: 0.0449  loss_cls: 0.2509  acc: 90.3809  loss_bbox: 0.2805  loss_mask: 0.2872
2025/12/11 07:37:48 - mmengine - INFO - Epoch(train)  [2][5050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:39:29  time: 1.9138  data_time: 0.0045  memory: 41506  loss: 0.9206  loss_rpn_cls: 0.0458  loss_rpn_bbox: 0.0480  loss_cls: 0.2535  acc: 92.3584  loss_bbox: 0.2835  loss_mask: 0.2899
2025/12/11 07:39:24 - mmengine - INFO - Epoch(train)  [2][5100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:37:11  time: 1.9141  data_time: 0.0045  memory: 43388  loss: 0.9115  loss_rpn_cls: 0.0450  loss_rpn_bbox: 0.0480  loss_cls: 0.2486  acc: 91.8579  loss_bbox: 0.2864  loss_mask: 0.2836
2025/12/11 07:41:04 - mmengine - INFO - Epoch(train)  [2][5150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:35:19  time: 1.9952  data_time: 0.0053  memory: 42865  loss: 0.8977  loss_rpn_cls: 0.0429  loss_rpn_bbox: 0.0477  loss_cls: 0.2431  acc: 89.7949  loss_bbox: 0.2795  loss_mask: 0.2844
2025/12/11 07:42:41 - mmengine - INFO - Epoch(train)  [2][5200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:33:12  time: 1.9484  data_time: 0.0053  memory: 42282  loss: 0.9155  loss_rpn_cls: 0.0460  loss_rpn_bbox: 0.0492  loss_cls: 0.2482  acc: 93.7988  loss_bbox: 0.2864  loss_mask: 0.2857
2025/12/11 07:44:18 - mmengine - INFO - Epoch(train)  [2][5250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:31:01  time: 1.9306  data_time: 0.0047  memory: 42976  loss: 0.9171  loss_rpn_cls: 0.0460  loss_rpn_bbox: 0.0472  loss_cls: 0.2516  acc: 94.3359  loss_bbox: 0.2874  loss_mask: 0.2850
2025/12/11 07:45:55 - mmengine - INFO - Epoch(train)  [2][5300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:28:56  time: 1.9532  data_time: 0.0052  memory: 44246  loss: 0.9003  loss_rpn_cls: 0.0462  loss_rpn_bbox: 0.0487  loss_cls: 0.2464  acc: 90.0024  loss_bbox: 0.2771  loss_mask: 0.2818
2025/12/11 07:47:32 - mmengine - INFO - Epoch(train)  [2][5350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:26:48  time: 1.9414  data_time: 0.0050  memory: 42317  loss: 0.8902  loss_rpn_cls: 0.0429  loss_rpn_bbox: 0.0468  loss_cls: 0.2421  acc: 89.8560  loss_bbox: 0.2742  loss_mask: 0.2842
2025/12/11 07:49:08 - mmengine - INFO - Epoch(train)  [2][5400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:24:31  time: 1.9100  data_time: 0.0045  memory: 41797  loss: 0.9002  loss_rpn_cls: 0.0433  loss_rpn_bbox: 0.0470  loss_cls: 0.2441  acc: 93.0176  loss_bbox: 0.2818  loss_mask: 0.2840
2025/12/11 07:50:46 - mmengine - INFO - Epoch(train)  [2][5450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:22:30  time: 1.9614  data_time: 0.0082  memory: 43512  loss: 0.9059  loss_rpn_cls: 0.0455  loss_rpn_bbox: 0.0481  loss_cls: 0.2477  acc: 90.0879  loss_bbox: 0.2768  loss_mask: 0.2878
2025/12/11 07:52:29 - mmengine - INFO - Epoch(train)  [2][5500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:20:58  time: 2.0628  data_time: 0.0067  memory: 42450  loss: 0.8998  loss_rpn_cls: 0.0433  loss_rpn_bbox: 0.0452  loss_cls: 0.2527  acc: 94.4336  loss_bbox: 0.2759  loss_mask: 0.2826
2025/12/11 07:54:07 - mmengine - INFO - Epoch(train)  [2][5550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:18:57  time: 1.9617  data_time: 0.0053  memory: 41954  loss: 0.9436  loss_rpn_cls: 0.0482  loss_rpn_bbox: 0.0510  loss_cls: 0.2566  acc: 92.9810  loss_bbox: 0.2955  loss_mask: 0.2923
2025/12/11 07:55:44 - mmengine - INFO - Epoch(train)  [2][5600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:16:50  time: 1.9421  data_time: 0.0049  memory: 43135  loss: 0.9231  loss_rpn_cls: 0.0475  loss_rpn_bbox: 0.0512  loss_cls: 0.2507  acc: 90.9668  loss_bbox: 0.2876  loss_mask: 0.2860
2025/12/11 07:57:22 - mmengine - INFO - Epoch(train)  [2][5650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:14:45  time: 1.9464  data_time: 0.0048  memory: 44623  loss: 0.8719  loss_rpn_cls: 0.0416  loss_rpn_bbox: 0.0442  loss_cls: 0.2359  acc: 93.3350  loss_bbox: 0.2703  loss_mask: 0.2799
2025/12/11 07:58:02 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 07:59:01 - mmengine - INFO - Epoch(train)  [2][5700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:12:53  time: 1.9928  data_time: 0.0053  memory: 44380  loss: 0.9010  loss_rpn_cls: 0.0458  loss_rpn_bbox: 0.0493  loss_cls: 0.2460  acc: 90.6860  loss_bbox: 0.2774  loss_mask: 0.2825
2025/12/11 08:00:37 - mmengine - INFO - Epoch(train)  [2][5750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:10:37  time: 1.9075  data_time: 0.0047  memory: 42229  loss: 0.8647  loss_rpn_cls: 0.0405  loss_rpn_bbox: 0.0439  loss_cls: 0.2367  acc: 91.0278  loss_bbox: 0.2640  loss_mask: 0.2797
2025/12/11 08:02:14 - mmengine - INFO - Epoch(train)  [2][5800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:08:30  time: 1.9370  data_time: 0.0048  memory: 43860  loss: 0.8817  loss_rpn_cls: 0.0394  loss_rpn_bbox: 0.0450  loss_cls: 0.2447  acc: 89.5752  loss_bbox: 0.2706  loss_mask: 0.2820
2025/12/11 08:03:51 - mmengine - INFO - Epoch(train)  [2][5850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:06:24  time: 1.9414  data_time: 0.0050  memory: 44283  loss: 0.9192  loss_rpn_cls: 0.0467  loss_rpn_bbox: 0.0494  loss_cls: 0.2525  acc: 91.8701  loss_bbox: 0.2859  loss_mask: 0.2847
2025/12/11 08:05:29 - mmengine - INFO - Epoch(train)  [2][5900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:04:27  time: 1.9701  data_time: 0.0050  memory: 42318  loss: 0.8849  loss_rpn_cls: 0.0432  loss_rpn_bbox: 0.0460  loss_cls: 0.2450  acc: 91.6260  loss_bbox: 0.2722  loss_mask: 0.2786
2025/12/11 08:07:06 - mmengine - INFO - Epoch(train)  [2][5950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:02:20  time: 1.9354  data_time: 0.0051  memory: 43920  loss: 0.8845  loss_rpn_cls: 0.0422  loss_rpn_bbox: 0.0456  loss_cls: 0.2413  acc: 90.9546  loss_bbox: 0.2748  loss_mask: 0.2805
2025/12/11 08:08:44 - mmengine - INFO - Epoch(train)  [2][6000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 18:00:20  time: 1.9590  data_time: 0.0055  memory: 42845  loss: 0.8833  loss_rpn_cls: 0.0441  loss_rpn_bbox: 0.0469  loss_cls: 0.2381  acc: 90.3931  loss_bbox: 0.2724  loss_mask: 0.2818
2025/12/11 08:10:21 - mmengine - INFO - Epoch(train)  [2][6050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:58:16  time: 1.9455  data_time: 0.0049  memory: 41923  loss: 0.8665  loss_rpn_cls: 0.0418  loss_rpn_bbox: 0.0438  loss_cls: 0.2335  acc: 91.7480  loss_bbox: 0.2688  loss_mask: 0.2786
2025/12/11 08:11:59 - mmengine - INFO - Epoch(train)  [2][6100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:56:18  time: 1.9665  data_time: 0.0050  memory: 43934  loss: 0.9088  loss_rpn_cls: 0.0433  loss_rpn_bbox: 0.0468  loss_cls: 0.2539  acc: 92.7856  loss_bbox: 0.2812  loss_mask: 0.2836
2025/12/11 08:13:35 - mmengine - INFO - Epoch(train)  [2][6150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:54:02  time: 1.9014  data_time: 0.0045  memory: 42804  loss: 0.8765  loss_rpn_cls: 0.0449  loss_rpn_bbox: 0.0449  loss_cls: 0.2387  acc: 91.6870  loss_bbox: 0.2682  loss_mask: 0.2798
2025/12/11 08:15:10 - mmengine - INFO - Epoch(train)  [2][6200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:51:50  time: 1.9130  data_time: 0.0048  memory: 42156  loss: 0.8822  loss_rpn_cls: 0.0457  loss_rpn_bbox: 0.0466  loss_cls: 0.2355  acc: 88.0859  loss_bbox: 0.2746  loss_mask: 0.2799
2025/12/11 08:16:50 - mmengine - INFO - Epoch(train)  [2][6250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:50:00  time: 1.9935  data_time: 0.0057  memory: 42466  loss: 0.9069  loss_rpn_cls: 0.0457  loss_rpn_bbox: 0.0494  loss_cls: 0.2436  acc: 92.5415  loss_bbox: 0.2822  loss_mask: 0.2859
2025/12/11 08:18:25 - mmengine - INFO - Epoch(train)  [2][6300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:47:47  time: 1.9056  data_time: 0.0047  memory: 43457  loss: 0.8909  loss_rpn_cls: 0.0436  loss_rpn_bbox: 0.0480  loss_cls: 0.2450  acc: 90.7959  loss_bbox: 0.2793  loss_mask: 0.2750
2025/12/11 08:20:01 - mmengine - INFO - Epoch(train)  [2][6350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:45:36  time: 1.9140  data_time: 0.0049  memory: 43227  loss: 0.8895  loss_rpn_cls: 0.0424  loss_rpn_bbox: 0.0451  loss_cls: 0.2470  acc: 91.1865  loss_bbox: 0.2698  loss_mask: 0.2852
2025/12/11 08:21:38 - mmengine - INFO - Epoch(train)  [2][6400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:43:30  time: 1.9342  data_time: 0.0050  memory: 42325  loss: 0.8935  loss_rpn_cls: 0.0429  loss_rpn_bbox: 0.0480  loss_cls: 0.2443  acc: 91.2842  loss_bbox: 0.2776  loss_mask: 0.2807
2025/12/11 08:23:13 - mmengine - INFO - Epoch(train)  [2][6450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:41:17  time: 1.9049  data_time: 0.0046  memory: 43660  loss: 0.9183  loss_rpn_cls: 0.0446  loss_rpn_bbox: 0.0492  loss_cls: 0.2530  acc: 89.8926  loss_bbox: 0.2866  loss_mask: 0.2849
2025/12/11 08:24:48 - mmengine - INFO - Epoch(train)  [2][6500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:39:06  time: 1.9103  data_time: 0.0045  memory: 42307  loss: 0.8971  loss_rpn_cls: 0.0454  loss_rpn_bbox: 0.0483  loss_cls: 0.2407  acc: 88.3545  loss_bbox: 0.2769  loss_mask: 0.2858
2025/12/11 08:26:25 - mmengine - INFO - Epoch(train)  [2][6550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:36:59  time: 1.9290  data_time: 0.0049  memory: 43278  loss: 0.9003  loss_rpn_cls: 0.0446  loss_rpn_bbox: 0.0483  loss_cls: 0.2458  acc: 92.1875  loss_bbox: 0.2768  loss_mask: 0.2848
2025/12/11 08:27:59 - mmengine - INFO - Epoch(train)  [2][6600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:34:43  time: 1.8905  data_time: 0.0045  memory: 41967  loss: 0.9201  loss_rpn_cls: 0.0447  loss_rpn_bbox: 0.0492  loss_cls: 0.2503  acc: 90.3076  loss_bbox: 0.2844  loss_mask: 0.2915
2025/12/11 08:29:38 - mmengine - INFO - Epoch(train)  [2][6650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:32:48  time: 1.9700  data_time: 0.0047  memory: 43682  loss: 0.8699  loss_rpn_cls: 0.0426  loss_rpn_bbox: 0.0450  loss_cls: 0.2377  acc: 92.0044  loss_bbox: 0.2648  loss_mask: 0.2798
2025/12/11 08:30:16 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 08:31:13 - mmengine - INFO - Epoch(train)  [2][6700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:30:34  time: 1.8958  data_time: 0.0044  memory: 42863  loss: 0.8974  loss_rpn_cls: 0.0436  loss_rpn_bbox: 0.0467  loss_cls: 0.2433  acc: 88.9282  loss_bbox: 0.2795  loss_mask: 0.2843
2025/12/11 08:32:50 - mmengine - INFO - Epoch(train)  [2][6750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:28:33  time: 1.9449  data_time: 0.0053  memory: 42599  loss: 0.8794  loss_rpn_cls: 0.0426  loss_rpn_bbox: 0.0463  loss_cls: 0.2367  acc: 92.5903  loss_bbox: 0.2733  loss_mask: 0.2805
2025/12/11 08:34:27 - mmengine - INFO - Epoch(train)  [2][6800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:26:30  time: 1.9366  data_time: 0.0049  memory: 45172  loss: 0.8830  loss_rpn_cls: 0.0437  loss_rpn_bbox: 0.0462  loss_cls: 0.2392  acc: 88.2812  loss_bbox: 0.2776  loss_mask: 0.2763
2025/12/11 08:36:03 - mmengine - INFO - Epoch(train)  [2][6850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:24:24  time: 1.9256  data_time: 0.0048  memory: 43674  loss: 0.8708  loss_rpn_cls: 0.0409  loss_rpn_bbox: 0.0445  loss_cls: 0.2366  acc: 92.5415  loss_bbox: 0.2685  loss_mask: 0.2802
2025/12/11 08:37:40 - mmengine - INFO - Epoch(train)  [2][6900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:22:21  time: 1.9343  data_time: 0.0050  memory: 41678  loss: 0.9084  loss_rpn_cls: 0.0438  loss_rpn_bbox: 0.0473  loss_cls: 0.2503  acc: 90.4785  loss_bbox: 0.2829  loss_mask: 0.2841
2025/12/11 08:39:15 - mmengine - INFO - Epoch(train)  [2][6950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:20:09  time: 1.9012  data_time: 0.0046  memory: 41361  loss: 0.9225  loss_rpn_cls: 0.0456  loss_rpn_bbox: 0.0513  loss_cls: 0.2520  acc: 88.4888  loss_bbox: 0.2848  loss_mask: 0.2887
2025/12/11 08:40:49 - mmengine - INFO - Epoch(train)  [2][7000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:17:55  time: 1.8902  data_time: 0.0046  memory: 42982  loss: 0.8909  loss_rpn_cls: 0.0451  loss_rpn_bbox: 0.0472  loss_cls: 0.2412  acc: 91.3208  loss_bbox: 0.2730  loss_mask: 0.2845
2025/12/11 08:42:25 - mmengine - INFO - Epoch(train)  [2][7050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:15:47  time: 1.9120  data_time: 0.0051  memory: 43067  loss: 0.8744  loss_rpn_cls: 0.0441  loss_rpn_bbox: 0.0461  loss_cls: 0.2305  acc: 91.5039  loss_bbox: 0.2698  loss_mask: 0.2839
2025/12/11 08:44:01 - mmengine - INFO - Epoch(train)  [2][7100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:13:43  time: 1.9291  data_time: 0.0051  memory: 42499  loss: 0.9023  loss_rpn_cls: 0.0485  loss_rpn_bbox: 0.0489  loss_cls: 0.2462  acc: 93.9575  loss_bbox: 0.2794  loss_mask: 0.2793
2025/12/11 08:45:37 - mmengine - INFO - Epoch(train)  [2][7150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:11:35  time: 1.9145  data_time: 0.0050  memory: 44171  loss: 0.8969  loss_rpn_cls: 0.0438  loss_rpn_bbox: 0.0482  loss_cls: 0.2505  acc: 89.9536  loss_bbox: 0.2821  loss_mask: 0.2722
2025/12/11 08:47:13 - mmengine - INFO - Epoch(train)  [2][7200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:09:31  time: 1.9257  data_time: 0.0047  memory: 41745  loss: 0.8766  loss_rpn_cls: 0.0430  loss_rpn_bbox: 0.0473  loss_cls: 0.2348  acc: 91.2720  loss_bbox: 0.2737  loss_mask: 0.2778
2025/12/11 08:48:48 - mmengine - INFO - Epoch(train)  [2][7250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:07:21  time: 1.9004  data_time: 0.0046  memory: 42407  loss: 0.8866  loss_rpn_cls: 0.0449  loss_rpn_bbox: 0.0467  loss_cls: 0.2437  acc: 93.2373  loss_bbox: 0.2769  loss_mask: 0.2745
2025/12/11 08:50:25 - mmengine - INFO - Epoch(train)  [2][7300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:05:18  time: 1.9319  data_time: 0.0050  memory: 43275  loss: 0.8904  loss_rpn_cls: 0.0459  loss_rpn_bbox: 0.0489  loss_cls: 0.2396  acc: 92.7246  loss_bbox: 0.2731  loss_mask: 0.2829
2025/12/11 08:51:23 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 08:51:23 - mmengine - INFO - Saving checkpoint at 2 epochs
2025/12/11 08:53:28 - mmengine - INFO - Epoch(val)  [2][ 50/313]    eta: 0:10:21  time: 2.3623  data_time: 0.0915  memory: 42450  
2025/12/11 08:55:19 - mmengine - INFO - Epoch(val)  [2][100/313]    eta: 0:08:07  time: 2.2177  data_time: 0.0014  memory: 8290  
2025/12/11 08:57:18 - mmengine - INFO - Epoch(val)  [2][150/313]    eta: 0:06:18  time: 2.3828  data_time: 0.0014  memory: 8290  
2025/12/11 09:01:33 - mmengine - INFO - Epoch(val)  [2][200/313]    eta: 0:05:40  time: 5.1054  data_time: 0.0020  memory: 8290  
2025/12/11 09:05:37 - mmengine - INFO - Epoch(val)  [2][250/313]    eta: 0:03:33  time: 4.8830  data_time: 0.0023  memory: 8290  
2025/12/11 09:07:29 - mmengine - INFO - Epoch(val)  [2][300/313]    eta: 0:00:41  time: 2.2252  data_time: 0.0015  memory: 8290  
2025/12/11 09:08:08 - mmengine - INFO - Evaluating bbox...
2025/12/11 09:08:46 - mmengine - INFO - bbox_mAP_copypaste: 0.358 0.580 0.385 0.223 0.390 0.458
2025/12/11 09:08:46 - mmengine - INFO - Evaluating segm...
2025/12/11 09:09:27 - mmengine - INFO - segm_mAP_copypaste: 0.329 0.550 0.344 0.162 0.359 0.478
2025/12/11 09:09:28 - mmengine - INFO - Epoch(val) [2][313/313]    coco/bbox_mAP: 0.3580  coco/bbox_mAP_50: 0.5800  coco/bbox_mAP_75: 0.3850  coco/bbox_mAP_s: 0.2230  coco/bbox_mAP_m: 0.3900  coco/bbox_mAP_l: 0.4580  coco/segm_mAP: 0.3290  coco/segm_mAP_50: 0.5500  coco/segm_mAP_75: 0.3440  coco/segm_mAP_s: 0.1620  coco/segm_mAP_m: 0.3590  coco/segm_mAP_l: 0.4780  data_time: 0.0160  time: 3.1461
2025/12/11 09:11:13 - mmengine - INFO - Epoch(train)  [3][  50/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:02:43  time: 2.0853  data_time: 0.0723  memory: 42065  loss: 0.8459  loss_rpn_cls: 0.0409  loss_rpn_bbox: 0.0454  loss_cls: 0.2232  acc: 91.3208  loss_bbox: 0.2617  loss_mask: 0.2747
2025/12/11 09:12:49 - mmengine - INFO - Epoch(train)  [3][ 100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 17:00:39  time: 1.9252  data_time: 0.0050  memory: 42125  loss: 0.8809  loss_rpn_cls: 0.0387  loss_rpn_bbox: 0.0436  loss_cls: 0.2374  acc: 92.4072  loss_bbox: 0.2736  loss_mask: 0.2875
2025/12/11 09:14:29 - mmengine - INFO - Epoch(train)  [3][ 150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:58:55  time: 2.0026  data_time: 0.0050  memory: 43932  loss: 0.8623  loss_rpn_cls: 0.0379  loss_rpn_bbox: 0.0427  loss_cls: 0.2336  acc: 89.6484  loss_bbox: 0.2732  loss_mask: 0.2749
2025/12/11 09:16:07 - mmengine - INFO - Epoch(train)  [3][ 200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:57:01  time: 1.9629  data_time: 0.0050  memory: 42554  loss: 0.8813  loss_rpn_cls: 0.0402  loss_rpn_bbox: 0.0468  loss_cls: 0.2394  acc: 92.7490  loss_bbox: 0.2796  loss_mask: 0.2752
2025/12/11 09:17:46 - mmengine - INFO - Epoch(train)  [3][ 250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:55:09  time: 1.9713  data_time: 0.0049  memory: 42892  loss: 0.8623  loss_rpn_cls: 0.0428  loss_rpn_bbox: 0.0449  loss_cls: 0.2310  acc: 89.6118  loss_bbox: 0.2685  loss_mask: 0.2751
2025/12/11 09:19:22 - mmengine - INFO - Epoch(train)  [3][ 300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:53:08  time: 1.9353  data_time: 0.0051  memory: 43214  loss: 0.8764  loss_rpn_cls: 0.0416  loss_rpn_bbox: 0.0465  loss_cls: 0.2385  acc: 92.4805  loss_bbox: 0.2754  loss_mask: 0.2745
2025/12/11 09:20:43 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 09:21:03 - mmengine - INFO - Epoch(train)  [3][ 350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:51:24  time: 2.0045  data_time: 0.0080  memory: 42474  loss: 0.9152  loss_rpn_cls: 0.0445  loss_rpn_bbox: 0.0499  loss_cls: 0.2515  acc: 93.2129  loss_bbox: 0.2887  loss_mask: 0.2807
2025/12/11 09:22:39 - mmengine - INFO - Epoch(train)  [3][ 400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:49:23  time: 1.9323  data_time: 0.0047  memory: 41792  loss: 0.8939  loss_rpn_cls: 0.0446  loss_rpn_bbox: 0.0492  loss_cls: 0.2390  acc: 94.6289  loss_bbox: 0.2842  loss_mask: 0.2769
2025/12/11 09:24:17 - mmengine - INFO - Epoch(train)  [3][ 450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:47:29  time: 1.9620  data_time: 0.0056  memory: 41708  loss: 0.8700  loss_rpn_cls: 0.0421  loss_rpn_bbox: 0.0473  loss_cls: 0.2325  acc: 92.5293  loss_bbox: 0.2685  loss_mask: 0.2796
2025/12/11 09:25:51 - mmengine - INFO - Epoch(train)  [3][ 500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:45:17  time: 1.8825  data_time: 0.0049  memory: 42521  loss: 0.8503  loss_rpn_cls: 0.0411  loss_rpn_bbox: 0.0439  loss_cls: 0.2280  acc: 94.2383  loss_bbox: 0.2632  loss_mask: 0.2741
2025/12/11 09:27:30 - mmengine - INFO - Epoch(train)  [3][ 550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:43:27  time: 1.9777  data_time: 0.0052  memory: 43635  loss: 0.8755  loss_rpn_cls: 0.0431  loss_rpn_bbox: 0.0464  loss_cls: 0.2325  acc: 90.2100  loss_bbox: 0.2762  loss_mask: 0.2772
2025/12/11 09:29:05 - mmengine - INFO - Epoch(train)  [3][ 600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:41:19  time: 1.9002  data_time: 0.0049  memory: 42275  loss: 0.8755  loss_rpn_cls: 0.0412  loss_rpn_bbox: 0.0487  loss_cls: 0.2336  acc: 91.0156  loss_bbox: 0.2776  loss_mask: 0.2745
2025/12/11 09:30:44 - mmengine - INFO - Epoch(train)  [3][ 650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:39:29  time: 1.9767  data_time: 0.0081  memory: 44062  loss: 0.9227  loss_rpn_cls: 0.0452  loss_rpn_bbox: 0.0483  loss_cls: 0.2517  acc: 90.4663  loss_bbox: 0.2902  loss_mask: 0.2873
2025/12/11 09:32:22 - mmengine - INFO - Epoch(train)  [3][ 700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:37:35  time: 1.9612  data_time: 0.0053  memory: 44073  loss: 0.8689  loss_rpn_cls: 0.0381  loss_rpn_bbox: 0.0456  loss_cls: 0.2354  acc: 90.2832  loss_bbox: 0.2780  loss_mask: 0.2718
2025/12/11 09:33:59 - mmengine - INFO - Epoch(train)  [3][ 750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:35:34  time: 1.9255  data_time: 0.0053  memory: 42628  loss: 0.8707  loss_rpn_cls: 0.0423  loss_rpn_bbox: 0.0454  loss_cls: 0.2363  acc: 96.2524  loss_bbox: 0.2742  loss_mask: 0.2725
2025/12/11 09:35:35 - mmengine - INFO - Epoch(train)  [3][ 800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:33:32  time: 1.9236  data_time: 0.0049  memory: 42776  loss: 0.8629  loss_rpn_cls: 0.0463  loss_rpn_bbox: 0.0466  loss_cls: 0.2274  acc: 92.5659  loss_bbox: 0.2669  loss_mask: 0.2757
2025/12/11 09:37:11 - mmengine - INFO - Epoch(train)  [3][ 850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:31:30  time: 1.9219  data_time: 0.0049  memory: 43157  loss: 0.8823  loss_rpn_cls: 0.0405  loss_rpn_bbox: 0.0460  loss_cls: 0.2428  acc: 91.2598  loss_bbox: 0.2809  loss_mask: 0.2721
2025/12/11 09:38:48 - mmengine - INFO - Epoch(train)  [3][ 900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:29:32  time: 1.9406  data_time: 0.0048  memory: 42702  loss: 0.9006  loss_rpn_cls: 0.0441  loss_rpn_bbox: 0.0482  loss_cls: 0.2469  acc: 90.6860  loss_bbox: 0.2808  loss_mask: 0.2806
2025/12/11 09:40:25 - mmengine - INFO - Epoch(train)  [3][ 950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:27:36  time: 1.9474  data_time: 0.0052  memory: 42742  loss: 0.8930  loss_rpn_cls: 0.0430  loss_rpn_bbox: 0.0487  loss_cls: 0.2441  acc: 89.0503  loss_bbox: 0.2813  loss_mask: 0.2759
2025/12/11 09:42:03 - mmengine - INFO - Epoch(train)  [3][1000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:25:41  time: 1.9502  data_time: 0.0052  memory: 44100  loss: 0.8686  loss_rpn_cls: 0.0438  loss_rpn_bbox: 0.0482  loss_cls: 0.2308  acc: 91.1865  loss_bbox: 0.2696  loss_mask: 0.2763
2025/12/11 09:43:43 - mmengine - INFO - Epoch(train)  [3][1050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:23:57  time: 1.9979  data_time: 0.0056  memory: 42907  loss: 0.8837  loss_rpn_cls: 0.0420  loss_rpn_bbox: 0.0485  loss_cls: 0.2399  acc: 90.8447  loss_bbox: 0.2720  loss_mask: 0.2813
2025/12/11 09:45:22 - mmengine - INFO - Epoch(train)  [3][1100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:22:12  time: 1.9956  data_time: 0.0054  memory: 44413  loss: 0.9116  loss_rpn_cls: 0.0450  loss_rpn_bbox: 0.0508  loss_cls: 0.2489  acc: 89.4653  loss_bbox: 0.2824  loss_mask: 0.2845
2025/12/11 09:47:02 - mmengine - INFO - Epoch(train)  [3][1150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:20:28  time: 1.9993  data_time: 0.0057  memory: 44402  loss: 0.8858  loss_rpn_cls: 0.0458  loss_rpn_bbox: 0.0483  loss_cls: 0.2360  acc: 93.3105  loss_bbox: 0.2735  loss_mask: 0.2821
2025/12/11 09:48:38 - mmengine - INFO - Epoch(train)  [3][1200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:18:24  time: 1.9111  data_time: 0.0048  memory: 42014  loss: 0.8658  loss_rpn_cls: 0.0403  loss_rpn_bbox: 0.0444  loss_cls: 0.2360  acc: 92.2119  loss_bbox: 0.2701  loss_mask: 0.2750
2025/12/11 09:50:18 - mmengine - INFO - Epoch(train)  [3][1250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:16:39  time: 1.9931  data_time: 0.0056  memory: 43294  loss: 0.8845  loss_rpn_cls: 0.0431  loss_rpn_bbox: 0.0481  loss_cls: 0.2356  acc: 93.3594  loss_bbox: 0.2779  loss_mask: 0.2797
2025/12/11 09:51:54 - mmengine - INFO - Epoch(train)  [3][1300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:14:38  time: 1.9224  data_time: 0.0046  memory: 43075  loss: 0.8699  loss_rpn_cls: 0.0408  loss_rpn_bbox: 0.0468  loss_cls: 0.2301  acc: 92.1997  loss_bbox: 0.2762  loss_mask: 0.2759
2025/12/11 09:53:12 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 09:53:31 - mmengine - INFO - Epoch(train)  [3][1350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:12:44  time: 1.9486  data_time: 0.0047  memory: 43271  loss: 0.8880  loss_rpn_cls: 0.0438  loss_rpn_bbox: 0.0492  loss_cls: 0.2419  acc: 91.3940  loss_bbox: 0.2791  loss_mask: 0.2740
2025/12/11 09:55:12 - mmengine - INFO - Epoch(train)  [3][1400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:11:05  time: 2.0219  data_time: 0.0054  memory: 43431  loss: 0.8647  loss_rpn_cls: 0.0414  loss_rpn_bbox: 0.0473  loss_cls: 0.2323  acc: 90.2954  loss_bbox: 0.2711  loss_mask: 0.2726
2025/12/11 09:56:52 - mmengine - INFO - Epoch(train)  [3][1450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:09:19  time: 1.9894  data_time: 0.0053  memory: 42112  loss: 0.8548  loss_rpn_cls: 0.0398  loss_rpn_bbox: 0.0461  loss_cls: 0.2301  acc: 92.1753  loss_bbox: 0.2646  loss_mask: 0.2741
2025/12/11 09:58:33 - mmengine - INFO - Epoch(train)  [3][1500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:07:40  time: 2.0186  data_time: 0.0056  memory: 43614  loss: 0.8702  loss_rpn_cls: 0.0416  loss_rpn_bbox: 0.0483  loss_cls: 0.2395  acc: 92.4927  loss_bbox: 0.2717  loss_mask: 0.2692
2025/12/11 10:00:10 - mmengine - INFO - Epoch(train)  [3][1550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:05:45  time: 1.9462  data_time: 0.0066  memory: 41406  loss: 0.8650  loss_rpn_cls: 0.0400  loss_rpn_bbox: 0.0460  loss_cls: 0.2332  acc: 93.1763  loss_bbox: 0.2696  loss_mask: 0.2762
2025/12/11 10:01:50 - mmengine - INFO - Epoch(train)  [3][1600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:04:03  time: 2.0064  data_time: 0.0055  memory: 42971  loss: 0.8804  loss_rpn_cls: 0.0429  loss_rpn_bbox: 0.0477  loss_cls: 0.2363  acc: 94.6899  loss_bbox: 0.2780  loss_mask: 0.2756
2025/12/11 10:03:29 - mmengine - INFO - Epoch(train)  [3][1650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:02:12  time: 1.9644  data_time: 0.0051  memory: 44249  loss: 0.8809  loss_rpn_cls: 0.0440  loss_rpn_bbox: 0.0469  loss_cls: 0.2400  acc: 91.9556  loss_bbox: 0.2725  loss_mask: 0.2776
2025/12/11 10:05:05 - mmengine - INFO - Epoch(train)  [3][1700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 16:00:15  time: 1.9345  data_time: 0.0047  memory: 41976  loss: 0.8392  loss_rpn_cls: 0.0399  loss_rpn_bbox: 0.0437  loss_cls: 0.2204  acc: 94.2505  loss_bbox: 0.2640  loss_mask: 0.2712
2025/12/11 10:06:46 - mmengine - INFO - Epoch(train)  [3][1750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:58:36  time: 2.0209  data_time: 0.0057  memory: 42723  loss: 0.8581  loss_rpn_cls: 0.0415  loss_rpn_bbox: 0.0480  loss_cls: 0.2290  acc: 90.4663  loss_bbox: 0.2653  loss_mask: 0.2743
2025/12/11 10:08:24 - mmengine - INFO - Epoch(train)  [3][1800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:56:44  time: 1.9561  data_time: 0.0049  memory: 42820  loss: 0.9206  loss_rpn_cls: 0.0467  loss_rpn_bbox: 0.0506  loss_cls: 0.2532  acc: 92.1143  loss_bbox: 0.2900  loss_mask: 0.2801
2025/12/11 10:10:02 - mmengine - INFO - Epoch(train)  [3][1850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:54:50  time: 1.9504  data_time: 0.0056  memory: 43173  loss: 0.8542  loss_rpn_cls: 0.0418  loss_rpn_bbox: 0.0468  loss_cls: 0.2265  acc: 93.3960  loss_bbox: 0.2630  loss_mask: 0.2762
2025/12/11 10:11:40 - mmengine - INFO - Epoch(train)  [3][1900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:52:58  time: 1.9579  data_time: 0.0049  memory: 44928  loss: 0.8600  loss_rpn_cls: 0.0402  loss_rpn_bbox: 0.0475  loss_cls: 0.2320  acc: 91.7847  loss_bbox: 0.2682  loss_mask: 0.2721
2025/12/11 10:13:17 - mmengine - INFO - Epoch(train)  [3][1950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:51:04  time: 1.9487  data_time: 0.0050  memory: 42850  loss: 0.8473  loss_rpn_cls: 0.0384  loss_rpn_bbox: 0.0452  loss_cls: 0.2264  acc: 93.8110  loss_bbox: 0.2590  loss_mask: 0.2783
2025/12/11 10:14:55 - mmengine - INFO - Epoch(train)  [3][2000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:49:12  time: 1.9545  data_time: 0.0049  memory: 42535  loss: 0.8485  loss_rpn_cls: 0.0416  loss_rpn_bbox: 0.0452  loss_cls: 0.2232  acc: 91.6626  loss_bbox: 0.2618  loss_mask: 0.2767
2025/12/11 10:16:30 - mmengine - INFO - Epoch(train)  [3][2050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:47:09  time: 1.9066  data_time: 0.0049  memory: 43235  loss: 0.8533  loss_rpn_cls: 0.0436  loss_rpn_bbox: 0.0456  loss_cls: 0.2249  acc: 94.9341  loss_bbox: 0.2672  loss_mask: 0.2720
2025/12/11 10:18:06 - mmengine - INFO - Epoch(train)  [3][2100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:45:10  time: 1.9233  data_time: 0.0053  memory: 44174  loss: 0.8624  loss_rpn_cls: 0.0420  loss_rpn_bbox: 0.0463  loss_cls: 0.2294  acc: 88.9404  loss_bbox: 0.2650  loss_mask: 0.2795
2025/12/11 10:19:46 - mmengine - INFO - Epoch(train)  [3][2150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:43:28  time: 2.0010  data_time: 0.0060  memory: 44164  loss: 0.8757  loss_rpn_cls: 0.0411  loss_rpn_bbox: 0.0443  loss_cls: 0.2423  acc: 88.9404  loss_bbox: 0.2729  loss_mask: 0.2750
2025/12/11 10:21:28 - mmengine - INFO - Epoch(train)  [3][2200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:41:52  time: 2.0327  data_time: 0.0058  memory: 43907  loss: 0.8455  loss_rpn_cls: 0.0426  loss_rpn_bbox: 0.0463  loss_cls: 0.2222  acc: 93.2617  loss_bbox: 0.2608  loss_mask: 0.2736
2025/12/11 10:23:05 - mmengine - INFO - Epoch(train)  [3][2250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:39:56  time: 1.9379  data_time: 0.0050  memory: 43311  loss: 0.8354  loss_rpn_cls: 0.0409  loss_rpn_bbox: 0.0443  loss_cls: 0.2219  acc: 91.5283  loss_bbox: 0.2592  loss_mask: 0.2692
2025/12/11 10:24:42 - mmengine - INFO - Epoch(train)  [3][2300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:38:03  time: 1.9502  data_time: 0.0052  memory: 42591  loss: 0.8295  loss_rpn_cls: 0.0385  loss_rpn_bbox: 0.0416  loss_cls: 0.2201  acc: 95.2759  loss_bbox: 0.2559  loss_mask: 0.2734
2025/12/11 10:26:02 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 10:26:22 - mmengine - INFO - Epoch(train)  [3][2350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:36:21  time: 2.0002  data_time: 0.0059  memory: 43776  loss: 0.8561  loss_rpn_cls: 0.0427  loss_rpn_bbox: 0.0465  loss_cls: 0.2317  acc: 92.2729  loss_bbox: 0.2632  loss_mask: 0.2720
2025/12/11 10:28:00 - mmengine - INFO - Epoch(train)  [3][2400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:34:28  time: 1.9515  data_time: 0.0047  memory: 42862  loss: 0.8771  loss_rpn_cls: 0.0416  loss_rpn_bbox: 0.0467  loss_cls: 0.2422  acc: 89.9902  loss_bbox: 0.2708  loss_mask: 0.2756
2025/12/11 10:29:36 - mmengine - INFO - Epoch(train)  [3][2450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:32:28  time: 1.9159  data_time: 0.0050  memory: 42992  loss: 0.8482  loss_rpn_cls: 0.0401  loss_rpn_bbox: 0.0438  loss_cls: 0.2300  acc: 93.7866  loss_bbox: 0.2653  loss_mask: 0.2690
2025/12/11 10:31:11 - mmengine - INFO - Epoch(train)  [3][2500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:30:27  time: 1.9079  data_time: 0.0059  memory: 41705  loss: 0.8759  loss_rpn_cls: 0.0417  loss_rpn_bbox: 0.0448  loss_cls: 0.2392  acc: 90.5884  loss_bbox: 0.2738  loss_mask: 0.2765
2025/12/11 10:32:47 - mmengine - INFO - Epoch(train)  [3][2550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:28:29  time: 1.9228  data_time: 0.0049  memory: 42009  loss: 0.8603  loss_rpn_cls: 0.0393  loss_rpn_bbox: 0.0448  loss_cls: 0.2315  acc: 89.8193  loss_bbox: 0.2703  loss_mask: 0.2745
2025/12/11 10:34:22 - mmengine - INFO - Epoch(train)  [3][2600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:26:25  time: 1.8960  data_time: 0.0046  memory: 43673  loss: 0.8761  loss_rpn_cls: 0.0439  loss_rpn_bbox: 0.0473  loss_cls: 0.2332  acc: 90.3320  loss_bbox: 0.2734  loss_mask: 0.2783
2025/12/11 10:35:57 - mmengine - INFO - Epoch(train)  [3][2650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:24:25  time: 1.9079  data_time: 0.0048  memory: 44037  loss: 0.8789  loss_rpn_cls: 0.0424  loss_rpn_bbox: 0.0471  loss_cls: 0.2391  acc: 90.8813  loss_bbox: 0.2749  loss_mask: 0.2754
2025/12/11 10:37:34 - mmengine - INFO - Epoch(train)  [3][2700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:22:30  time: 1.9377  data_time: 0.0049  memory: 43028  loss: 0.8714  loss_rpn_cls: 0.0412  loss_rpn_bbox: 0.0479  loss_cls: 0.2327  acc: 93.0908  loss_bbox: 0.2724  loss_mask: 0.2772
2025/12/11 10:39:12 - mmengine - INFO - Epoch(train)  [3][2750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:20:38  time: 1.9505  data_time: 0.0051  memory: 43148  loss: 0.8701  loss_rpn_cls: 0.0404  loss_rpn_bbox: 0.0490  loss_cls: 0.2326  acc: 93.4204  loss_bbox: 0.2696  loss_mask: 0.2785
2025/12/11 10:40:49 - mmengine - INFO - Epoch(train)  [3][2800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:18:44  time: 1.9426  data_time: 0.0050  memory: 42491  loss: 0.9026  loss_rpn_cls: 0.0401  loss_rpn_bbox: 0.0499  loss_cls: 0.2412  acc: 91.2231  loss_bbox: 0.2884  loss_mask: 0.2830
2025/12/11 10:42:26 - mmengine - INFO - Epoch(train)  [3][2850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:16:51  time: 1.9433  data_time: 0.0049  memory: 42244  loss: 0.8715  loss_rpn_cls: 0.0391  loss_rpn_bbox: 0.0455  loss_cls: 0.2367  acc: 92.6514  loss_bbox: 0.2736  loss_mask: 0.2766
2025/12/11 10:44:03 - mmengine - INFO - Epoch(train)  [3][2900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:14:58  time: 1.9429  data_time: 0.0052  memory: 42243  loss: 0.8526  loss_rpn_cls: 0.0427  loss_rpn_bbox: 0.0447  loss_cls: 0.2214  acc: 91.9678  loss_bbox: 0.2628  loss_mask: 0.2810
2025/12/11 10:45:41 - mmengine - INFO - Epoch(train)  [3][2950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:13:08  time: 1.9610  data_time: 0.0050  memory: 43649  loss: 0.8888  loss_rpn_cls: 0.0422  loss_rpn_bbox: 0.0483  loss_cls: 0.2415  acc: 93.8477  loss_bbox: 0.2774  loss_mask: 0.2793
2025/12/11 10:47:18 - mmengine - INFO - Epoch(train)  [3][3000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:11:12  time: 1.9257  data_time: 0.0047  memory: 42498  loss: 0.8591  loss_rpn_cls: 0.0391  loss_rpn_bbox: 0.0458  loss_cls: 0.2333  acc: 88.9282  loss_bbox: 0.2680  loss_mask: 0.2729
2025/12/11 10:48:56 - mmengine - INFO - Epoch(train)  [3][3050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:09:22  time: 1.9600  data_time: 0.0048  memory: 42286  loss: 0.8650  loss_rpn_cls: 0.0410  loss_rpn_bbox: 0.0457  loss_cls: 0.2316  acc: 91.1987  loss_bbox: 0.2728  loss_mask: 0.2739
2025/12/11 10:50:35 - mmengine - INFO - Epoch(train)  [3][3100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:07:37  time: 1.9844  data_time: 0.0058  memory: 42372  loss: 0.8708  loss_rpn_cls: 0.0447  loss_rpn_bbox: 0.0487  loss_cls: 0.2324  acc: 89.6606  loss_bbox: 0.2694  loss_mask: 0.2756
2025/12/11 10:52:13 - mmengine - INFO - Epoch(train)  [3][3150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:05:48  time: 1.9622  data_time: 0.0056  memory: 42723  loss: 0.8428  loss_rpn_cls: 0.0387  loss_rpn_bbox: 0.0464  loss_cls: 0.2250  acc: 92.1021  loss_bbox: 0.2604  loss_mask: 0.2724
2025/12/11 10:53:53 - mmengine - INFO - Epoch(train)  [3][3200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:04:05  time: 1.9908  data_time: 0.0139  memory: 41946  loss: 0.8444  loss_rpn_cls: 0.0400  loss_rpn_bbox: 0.0459  loss_cls: 0.2244  acc: 92.3584  loss_bbox: 0.2579  loss_mask: 0.2762
2025/12/11 10:55:33 - mmengine - INFO - Epoch(train)  [3][3250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:02:25  time: 2.0090  data_time: 0.0057  memory: 43842  loss: 0.8285  loss_rpn_cls: 0.0374  loss_rpn_bbox: 0.0418  loss_cls: 0.2247  acc: 89.8193  loss_bbox: 0.2579  loss_mask: 0.2666
2025/12/11 10:57:10 - mmengine - INFO - Epoch(train)  [3][3300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:00:30  time: 1.9325  data_time: 0.0049  memory: 42588  loss: 0.8364  loss_rpn_cls: 0.0379  loss_rpn_bbox: 0.0435  loss_cls: 0.2262  acc: 90.7715  loss_bbox: 0.2614  loss_mask: 0.2674
2025/12/11 10:58:26 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 10:58:46 - mmengine - INFO - Epoch(train)  [3][3350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:58:34  time: 1.9225  data_time: 0.0050  memory: 43742  loss: 0.8699  loss_rpn_cls: 0.0401  loss_rpn_bbox: 0.0462  loss_cls: 0.2355  acc: 93.1030  loss_bbox: 0.2683  loss_mask: 0.2799
2025/12/11 11:00:25 - mmengine - INFO - Epoch(train)  [3][3400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:56:48  time: 1.9783  data_time: 0.0061  memory: 44711  loss: 0.8482  loss_rpn_cls: 0.0407  loss_rpn_bbox: 0.0453  loss_cls: 0.2274  acc: 94.8364  loss_bbox: 0.2629  loss_mask: 0.2718
2025/12/11 11:02:01 - mmengine - INFO - Epoch(train)  [3][3450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:54:53  time: 1.9274  data_time: 0.0048  memory: 44173  loss: 0.8445  loss_rpn_cls: 0.0387  loss_rpn_bbox: 0.0438  loss_cls: 0.2256  acc: 92.6392  loss_bbox: 0.2601  loss_mask: 0.2762
2025/12/11 11:03:38 - mmengine - INFO - Epoch(train)  [3][3500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:52:59  time: 1.9360  data_time: 0.0048  memory: 42354  loss: 0.8179  loss_rpn_cls: 0.0406  loss_rpn_bbox: 0.0413  loss_cls: 0.2255  acc: 92.7490  loss_bbox: 0.2463  loss_mask: 0.2643
2025/12/11 11:05:17 - mmengine - INFO - Epoch(train)  [3][3550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:51:14  time: 1.9806  data_time: 0.0060  memory: 42912  loss: 0.8296  loss_rpn_cls: 0.0391  loss_rpn_bbox: 0.0443  loss_cls: 0.2221  acc: 90.3198  loss_bbox: 0.2527  loss_mask: 0.2714
2025/12/11 11:06:53 - mmengine - INFO - Epoch(train)  [3][3600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:49:18  time: 1.9207  data_time: 0.0048  memory: 41796  loss: 0.8295  loss_rpn_cls: 0.0398  loss_rpn_bbox: 0.0452  loss_cls: 0.2141  acc: 93.8965  loss_bbox: 0.2551  loss_mask: 0.2753
2025/12/11 11:08:30 - mmengine - INFO - Epoch(train)  [3][3650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:47:25  time: 1.9374  data_time: 0.0049  memory: 42821  loss: 0.8568  loss_rpn_cls: 0.0416  loss_rpn_bbox: 0.0461  loss_cls: 0.2253  acc: 92.1875  loss_bbox: 0.2677  loss_mask: 0.2761
2025/12/11 11:10:10 - mmengine - INFO - Epoch(train)  [3][3700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:45:43  time: 1.9964  data_time: 0.0051  memory: 43846  loss: 0.8913  loss_rpn_cls: 0.0422  loss_rpn_bbox: 0.0485  loss_cls: 0.2368  acc: 92.6147  loss_bbox: 0.2828  loss_mask: 0.2810
2025/12/11 11:11:46 - mmengine - INFO - Epoch(train)  [3][3750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:43:50  time: 1.9371  data_time: 0.0049  memory: 44079  loss: 0.8397  loss_rpn_cls: 0.0394  loss_rpn_bbox: 0.0448  loss_cls: 0.2192  acc: 93.3960  loss_bbox: 0.2610  loss_mask: 0.2753
2025/12/11 11:13:23 - mmengine - INFO - Epoch(train)  [3][3800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:41:54  time: 1.9212  data_time: 0.0046  memory: 43586  loss: 0.8808  loss_rpn_cls: 0.0453  loss_rpn_bbox: 0.0483  loss_cls: 0.2357  acc: 93.1885  loss_bbox: 0.2749  loss_mask: 0.2766
2025/12/11 11:15:00 - mmengine - INFO - Epoch(train)  [3][3850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:40:03  time: 1.9474  data_time: 0.0049  memory: 41830  loss: 0.8536  loss_rpn_cls: 0.0402  loss_rpn_bbox: 0.0451  loss_cls: 0.2300  acc: 93.4937  loss_bbox: 0.2627  loss_mask: 0.2757
2025/12/11 11:16:36 - mmengine - INFO - Epoch(train)  [3][3900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:38:07  time: 1.9195  data_time: 0.0047  memory: 42264  loss: 0.8442  loss_rpn_cls: 0.0394  loss_rpn_bbox: 0.0439  loss_cls: 0.2255  acc: 91.4673  loss_bbox: 0.2671  loss_mask: 0.2683
2025/12/11 11:18:14 - mmengine - INFO - Epoch(train)  [3][3950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:36:20  time: 1.9669  data_time: 0.0053  memory: 42587  loss: 0.8688  loss_rpn_cls: 0.0388  loss_rpn_bbox: 0.0465  loss_cls: 0.2415  acc: 90.1367  loss_bbox: 0.2708  loss_mask: 0.2712
2025/12/11 11:19:51 - mmengine - INFO - Epoch(train)  [3][4000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:34:26  time: 1.9302  data_time: 0.0047  memory: 42194  loss: 0.8847  loss_rpn_cls: 0.0413  loss_rpn_bbox: 0.0476  loss_cls: 0.2362  acc: 90.6860  loss_bbox: 0.2769  loss_mask: 0.2827
2025/12/11 11:21:26 - mmengine - INFO - Epoch(train)  [3][4050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:32:29  time: 1.9129  data_time: 0.0047  memory: 42549  loss: 0.8552  loss_rpn_cls: 0.0393  loss_rpn_bbox: 0.0449  loss_cls: 0.2304  acc: 93.0420  loss_bbox: 0.2640  loss_mask: 0.2765
2025/12/11 11:23:04 - mmengine - INFO - Epoch(train)  [3][4100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:30:38  time: 1.9476  data_time: 0.0048  memory: 43125  loss: 0.8354  loss_rpn_cls: 0.0373  loss_rpn_bbox: 0.0443  loss_cls: 0.2219  acc: 93.2739  loss_bbox: 0.2586  loss_mask: 0.2733
2025/12/11 11:24:42 - mmengine - INFO - Epoch(train)  [3][4150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:28:51  time: 1.9681  data_time: 0.0054  memory: 43807  loss: 0.8579  loss_rpn_cls: 0.0415  loss_rpn_bbox: 0.0460  loss_cls: 0.2286  acc: 91.4673  loss_bbox: 0.2721  loss_mask: 0.2697
2025/12/11 11:26:18 - mmengine - INFO - Epoch(train)  [3][4200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:26:56  time: 1.9206  data_time: 0.0050  memory: 42767  loss: 0.8366  loss_rpn_cls: 0.0410  loss_rpn_bbox: 0.0436  loss_cls: 0.2245  acc: 94.2261  loss_bbox: 0.2608  loss_mask: 0.2666
2025/12/11 11:27:56 - mmengine - INFO - Epoch(train)  [3][4250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:25:07  time: 1.9537  data_time: 0.0052  memory: 43679  loss: 0.8735  loss_rpn_cls: 0.0423  loss_rpn_bbox: 0.0481  loss_cls: 0.2361  acc: 93.2495  loss_bbox: 0.2705  loss_mask: 0.2765
2025/12/11 11:29:38 - mmengine - INFO - Epoch(train)  [3][4300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:23:32  time: 2.0341  data_time: 0.0061  memory: 43015  loss: 0.8694  loss_rpn_cls: 0.0396  loss_rpn_bbox: 0.0470  loss_cls: 0.2350  acc: 91.2598  loss_bbox: 0.2694  loss_mask: 0.2784
2025/12/11 11:30:56 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 11:31:15 - mmengine - INFO - Epoch(train)  [3][4350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:21:42  time: 1.9467  data_time: 0.0056  memory: 42421  loss: 0.8620  loss_rpn_cls: 0.0464  loss_rpn_bbox: 0.0450  loss_cls: 0.2312  acc: 92.1753  loss_bbox: 0.2665  loss_mask: 0.2729
2025/12/11 11:32:53 - mmengine - INFO - Epoch(train)  [3][4400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:19:56  time: 1.9690  data_time: 0.0060  memory: 43631  loss: 0.8611  loss_rpn_cls: 0.0427  loss_rpn_bbox: 0.0461  loss_cls: 0.2299  acc: 90.4907  loss_bbox: 0.2669  loss_mask: 0.2754
2025/12/11 11:34:27 - mmengine - INFO - Epoch(train)  [3][4450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:17:54  time: 1.8804  data_time: 0.0047  memory: 42318  loss: 0.8278  loss_rpn_cls: 0.0393  loss_rpn_bbox: 0.0406  loss_cls: 0.2217  acc: 94.0918  loss_bbox: 0.2522  loss_mask: 0.2739
2025/12/11 11:36:02 - mmengine - INFO - Epoch(train)  [3][4500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:15:55  time: 1.8997  data_time: 0.0046  memory: 42122  loss: 0.8427  loss_rpn_cls: 0.0407  loss_rpn_bbox: 0.0459  loss_cls: 0.2217  acc: 92.4072  loss_bbox: 0.2615  loss_mask: 0.2728
2025/12/11 11:37:41 - mmengine - INFO - Epoch(train)  [3][4550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:14:08  time: 1.9630  data_time: 0.0051  memory: 42261  loss: 0.8410  loss_rpn_cls: 0.0400  loss_rpn_bbox: 0.0447  loss_cls: 0.2226  acc: 91.8823  loss_bbox: 0.2626  loss_mask: 0.2711
2025/12/11 11:39:17 - mmengine - INFO - Epoch(train)  [3][4600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:12:16  time: 1.9351  data_time: 0.0039  memory: 42246  loss: 0.8225  loss_rpn_cls: 0.0391  loss_rpn_bbox: 0.0423  loss_cls: 0.2199  acc: 89.6118  loss_bbox: 0.2508  loss_mask: 0.2704
2025/12/11 11:40:53 - mmengine - INFO - Epoch(train)  [3][4650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:10:19  time: 1.9062  data_time: 0.0040  memory: 44001  loss: 0.8479  loss_rpn_cls: 0.0379  loss_rpn_bbox: 0.0455  loss_cls: 0.2267  acc: 90.7104  loss_bbox: 0.2651  loss_mask: 0.2726
2025/12/11 11:42:27 - mmengine - INFO - Epoch(train)  [3][4700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:08:16  time: 1.8771  data_time: 0.0042  memory: 43687  loss: 0.8575  loss_rpn_cls: 0.0412  loss_rpn_bbox: 0.0472  loss_cls: 0.2311  acc: 92.1997  loss_bbox: 0.2670  loss_mask: 0.2710
2025/12/11 11:44:03 - mmengine - INFO - Epoch(train)  [3][4750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:06:22  time: 1.9222  data_time: 0.0052  memory: 43897  loss: 0.8621  loss_rpn_cls: 0.0378  loss_rpn_bbox: 0.0466  loss_cls: 0.2360  acc: 90.5884  loss_bbox: 0.2750  loss_mask: 0.2668
2025/12/11 11:45:36 - mmengine - INFO - Epoch(train)  [3][4800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:04:19  time: 1.8696  data_time: 0.0041  memory: 42122  loss: 0.8466  loss_rpn_cls: 0.0390  loss_rpn_bbox: 0.0440  loss_cls: 0.2252  acc: 89.8804  loss_bbox: 0.2622  loss_mask: 0.2762
2025/12/11 11:47:12 - mmengine - INFO - Epoch(train)  [3][4850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:02:25  time: 1.9200  data_time: 0.0048  memory: 42246  loss: 0.8484  loss_rpn_cls: 0.0398  loss_rpn_bbox: 0.0445  loss_cls: 0.2284  acc: 92.5781  loss_bbox: 0.2648  loss_mask: 0.2709
2025/12/11 11:48:45 - mmengine - INFO - Epoch(train)  [3][4900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:00:21  time: 1.8642  data_time: 0.0043  memory: 42722  loss: 0.8245  loss_rpn_cls: 0.0408  loss_rpn_bbox: 0.0449  loss_cls: 0.2201  acc: 92.3950  loss_bbox: 0.2520  loss_mask: 0.2667
2025/12/11 11:50:20 - mmengine - INFO - Epoch(train)  [3][4950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:58:22  time: 1.8896  data_time: 0.0040  memory: 41632  loss: 0.8462  loss_rpn_cls: 0.0421  loss_rpn_bbox: 0.0459  loss_cls: 0.2274  acc: 90.1489  loss_bbox: 0.2582  loss_mask: 0.2727
2025/12/11 11:51:56 - mmengine - INFO - Epoch(train)  [3][5000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:56:29  time: 1.9244  data_time: 0.0041  memory: 41758  loss: 0.8614  loss_rpn_cls: 0.0396  loss_rpn_bbox: 0.0451  loss_cls: 0.2293  acc: 94.1284  loss_bbox: 0.2712  loss_mask: 0.2761
2025/12/11 11:53:28 - mmengine - INFO - Epoch(train)  [3][5050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:54:23  time: 1.8493  data_time: 0.0039  memory: 44482  loss: 0.8474  loss_rpn_cls: 0.0414  loss_rpn_bbox: 0.0476  loss_cls: 0.2254  acc: 93.7012  loss_bbox: 0.2642  loss_mask: 0.2688
2025/12/11 11:55:03 - mmengine - INFO - Epoch(train)  [3][5100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:52:22  time: 1.8807  data_time: 0.0041  memory: 41337  loss: 0.8632  loss_rpn_cls: 0.0408  loss_rpn_bbox: 0.0456  loss_cls: 0.2338  acc: 95.3369  loss_bbox: 0.2667  loss_mask: 0.2763
2025/12/11 11:56:39 - mmengine - INFO - Epoch(train)  [3][5150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:50:31  time: 1.9348  data_time: 0.0041  memory: 42696  loss: 0.8338  loss_rpn_cls: 0.0406  loss_rpn_bbox: 0.0441  loss_cls: 0.2196  acc: 89.3066  loss_bbox: 0.2542  loss_mask: 0.2753
2025/12/11 11:58:14 - mmengine - INFO - Epoch(train)  [3][5200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:48:34  time: 1.8993  data_time: 0.0039  memory: 42563  loss: 0.8502  loss_rpn_cls: 0.0399  loss_rpn_bbox: 0.0451  loss_cls: 0.2309  acc: 94.8242  loss_bbox: 0.2694  loss_mask: 0.2649
2025/12/11 11:59:49 - mmengine - INFO - Epoch(train)  [3][5250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:46:35  time: 1.8898  data_time: 0.0036  memory: 41325  loss: 0.8634  loss_rpn_cls: 0.0417  loss_rpn_bbox: 0.0473  loss_cls: 0.2367  acc: 93.3838  loss_bbox: 0.2646  loss_mask: 0.2730
2025/12/11 12:01:24 - mmengine - INFO - Epoch(train)  [3][5300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:44:39  time: 1.9029  data_time: 0.0039  memory: 42965  loss: 0.8390  loss_rpn_cls: 0.0377  loss_rpn_bbox: 0.0427  loss_cls: 0.2292  acc: 92.2852  loss_bbox: 0.2597  loss_mask: 0.2696
2025/12/11 12:02:40 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 12:02:58 - mmengine - INFO - Epoch(train)  [3][5350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:42:40  time: 1.8869  data_time: 0.0034  memory: 43998  loss: 0.8552  loss_rpn_cls: 0.0438  loss_rpn_bbox: 0.0441  loss_cls: 0.2319  acc: 91.4917  loss_bbox: 0.2667  loss_mask: 0.2687
2025/12/11 12:04:33 - mmengine - INFO - Epoch(train)  [3][5400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:40:45  time: 1.9053  data_time: 0.0036  memory: 42579  loss: 0.8381  loss_rpn_cls: 0.0394  loss_rpn_bbox: 0.0449  loss_cls: 0.2207  acc: 93.0054  loss_bbox: 0.2638  loss_mask: 0.2693
2025/12/11 12:06:09 - mmengine - INFO - Epoch(train)  [3][5450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:38:49  time: 1.9043  data_time: 0.0046  memory: 43339  loss: 0.8430  loss_rpn_cls: 0.0395  loss_rpn_bbox: 0.0443  loss_cls: 0.2223  acc: 90.9668  loss_bbox: 0.2621  loss_mask: 0.2747
2025/12/11 12:07:44 - mmengine - INFO - Epoch(train)  [3][5500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:36:54  time: 1.9043  data_time: 0.0041  memory: 43240  loss: 0.8575  loss_rpn_cls: 0.0403  loss_rpn_bbox: 0.0461  loss_cls: 0.2297  acc: 90.9058  loss_bbox: 0.2687  loss_mask: 0.2726
2025/12/11 12:09:16 - mmengine - INFO - Epoch(train)  [3][5550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:34:48  time: 1.8454  data_time: 0.0032  memory: 43879  loss: 0.8269  loss_rpn_cls: 0.0359  loss_rpn_bbox: 0.0436  loss_cls: 0.2210  acc: 91.4795  loss_bbox: 0.2567  loss_mask: 0.2697
2025/12/11 12:10:50 - mmengine - INFO - Epoch(train)  [3][5600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:32:48  time: 1.8771  data_time: 0.0034  memory: 42983  loss: 0.8815  loss_rpn_cls: 0.0431  loss_rpn_bbox: 0.0485  loss_cls: 0.2400  acc: 91.5161  loss_bbox: 0.2761  loss_mask: 0.2738
2025/12/11 12:12:22 - mmengine - INFO - Epoch(train)  [3][5650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:30:43  time: 1.8395  data_time: 0.0030  memory: 43254  loss: 0.8473  loss_rpn_cls: 0.0376  loss_rpn_bbox: 0.0455  loss_cls: 0.2304  acc: 91.6504  loss_bbox: 0.2672  loss_mask: 0.2666
2025/12/11 12:13:55 - mmengine - INFO - Epoch(train)  [3][5700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:28:39  time: 1.8548  data_time: 0.0031  memory: 42018  loss: 0.8407  loss_rpn_cls: 0.0404  loss_rpn_bbox: 0.0439  loss_cls: 0.2297  acc: 94.4092  loss_bbox: 0.2592  loss_mask: 0.2675
2025/12/11 12:15:27 - mmengine - INFO - Epoch(train)  [3][5750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:26:33  time: 1.8368  data_time: 0.0032  memory: 43219  loss: 0.8667  loss_rpn_cls: 0.0424  loss_rpn_bbox: 0.0482  loss_cls: 0.2350  acc: 89.5508  loss_bbox: 0.2677  loss_mask: 0.2734
2025/12/11 12:16:59 - mmengine - INFO - Epoch(train)  [3][5800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:24:30  time: 1.8530  data_time: 0.0031  memory: 42125  loss: 0.8359  loss_rpn_cls: 0.0402  loss_rpn_bbox: 0.0438  loss_cls: 0.2232  acc: 94.8853  loss_bbox: 0.2578  loss_mask: 0.2710
2025/12/11 12:18:32 - mmengine - INFO - Epoch(train)  [3][5850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:22:27  time: 1.8553  data_time: 0.0032  memory: 43584  loss: 0.8395  loss_rpn_cls: 0.0417  loss_rpn_bbox: 0.0445  loss_cls: 0.2223  acc: 92.6514  loss_bbox: 0.2601  loss_mask: 0.2710
2025/12/11 12:20:06 - mmengine - INFO - Epoch(train)  [3][5900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:20:27  time: 1.8734  data_time: 0.0036  memory: 41846  loss: 0.8369  loss_rpn_cls: 0.0380  loss_rpn_bbox: 0.0435  loss_cls: 0.2243  acc: 94.5679  loss_bbox: 0.2579  loss_mask: 0.2732
2025/12/11 12:21:43 - mmengine - INFO - Epoch(train)  [3][5950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:18:41  time: 1.9521  data_time: 0.0044  memory: 42665  loss: 0.8126  loss_rpn_cls: 0.0382  loss_rpn_bbox: 0.0399  loss_cls: 0.2175  acc: 94.7754  loss_bbox: 0.2481  loss_mask: 0.2689
2025/12/11 12:23:19 - mmengine - INFO - Epoch(train)  [3][6000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:16:48  time: 1.9145  data_time: 0.0041  memory: 42549  loss: 0.8533  loss_rpn_cls: 0.0417  loss_rpn_bbox: 0.0470  loss_cls: 0.2238  acc: 91.9189  loss_bbox: 0.2642  loss_mask: 0.2766
2025/12/11 12:24:53 - mmengine - INFO - Epoch(train)  [3][6050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:14:51  time: 1.8867  data_time: 0.0035  memory: 42933  loss: 0.8177  loss_rpn_cls: 0.0362  loss_rpn_bbox: 0.0436  loss_cls: 0.2168  acc: 91.4429  loss_bbox: 0.2510  loss_mask: 0.2701
2025/12/11 12:26:30 - mmengine - INFO - Epoch(train)  [3][6100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:13:01  time: 1.9335  data_time: 0.0039  memory: 41790  loss: 0.8461  loss_rpn_cls: 0.0391  loss_rpn_bbox: 0.0432  loss_cls: 0.2289  acc: 92.3340  loss_bbox: 0.2620  loss_mask: 0.2728
2025/12/11 12:28:04 - mmengine - INFO - Epoch(train)  [3][6150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:11:02  time: 1.8727  data_time: 0.0036  memory: 42316  loss: 0.8583  loss_rpn_cls: 0.0389  loss_rpn_bbox: 0.0460  loss_cls: 0.2324  acc: 92.2119  loss_bbox: 0.2665  loss_mask: 0.2746
2025/12/11 12:29:42 - mmengine - INFO - Epoch(train)  [3][6200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:09:19  time: 1.9691  data_time: 0.0044  memory: 42436  loss: 0.8890  loss_rpn_cls: 0.0428  loss_rpn_bbox: 0.0488  loss_cls: 0.2446  acc: 93.2861  loss_bbox: 0.2772  loss_mask: 0.2757
2025/12/11 12:31:22 - mmengine - INFO - Epoch(train)  [3][6250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:07:38  time: 1.9895  data_time: 0.0052  memory: 44162  loss: 0.8411  loss_rpn_cls: 0.0392  loss_rpn_bbox: 0.0442  loss_cls: 0.2244  acc: 91.2354  loss_bbox: 0.2600  loss_mask: 0.2733
2025/12/11 12:33:00 - mmengine - INFO - Epoch(train)  [3][6300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:05:53  time: 1.9599  data_time: 0.0043  memory: 44550  loss: 0.8753  loss_rpn_cls: 0.0422  loss_rpn_bbox: 0.0477  loss_cls: 0.2415  acc: 93.0298  loss_bbox: 0.2728  loss_mask: 0.2711
2025/12/11 12:34:18 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 12:34:36 - mmengine - INFO - Epoch(train)  [3][6350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:04:04  time: 1.9356  data_time: 0.0043  memory: 43105  loss: 0.8531  loss_rpn_cls: 0.0372  loss_rpn_bbox: 0.0439  loss_cls: 0.2340  acc: 92.7490  loss_bbox: 0.2680  loss_mask: 0.2700
2025/12/11 12:36:15 - mmengine - INFO - Epoch(train)  [3][6400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:02:22  time: 1.9750  data_time: 0.0045  memory: 41814  loss: 0.8341  loss_rpn_cls: 0.0378  loss_rpn_bbox: 0.0444  loss_cls: 0.2275  acc: 91.7480  loss_bbox: 0.2535  loss_mask: 0.2708
2025/12/11 12:37:51 - mmengine - INFO - Epoch(train)  [3][6450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:00:29  time: 1.9070  data_time: 0.0038  memory: 42658  loss: 0.8467  loss_rpn_cls: 0.0400  loss_rpn_bbox: 0.0459  loss_cls: 0.2298  acc: 91.7358  loss_bbox: 0.2596  loss_mask: 0.2715
2025/12/11 12:39:27 - mmengine - INFO - Epoch(train)  [3][6500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:58:39  time: 1.9278  data_time: 0.0046  memory: 41919  loss: 0.8573  loss_rpn_cls: 0.0403  loss_rpn_bbox: 0.0462  loss_cls: 0.2285  acc: 94.9707  loss_bbox: 0.2665  loss_mask: 0.2758
2025/12/11 12:41:05 - mmengine - INFO - Epoch(train)  [3][6550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:56:54  time: 1.9590  data_time: 0.0046  memory: 43353  loss: 0.8514  loss_rpn_cls: 0.0391  loss_rpn_bbox: 0.0448  loss_cls: 0.2260  acc: 90.4175  loss_bbox: 0.2679  loss_mask: 0.2735
2025/12/11 12:42:41 - mmengine - INFO - Epoch(train)  [3][6600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:55:03  time: 1.9241  data_time: 0.0039  memory: 44236  loss: 0.8536  loss_rpn_cls: 0.0388  loss_rpn_bbox: 0.0454  loss_cls: 0.2311  acc: 89.6973  loss_bbox: 0.2649  loss_mask: 0.2734
2025/12/11 12:44:18 - mmengine - INFO - Epoch(train)  [3][6650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:53:17  time: 1.9478  data_time: 0.0044  memory: 44468  loss: 0.8541  loss_rpn_cls: 0.0387  loss_rpn_bbox: 0.0459  loss_cls: 0.2306  acc: 92.2852  loss_bbox: 0.2667  loss_mask: 0.2722
2025/12/11 12:45:58 - mmengine - INFO - Epoch(train)  [3][6700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:51:37  time: 1.9916  data_time: 0.0047  memory: 41778  loss: 0.8627  loss_rpn_cls: 0.0430  loss_rpn_bbox: 0.0469  loss_cls: 0.2374  acc: 93.5913  loss_bbox: 0.2666  loss_mask: 0.2688
2025/12/11 12:47:38 - mmengine - INFO - Epoch(train)  [3][6750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:49:59  time: 2.0030  data_time: 0.0051  memory: 43172  loss: 0.8719  loss_rpn_cls: 0.0413  loss_rpn_bbox: 0.0476  loss_cls: 0.2427  acc: 91.6382  loss_bbox: 0.2702  loss_mask: 0.2700
2025/12/11 12:49:18 - mmengine - INFO - Epoch(train)  [3][6800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:48:19  time: 1.9884  data_time: 0.0046  memory: 43966  loss: 0.8672  loss_rpn_cls: 0.0395  loss_rpn_bbox: 0.0480  loss_cls: 0.2337  acc: 92.2607  loss_bbox: 0.2691  loss_mask: 0.2769
2025/12/11 12:50:59 - mmengine - INFO - Epoch(train)  [3][6850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:46:44  time: 2.0264  data_time: 0.0049  memory: 43089  loss: 0.8472  loss_rpn_cls: 0.0393  loss_rpn_bbox: 0.0449  loss_cls: 0.2269  acc: 92.7246  loss_bbox: 0.2634  loss_mask: 0.2728
2025/12/11 12:52:37 - mmengine - INFO - Epoch(train)  [3][6900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:44:58  time: 1.9513  data_time: 0.0035  memory: 42549  loss: 0.8473  loss_rpn_cls: 0.0404  loss_rpn_bbox: 0.0440  loss_cls: 0.2301  acc: 91.9800  loss_bbox: 0.2634  loss_mask: 0.2694
2025/12/11 12:54:13 - mmengine - INFO - Epoch(train)  [3][6950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:43:10  time: 1.9353  data_time: 0.0033  memory: 43201  loss: 0.8451  loss_rpn_cls: 0.0377  loss_rpn_bbox: 0.0437  loss_cls: 0.2317  acc: 93.9331  loss_bbox: 0.2657  loss_mask: 0.2663
2025/12/11 12:55:48 - mmengine - INFO - Epoch(train)  [3][7000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:41:16  time: 1.9004  data_time: 0.0033  memory: 42390  loss: 0.8717  loss_rpn_cls: 0.0425  loss_rpn_bbox: 0.0479  loss_cls: 0.2334  acc: 93.6035  loss_bbox: 0.2745  loss_mask: 0.2735
2025/12/11 12:57:26 - mmengine - INFO - Epoch(train)  [3][7050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:39:30  time: 1.9512  data_time: 0.0036  memory: 43743  loss: 0.8464  loss_rpn_cls: 0.0403  loss_rpn_bbox: 0.0451  loss_cls: 0.2257  acc: 90.2954  loss_bbox: 0.2641  loss_mask: 0.2712
2025/12/11 12:59:02 - mmengine - INFO - Epoch(train)  [3][7100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:37:40  time: 1.9235  data_time: 0.0034  memory: 43891  loss: 0.8821  loss_rpn_cls: 0.0403  loss_rpn_bbox: 0.0465  loss_cls: 0.2390  acc: 92.0776  loss_bbox: 0.2807  loss_mask: 0.2757
2025/12/11 13:00:38 - mmengine - INFO - Epoch(train)  [3][7150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:35:48  time: 1.9089  data_time: 0.0031  memory: 42143  loss: 0.8440  loss_rpn_cls: 0.0380  loss_rpn_bbox: 0.0429  loss_cls: 0.2284  acc: 92.2729  loss_bbox: 0.2651  loss_mask: 0.2695
2025/12/11 13:02:13 - mmengine - INFO - Epoch(train)  [3][7200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:33:58  time: 1.9190  data_time: 0.0036  memory: 42979  loss: 0.8781  loss_rpn_cls: 0.0408  loss_rpn_bbox: 0.0488  loss_cls: 0.2430  acc: 89.3311  loss_bbox: 0.2779  loss_mask: 0.2677
2025/12/11 13:03:49 - mmengine - INFO - Epoch(train)  [3][7250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:32:05  time: 1.9025  data_time: 0.0039  memory: 42799  loss: 0.8640  loss_rpn_cls: 0.0428  loss_rpn_bbox: 0.0462  loss_cls: 0.2310  acc: 88.0737  loss_bbox: 0.2680  loss_mask: 0.2760
2025/12/11 13:05:24 - mmengine - INFO - Epoch(train)  [3][7300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:30:13  time: 1.9088  data_time: 0.0042  memory: 43436  loss: 0.8771  loss_rpn_cls: 0.0447  loss_rpn_bbox: 0.0483  loss_cls: 0.2321  acc: 92.1021  loss_bbox: 0.2767  loss_mask: 0.2753
2025/12/11 13:06:17 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 13:06:17 - mmengine - INFO - Saving checkpoint at 3 epochs
2025/12/11 13:08:12 - mmengine - INFO - Epoch(val)  [3][ 50/313]    eta: 0:09:37  time: 2.1942  data_time: 0.0519  memory: 43388  
2025/12/11 13:09:56 - mmengine - INFO - Epoch(val)  [3][100/313]    eta: 0:07:36  time: 2.0908  data_time: 0.0010  memory: 8290  
2025/12/11 13:11:41 - mmengine - INFO - Epoch(val)  [3][150/313]    eta: 0:05:46  time: 2.0970  data_time: 0.0010  memory: 8290  
2025/12/11 13:13:27 - mmengine - INFO - Epoch(val)  [3][200/313]    eta: 0:03:59  time: 2.1098  data_time: 0.0011  memory: 8290  
2025/12/11 13:15:15 - mmengine - INFO - Epoch(val)  [3][250/313]    eta: 0:02:14  time: 2.1565  data_time: 0.0015  memory: 8290  
2025/12/11 13:17:01 - mmengine - INFO - Epoch(val)  [3][300/313]    eta: 0:00:27  time: 2.1300  data_time: 0.0013  memory: 8290  
2025/12/11 13:17:36 - mmengine - INFO - Evaluating bbox...
2025/12/11 13:18:04 - mmengine - INFO - bbox_mAP_copypaste: 0.386 0.605 0.419 0.243 0.422 0.497
2025/12/11 13:18:04 - mmengine - INFO - Evaluating segm...
2025/12/11 13:18:37 - mmengine - INFO - segm_mAP_copypaste: 0.351 0.574 0.373 0.180 0.383 0.510
2025/12/11 13:18:38 - mmengine - INFO - Epoch(val) [3][313/313]    coco/bbox_mAP: 0.3860  coco/bbox_mAP_50: 0.6050  coco/bbox_mAP_75: 0.4190  coco/bbox_mAP_s: 0.2430  coco/bbox_mAP_m: 0.4220  coco/bbox_mAP_l: 0.4970  coco/segm_mAP: 0.3510  coco/segm_mAP_50: 0.5740  coco/segm_mAP_75: 0.3730  coco/segm_mAP_s: 0.1800  coco/segm_mAP_m: 0.3830  coco/segm_mAP_l: 0.5100  data_time: 0.0093  time: 2.1216
2025/12/11 13:19:03 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 13:20:21 - mmengine - INFO - Epoch(train)  [4][  50/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:27:25  time: 2.0743  data_time: 0.0593  memory: 43027  loss: 0.8278  loss_rpn_cls: 0.0380  loss_rpn_bbox: 0.0442  loss_cls: 0.2201  acc: 93.7622  loss_bbox: 0.2592  loss_mask: 0.2663
2025/12/11 13:21:59 - mmengine - INFO - Epoch(train)  [4][ 100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:25:39  time: 1.9438  data_time: 0.0044  memory: 42386  loss: 0.8164  loss_rpn_cls: 0.0375  loss_rpn_bbox: 0.0434  loss_cls: 0.2117  acc: 94.9707  loss_bbox: 0.2549  loss_mask: 0.2689
2025/12/11 13:23:34 - mmengine - INFO - Epoch(train)  [4][ 150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:23:47  time: 1.9103  data_time: 0.0037  memory: 42865  loss: 0.8319  loss_rpn_cls: 0.0389  loss_rpn_bbox: 0.0449  loss_cls: 0.2216  acc: 93.5425  loss_bbox: 0.2635  loss_mask: 0.2630
2025/12/11 13:25:11 - mmengine - INFO - Epoch(train)  [4][ 200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:22:00  time: 1.9352  data_time: 0.0044  memory: 42928  loss: 0.8451  loss_rpn_cls: 0.0395  loss_rpn_bbox: 0.0453  loss_cls: 0.2265  acc: 91.2964  loss_bbox: 0.2697  loss_mask: 0.2641
2025/12/11 13:26:50 - mmengine - INFO - Epoch(train)  [4][ 250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:20:20  time: 1.9909  data_time: 0.0049  memory: 43562  loss: 0.8231  loss_rpn_cls: 0.0389  loss_rpn_bbox: 0.0424  loss_cls: 0.2167  acc: 92.5293  loss_bbox: 0.2594  loss_mask: 0.2657
2025/12/11 13:28:29 - mmengine - INFO - Epoch(train)  [4][ 300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:18:38  time: 1.9739  data_time: 0.0043  memory: 42409  loss: 0.8492  loss_rpn_cls: 0.0407  loss_rpn_bbox: 0.0471  loss_cls: 0.2224  acc: 89.8804  loss_bbox: 0.2674  loss_mask: 0.2716
2025/12/11 13:30:06 - mmengine - INFO - Epoch(train)  [4][ 350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:16:52  time: 1.9472  data_time: 0.0069  memory: 41804  loss: 0.8094  loss_rpn_cls: 0.0363  loss_rpn_bbox: 0.0425  loss_cls: 0.2093  acc: 93.1152  loss_bbox: 0.2521  loss_mask: 0.2692
2025/12/11 13:31:43 - mmengine - INFO - Epoch(train)  [4][ 400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:15:05  time: 1.9384  data_time: 0.0042  memory: 43454  loss: 0.8466  loss_rpn_cls: 0.0389  loss_rpn_bbox: 0.0482  loss_cls: 0.2219  acc: 93.2007  loss_bbox: 0.2670  loss_mask: 0.2707
2025/12/11 13:33:20 - mmengine - INFO - Epoch(train)  [4][ 450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:13:18  time: 1.9365  data_time: 0.0039  memory: 43428  loss: 0.8275  loss_rpn_cls: 0.0396  loss_rpn_bbox: 0.0452  loss_cls: 0.2172  acc: 92.1875  loss_bbox: 0.2600  loss_mask: 0.2655
2025/12/11 13:34:58 - mmengine - INFO - Epoch(train)  [4][ 500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:11:32  time: 1.9497  data_time: 0.0041  memory: 43594  loss: 0.8411  loss_rpn_cls: 0.0421  loss_rpn_bbox: 0.0458  loss_cls: 0.2190  acc: 95.0562  loss_bbox: 0.2616  loss_mask: 0.2726
2025/12/11 13:36:35 - mmengine - INFO - Epoch(train)  [4][ 550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:09:47  time: 1.9533  data_time: 0.0045  memory: 42080  loss: 0.8300  loss_rpn_cls: 0.0390  loss_rpn_bbox: 0.0441  loss_cls: 0.2190  acc: 91.7725  loss_bbox: 0.2621  loss_mask: 0.2657
2025/12/11 13:38:13 - mmengine - INFO - Epoch(train)  [4][ 600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:08:02  time: 1.9483  data_time: 0.0040  memory: 42488  loss: 0.8465  loss_rpn_cls: 0.0394  loss_rpn_bbox: 0.0458  loss_cls: 0.2215  acc: 94.0063  loss_bbox: 0.2637  loss_mask: 0.2759
2025/12/11 13:39:51 - mmengine - INFO - Epoch(train)  [4][ 650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:06:18  time: 1.9607  data_time: 0.0039  memory: 41864  loss: 0.8220  loss_rpn_cls: 0.0360  loss_rpn_bbox: 0.0430  loss_cls: 0.2156  acc: 93.1763  loss_bbox: 0.2631  loss_mask: 0.2642
2025/12/11 13:41:28 - mmengine - INFO - Epoch(train)  [4][ 700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:04:32  time: 1.9416  data_time: 0.0041  memory: 44371  loss: 0.8554  loss_rpn_cls: 0.0391  loss_rpn_bbox: 0.0460  loss_cls: 0.2330  acc: 92.2607  loss_bbox: 0.2726  loss_mask: 0.2647
2025/12/11 13:43:04 - mmengine - INFO - Epoch(train)  [4][ 750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:02:43  time: 1.9249  data_time: 0.0039  memory: 42353  loss: 0.8273  loss_rpn_cls: 0.0389  loss_rpn_bbox: 0.0432  loss_cls: 0.2214  acc: 93.3594  loss_bbox: 0.2610  loss_mask: 0.2628
2025/12/11 13:44:38 - mmengine - INFO - Epoch(train)  [4][ 800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:00:49  time: 1.8873  data_time: 0.0033  memory: 41651  loss: 0.8305  loss_rpn_cls: 0.0384  loss_rpn_bbox: 0.0467  loss_cls: 0.2198  acc: 93.6035  loss_bbox: 0.2622  loss_mask: 0.2634
2025/12/11 13:46:14 - mmengine - INFO - Epoch(train)  [4][ 850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:58:57  time: 1.9041  data_time: 0.0033  memory: 45154  loss: 0.8185  loss_rpn_cls: 0.0345  loss_rpn_bbox: 0.0424  loss_cls: 0.2169  acc: 92.7246  loss_bbox: 0.2546  loss_mask: 0.2700
2025/12/11 13:47:49 - mmengine - INFO - Epoch(train)  [4][ 900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:57:05  time: 1.8967  data_time: 0.0033  memory: 42828  loss: 0.8295  loss_rpn_cls: 0.0400  loss_rpn_bbox: 0.0452  loss_cls: 0.2205  acc: 89.5386  loss_bbox: 0.2544  loss_mask: 0.2695
2025/12/11 13:49:24 - mmengine - INFO - Epoch(train)  [4][ 950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:55:14  time: 1.9092  data_time: 0.0034  memory: 42482  loss: 0.8150  loss_rpn_cls: 0.0386  loss_rpn_bbox: 0.0440  loss_cls: 0.2151  acc: 92.3096  loss_bbox: 0.2517  loss_mask: 0.2655
2025/12/11 13:50:59 - mmengine - INFO - Epoch(train)  [4][1000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:53:22  time: 1.9018  data_time: 0.0032  memory: 42371  loss: 0.8300  loss_rpn_cls: 0.0397  loss_rpn_bbox: 0.0458  loss_cls: 0.2169  acc: 92.9199  loss_bbox: 0.2593  loss_mask: 0.2684
2025/12/11 13:51:19 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 13:52:36 - mmengine - INFO - Epoch(train)  [4][1050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:51:35  time: 1.9332  data_time: 0.0038  memory: 43305  loss: 0.8200  loss_rpn_cls: 0.0368  loss_rpn_bbox: 0.0462  loss_cls: 0.2174  acc: 95.1782  loss_bbox: 0.2581  loss_mask: 0.2615
2025/12/11 13:54:14 - mmengine - INFO - Epoch(train)  [4][1100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:49:51  time: 1.9603  data_time: 0.0039  memory: 42694  loss: 0.8282  loss_rpn_cls: 0.0432  loss_rpn_bbox: 0.0474  loss_cls: 0.2185  acc: 90.1733  loss_bbox: 0.2556  loss_mask: 0.2634
2025/12/11 13:55:50 - mmengine - INFO - Epoch(train)  [4][1150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:48:02  time: 1.9200  data_time: 0.0036  memory: 43879  loss: 0.8443  loss_rpn_cls: 0.0403  loss_rpn_bbox: 0.0468  loss_cls: 0.2218  acc: 92.7856  loss_bbox: 0.2635  loss_mask: 0.2719
2025/12/11 13:57:24 - mmengine - INFO - Epoch(train)  [4][1200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:46:08  time: 1.8797  data_time: 0.0035  memory: 42481  loss: 0.8185  loss_rpn_cls: 0.0363  loss_rpn_bbox: 0.0429  loss_cls: 0.2177  acc: 92.0166  loss_bbox: 0.2581  loss_mask: 0.2636
2025/12/11 13:58:59 - mmengine - INFO - Epoch(train)  [4][1250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:44:16  time: 1.9007  data_time: 0.0035  memory: 42619  loss: 0.8225  loss_rpn_cls: 0.0379  loss_rpn_bbox: 0.0448  loss_cls: 0.2144  acc: 94.9585  loss_bbox: 0.2566  loss_mask: 0.2687
2025/12/11 14:00:34 - mmengine - INFO - Epoch(train)  [4][1300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:42:26  time: 1.9081  data_time: 0.0056  memory: 42114  loss: 0.8268  loss_rpn_cls: 0.0381  loss_rpn_bbox: 0.0467  loss_cls: 0.2192  acc: 90.5518  loss_bbox: 0.2542  loss_mask: 0.2685
2025/12/11 14:02:10 - mmengine - INFO - Epoch(train)  [4][1350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:40:36  time: 1.9099  data_time: 0.0038  memory: 43029  loss: 0.8134  loss_rpn_cls: 0.0335  loss_rpn_bbox: 0.0407  loss_cls: 0.2150  acc: 93.0176  loss_bbox: 0.2582  loss_mask: 0.2660
2025/12/11 14:03:46 - mmengine - INFO - Epoch(train)  [4][1400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:38:47  time: 1.9223  data_time: 0.0035  memory: 41792  loss: 0.8082  loss_rpn_cls: 0.0402  loss_rpn_bbox: 0.0438  loss_cls: 0.2083  acc: 90.7959  loss_bbox: 0.2529  loss_mask: 0.2630
2025/12/11 14:05:21 - mmengine - INFO - Epoch(train)  [4][1450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:36:58  time: 1.9130  data_time: 0.0041  memory: 43380  loss: 0.8250  loss_rpn_cls: 0.0369  loss_rpn_bbox: 0.0437  loss_cls: 0.2179  acc: 92.2852  loss_bbox: 0.2595  loss_mask: 0.2669
2025/12/11 14:06:57 - mmengine - INFO - Epoch(train)  [4][1500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:35:08  time: 1.9156  data_time: 0.0038  memory: 42264  loss: 0.8566  loss_rpn_cls: 0.0390  loss_rpn_bbox: 0.0460  loss_cls: 0.2308  acc: 91.1011  loss_bbox: 0.2737  loss_mask: 0.2671
2025/12/11 14:08:35 - mmengine - INFO - Epoch(train)  [4][1550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:33:24  time: 1.9501  data_time: 0.0038  memory: 44191  loss: 0.8516  loss_rpn_cls: 0.0385  loss_rpn_bbox: 0.0475  loss_cls: 0.2280  acc: 90.2100  loss_bbox: 0.2687  loss_mask: 0.2690
2025/12/11 14:10:12 - mmengine - INFO - Epoch(train)  [4][1600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:31:38  time: 1.9389  data_time: 0.0039  memory: 43916  loss: 0.8100  loss_rpn_cls: 0.0346  loss_rpn_bbox: 0.0421  loss_cls: 0.2157  acc: 93.1885  loss_bbox: 0.2583  loss_mask: 0.2593
2025/12/11 14:11:49 - mmengine - INFO - Epoch(train)  [4][1650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:29:53  time: 1.9479  data_time: 0.0037  memory: 42314  loss: 0.8149  loss_rpn_cls: 0.0343  loss_rpn_bbox: 0.0426  loss_cls: 0.2138  acc: 92.1875  loss_bbox: 0.2587  loss_mask: 0.2656
2025/12/11 14:13:26 - mmengine - INFO - Epoch(train)  [4][1700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:28:08  time: 1.9437  data_time: 0.0036  memory: 43627  loss: 0.8363  loss_rpn_cls: 0.0389  loss_rpn_bbox: 0.0476  loss_cls: 0.2206  acc: 88.8306  loss_bbox: 0.2617  loss_mask: 0.2675
2025/12/11 14:15:05 - mmengine - INFO - Epoch(train)  [4][1750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:26:27  time: 1.9761  data_time: 0.0044  memory: 43848  loss: 0.8218  loss_rpn_cls: 0.0377  loss_rpn_bbox: 0.0442  loss_cls: 0.2158  acc: 92.0776  loss_bbox: 0.2615  loss_mask: 0.2626
2025/12/11 14:16:42 - mmengine - INFO - Epoch(train)  [4][1800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:24:40  time: 1.9290  data_time: 0.0039  memory: 41930  loss: 0.8431  loss_rpn_cls: 0.0371  loss_rpn_bbox: 0.0446  loss_cls: 0.2231  acc: 92.0044  loss_bbox: 0.2664  loss_mask: 0.2719
2025/12/11 14:18:19 - mmengine - INFO - Epoch(train)  [4][1850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:22:55  time: 1.9433  data_time: 0.0043  memory: 44340  loss: 0.8160  loss_rpn_cls: 0.0381  loss_rpn_bbox: 0.0443  loss_cls: 0.2165  acc: 92.5659  loss_bbox: 0.2546  loss_mask: 0.2624
2025/12/11 14:19:55 - mmengine - INFO - Epoch(train)  [4][1900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:21:09  time: 1.9360  data_time: 0.0038  memory: 43234  loss: 0.8391  loss_rpn_cls: 0.0430  loss_rpn_bbox: 0.0457  loss_cls: 0.2264  acc: 94.1040  loss_bbox: 0.2589  loss_mask: 0.2650
2025/12/11 14:21:31 - mmengine - INFO - Epoch(train)  [4][1950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:19:20  time: 1.9103  data_time: 0.0038  memory: 42839  loss: 0.8074  loss_rpn_cls: 0.0368  loss_rpn_bbox: 0.0402  loss_cls: 0.2154  acc: 92.0654  loss_bbox: 0.2499  loss_mask: 0.2652
2025/12/11 14:23:07 - mmengine - INFO - Epoch(train)  [4][2000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:17:31  time: 1.9184  data_time: 0.0037  memory: 43216  loss: 0.8351  loss_rpn_cls: 0.0400  loss_rpn_bbox: 0.0436  loss_cls: 0.2218  acc: 92.2729  loss_bbox: 0.2621  loss_mask: 0.2675
2025/12/11 14:23:26 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_s_1x_coco_20251211_002407
2025/12/11 14:24:46 - mmengine - INFO - Epoch(train)  [4][2050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:15:52  time: 1.9885  data_time: 0.0044  memory: 42627  loss: 0.8290  loss_rpn_cls: 0.0366  loss_rpn_bbox: 0.0431  loss_cls: 0.2207  acc: 92.4438  loss_bbox: 0.2624  loss_mask: 0.2662
2025/12/11 14:26:23 - mmengine - INFO - Epoch(train)  [4][2100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:14:05  time: 1.9254  data_time: 0.0042  memory: 44285  loss: 0.8388  loss_rpn_cls: 0.0384  loss_rpn_bbox: 0.0480  loss_cls: 0.2205  acc: 91.1255  loss_bbox: 0.2636  loss_mask: 0.2683
2025/12/11 14:28:01 - mmengine - INFO - Epoch(train)  [4][2150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:12:23  time: 1.9693  data_time: 0.0044  memory: 42036  loss: 0.8381  loss_rpn_cls: 0.0398  loss_rpn_bbox: 0.0475  loss_cls: 0.2242  acc: 94.1284  loss_bbox: 0.2667  loss_mask: 0.2600
2025/12/11 14:29:42 - mmengine - INFO - Epoch(train)  [4][2200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:10:47  time: 2.0115  data_time: 0.0049  memory: 43942  loss: 0.8297  loss_rpn_cls: 0.0387  loss_rpn_bbox: 0.0426  loss_cls: 0.2193  acc: 94.4092  loss_bbox: 0.2595  loss_mask: 0.2697
2025/12/11 14:31:21 - mmengine - INFO - Epoch(train)  [4][2250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 11:09:08  time: 1.9873  data_time: 0.0048  memory: 42116  loss: 0.8173  loss_rpn_cls: 0.0357  loss_rpn_bbox: 0.0417  loss_cls: 0.2174  acc: 93.9331  loss_bbox: 0.2545  loss_mask: 0.2679
