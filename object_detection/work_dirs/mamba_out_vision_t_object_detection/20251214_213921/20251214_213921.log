2025/12/14 21:39:23 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.25 (main, Nov  3 2025, 22:33:05) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 114160416
    GPU 0,1,2,3: NVIDIA GeForce RTX 3090
    CUDA_HOME: /usr/local/cuda
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
    PyTorch: 2.1.2+cu118
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.2+cu118
    OpenCV: 4.11.0
    MMEngine: 0.10.3

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 114160416
    Distributed launcher: pytorch
    Distributed training: True
    GPU number: 4
------------------------------------------------------------

2025/12/14 21:39:24 - mmengine - INFO - Config:
accum_steps = 1
auto_scale_lr = dict(base_batch_size=16, enable=False)
backend_args = None
batch_size_per_gpu = 4
data_root = './coco/'
dataset_type = 'CocoDataset'
default_hooks = dict(
    checkpoint=dict(interval=1, type='CheckpointHook'),
    logger=dict(interval=50, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='DetVisualizationHook'))
default_scope = 'mmdet'
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
launcher = 'pytorch'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)
log_root = './log_dirs/mamba_out_vision_t_object_detection'
max_epochs = 12
model = dict(
    backbone=dict(
        depth=50,
        depths=(
            1,
            3,
            8,
            4,
        ),
        dim=80,
        drop_path_rate=0.2,
        frozen_stages=1,
        in_dim=32,
        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),
        layer_scale=None,
        mlp_ratio=4,
        norm_cfg=dict(requires_grad=True, type='BN'),
        norm_eval=True,
        norm_layer='ln2d',
        num_heads=(
            2,
            4,
            8,
            16,
        ),
        num_stages=4,
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        pretrained='../models/mamba_out_vision_T-224/model_best.pth.tar',
        style='pytorch',
        type='MM_mamba_out_vision',
        window_size=(
            8,
            8,
            112,
            56,
        )),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_mask=True,
        pad_size_divisor=32,
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='DetDataPreprocessor'),
    neck=dict(
        in_channels=[
            80,
            160,
            320,
            640,
        ],
        num_outs=5,
        out_channels=256,
        type='FPN'),
    roi_head=dict(
        bbox_head=dict(
            bbox_coder=dict(
                target_means=[
                    0.0,
                    0.0,
                    0.0,
                    0.0,
                ],
                target_stds=[
                    0.1,
                    0.1,
                    0.2,
                    0.2,
                ],
                type='DeltaXYWHBBoxCoder'),
            conv_out_channels=256,
            fc_out_channels=1024,
            in_channels=256,
            loss_bbox=dict(loss_weight=10.0, type='GIoULoss'),
            loss_cls=dict(
                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
            norm_cfg=dict(requires_grad=True, type='SyncBN'),
            num_classes=80,
            num_shared_convs=4,
            num_shared_fcs=1,
            reg_class_agnostic=False,
            reg_decoded_bbox=True,
            roi_feat_size=7,
            type='ConvFCBBoxHead'),
        bbox_roi_extractor=dict(
            featmap_strides=[
                4,
                8,
                16,
                32,
            ],
            out_channels=256,
            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),
            type='SingleRoIExtractor'),
        mask_head=dict(
            conv_out_channels=256,
            in_channels=256,
            loss_mask=dict(
                loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),
            num_classes=80,
            num_convs=4,
            type='FCNMaskHead'),
        mask_roi_extractor=dict(
            featmap_strides=[
                4,
                8,
                16,
                32,
            ],
            out_channels=256,
            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),
            type='SingleRoIExtractor'),
        type='StandardRoIHead'),
    rpn_head=dict(
        anchor_generator=dict(
            ratios=[
                0.5,
                1.0,
                2.0,
            ],
            scales=[
                8,
            ],
            strides=[
                4,
                8,
                16,
                32,
                64,
            ],
            type='AnchorGenerator'),
        bbox_coder=dict(
            target_means=[
                0.0,
                0.0,
                0.0,
                0.0,
            ],
            target_stds=[
                1.0,
                1.0,
                1.0,
                1.0,
            ],
            type='DeltaXYWHBBoxCoder'),
        feat_channels=256,
        in_channels=256,
        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),
        loss_cls=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),
        type='RPNHead'),
    test_cfg=dict(
        rcnn=dict(
            mask_thr_binary=0.5,
            max_per_img=100,
            nms=dict(iou_threshold=0.5, type='nms'),
            score_thr=0.05),
        rpn=dict(
            max_per_img=1000,
            min_bbox_size=0,
            nms=dict(iou_threshold=0.7, type='nms'),
            nms_pre=1000)),
    train_cfg=dict(
        rcnn=dict(
            assigner=dict(
                ignore_iof_thr=-1,
                match_low_quality=True,
                min_pos_iou=0.5,
                neg_iou_thr=0.5,
                pos_iou_thr=0.5,
                type='MaxIoUAssigner'),
            debug=False,
            mask_size=28,
            pos_weight=-1,
            sampler=dict(
                add_gt_as_proposals=True,
                neg_pos_ub=-1,
                num=512,
                pos_fraction=0.25,
                type='RandomSampler')),
        rpn=dict(
            allowed_border=-1,
            assigner=dict(
                ignore_iof_thr=-1,
                match_low_quality=True,
                min_pos_iou=0.3,
                neg_iou_thr=0.3,
                pos_iou_thr=0.7,
                type='MaxIoUAssigner'),
            debug=False,
            pos_weight=-1,
            sampler=dict(
                add_gt_as_proposals=False,
                neg_pos_ub=-1,
                num=256,
                pos_fraction=0.5,
                type='RandomSampler')),
        rpn_proposal=dict(
            max_per_img=1000,
            min_bbox_size=0,
            nms=dict(iou_threshold=0.7, type='nms'),
            nms_pre=2000)),
    type='MaskRCNN')
num_gpus = 4
optim_wrapper = dict(
    accumulative_counts=1,
    loss_scale='dynamic',
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ), lr=0.0001, type='AdamW', weight_decay=0.05),
    paramwise_cfg=dict(custom_keys=dict(norm=dict(decay_mult=0.0))),
    type='AmpOptimWrapper')
param_scheduler = [
    dict(
        begin=0, by_epoch=False, end=1000, start_factor=0.001,
        type='LinearLR'),
    dict(
        begin=0,
        by_epoch=True,
        end=12,
        gamma=0.1,
        milestones=[
            8,
            11,
        ],
        type='MultiStepLR'),
]
resume = True
run_name = 'mamba_out_vision_t_object_detection'
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=4,
    dataset=dict(
        ann_file='annotations/instances_val2017.json',
        backend_args=None,
        data_prefix=dict(img='val2017/'),
        data_root='./coco/',
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                1333,
                800,
            ), type='Resize'),
            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackDetInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=4,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    ann_file='./coco/annotations/instances_val2017.json',
    backend_args=None,
    format_only=False,
    metric=[
        'bbox',
        'segm',
    ],
    type='CocoMetric')
test_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        1333,
        800,
    ), type='Resize'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(
        meta_keys=(
            'img_id',
            'img_path',
            'ori_shape',
            'img_shape',
            'scale_factor',
        ),
        type='PackDetInputs'),
]
total_batch_size = 16
train_cfg = dict(max_epochs=12, type='EpochBasedTrainLoop', val_interval=1)
train_dataloader = dict(
    batch_sampler=dict(type='AspectRatioBatchSampler'),
    batch_size=4,
    dataset=dict(
        ann_file='annotations/instances_train2017.json',
        backend_args=None,
        data_prefix=dict(img='train2017/'),
        data_root='./coco/',
        filter_cfg=dict(filter_empty_gt=True, min_size=32),
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
            dict(prob=0.5, type='RandomFlip'),
            dict(
                transforms=[
                    [
                        dict(
                            keep_ratio=True,
                            scales=[
                                (
                                    480,
                                    1333,
                                ),
                                (
                                    512,
                                    1333,
                                ),
                                (
                                    544,
                                    1333,
                                ),
                                (
                                    576,
                                    1333,
                                ),
                                (
                                    608,
                                    1333,
                                ),
                                (
                                    640,
                                    1333,
                                ),
                                (
                                    672,
                                    1333,
                                ),
                                (
                                    704,
                                    1333,
                                ),
                                (
                                    736,
                                    1333,
                                ),
                                (
                                    768,
                                    1333,
                                ),
                                (
                                    800,
                                    1333,
                                ),
                            ],
                            type='RandomChoiceResize'),
                    ],
                    [
                        dict(
                            keep_ratio=True,
                            scales=[
                                (
                                    400,
                                    1333,
                                ),
                                (
                                    500,
                                    1333,
                                ),
                                (
                                    600,
                                    1333,
                                ),
                            ],
                            type='RandomChoiceResize'),
                        dict(
                            allow_negative_crop=True,
                            crop_size=(
                                384,
                                600,
                            ),
                            crop_type='absolute_range',
                            type='RandomCrop'),
                        dict(
                            keep_ratio=True,
                            scales=[
                                (
                                    480,
                                    1333,
                                ),
                                (
                                    512,
                                    1333,
                                ),
                                (
                                    544,
                                    1333,
                                ),
                                (
                                    576,
                                    1333,
                                ),
                                (
                                    608,
                                    1333,
                                ),
                                (
                                    640,
                                    1333,
                                ),
                                (
                                    672,
                                    1333,
                                ),
                                (
                                    704,
                                    1333,
                                ),
                                (
                                    736,
                                    1333,
                                ),
                                (
                                    768,
                                    1333,
                                ),
                                (
                                    800,
                                    1333,
                                ),
                            ],
                            type='RandomChoiceResize'),
                    ],
                ],
                type='RandomChoice'),
            dict(type='PackDetInputs'),
        ],
        type='CocoDataset'),
    num_workers=4,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=True, type='DefaultSampler'))
train_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(prob=0.5, type='RandomFlip'),
    dict(
        transforms=[
            [
                dict(
                    keep_ratio=True,
                    scales=[
                        (
                            480,
                            1333,
                        ),
                        (
                            512,
                            1333,
                        ),
                        (
                            544,
                            1333,
                        ),
                        (
                            576,
                            1333,
                        ),
                        (
                            608,
                            1333,
                        ),
                        (
                            640,
                            1333,
                        ),
                        (
                            672,
                            1333,
                        ),
                        (
                            704,
                            1333,
                        ),
                        (
                            736,
                            1333,
                        ),
                        (
                            768,
                            1333,
                        ),
                        (
                            800,
                            1333,
                        ),
                    ],
                    type='RandomChoiceResize'),
            ],
            [
                dict(
                    keep_ratio=True,
                    scales=[
                        (
                            400,
                            1333,
                        ),
                        (
                            500,
                            1333,
                        ),
                        (
                            600,
                            1333,
                        ),
                    ],
                    type='RandomChoiceResize'),
                dict(
                    allow_negative_crop=True,
                    crop_size=(
                        384,
                        600,
                    ),
                    crop_type='absolute_range',
                    type='RandomCrop'),
                dict(
                    keep_ratio=True,
                    scales=[
                        (
                            480,
                            1333,
                        ),
                        (
                            512,
                            1333,
                        ),
                        (
                            544,
                            1333,
                        ),
                        (
                            576,
                            1333,
                        ),
                        (
                            608,
                            1333,
                        ),
                        (
                            640,
                            1333,
                        ),
                        (
                            672,
                            1333,
                        ),
                        (
                            704,
                            1333,
                        ),
                        (
                            736,
                            1333,
                        ),
                        (
                            768,
                            1333,
                        ),
                        (
                            800,
                            1333,
                        ),
                    ],
                    type='RandomChoiceResize'),
            ],
        ],
        type='RandomChoice'),
    dict(type='PackDetInputs'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=4,
    dataset=dict(
        ann_file='annotations/instances_val2017.json',
        backend_args=None,
        data_prefix=dict(img='val2017/'),
        data_root='./coco/',
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                1333,
                800,
            ), type='Resize'),
            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackDetInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=4,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    ann_file='./coco/annotations/instances_val2017.json',
    backend_args=None,
    format_only=False,
    metric=[
        'bbox',
        'segm',
    ],
    type='CocoMetric')
vis_backends = [
    dict(
        save_dir='./log_dirs/mamba_out_vision_t_object_detection',
        type='TensorboardVisBackend'),
    dict(
        save_dir='./log_dirs/mamba_out_vision_t_object_detection',
        type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='DetLocalVisualizer',
    vis_backends=[
        dict(
            save_dir='./log_dirs/mamba_out_vision_t_object_detection',
            type='TensorboardVisBackend'),
        dict(
            save_dir='./log_dirs/mamba_out_vision_t_object_detection',
            type='LocalVisBackend'),
    ])
work_dir = '../work_dirs/mamba_out_vision_t_object_detection'

2025/12/14 21:39:28 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm1.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm1.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm1.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm1.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm1.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm1.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm2.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm2.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm2.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm2.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm2.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm2.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm1.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm1.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm1.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm1.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm1.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm1.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm2.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm2.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm2.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm2.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm2.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm2.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm1.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm1.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm1.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm1.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm1.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm1.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm2.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm2.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm2.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm2.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm2.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm2.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm1.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm1.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm1.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm1.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm1.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm1.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm2.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm2.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm2.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm2.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm2.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm2.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm1.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm1.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm1.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm1.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm1.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm1.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm2.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm2.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm2.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm2.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm2.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm2.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm1.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm1.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm1.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm1.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm1.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm1.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm2.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm2.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm2.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm2.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm2.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm2.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm1.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm1.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm1.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm1.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm1.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm1.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm2.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm2.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm2.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm2.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm2.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm2.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm1.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm1.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm1.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm1.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm1.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm1.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm2.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm2.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm2.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm2.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm2.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm2.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm1.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm1.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm1.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm1.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm1.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm1.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm2.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm2.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm2.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm2.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm2.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm2.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm1.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm1.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm1.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm1.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm1.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm1.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm2.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm2.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm2.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm2.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm2.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm2.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm1.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm1.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm1.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm1.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm1.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm1.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm2.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm2.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm2.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm2.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm2.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm2.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm1.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm1.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm1.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm1.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm1.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm1.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm2.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm2.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm2.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm2.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm2.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm2.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm1.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm1.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm1.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm1.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm1.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm1.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm2.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm2.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm2.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm2.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm2.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm2.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm1.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm1.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm1.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm1.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm1.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm1.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm2.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm2.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm2.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm2.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm2.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm2.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm1.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm1.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm1.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm1.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm1.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm1.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm2.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm2.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm2.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm2.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm2.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm2.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm1.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm1.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm1.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm1.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm1.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm1.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm2.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm2.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm2.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm2.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm2.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm2.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm0.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm0.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm0.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm0.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm0.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm0.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm1.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm1.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm1.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm1.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm1.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm1.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm2.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm2.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm2.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm2.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm2.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm2.bias:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm3.weight:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm3.weight:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm3.weight:decay_mult=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm3.bias:lr=0.0001
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm3.bias:weight_decay=0.0
2025/12/14 21:40:07 - mmengine - INFO - paramwise_options -- backbone.outnorm3.bias:decay_mult=0.0
Name of parameter - Initialization information

backbone.patch_embed.conv_down.0.weight - torch.Size([32, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.patch_embed.conv_down.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.patch_embed.conv_down.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.patch_embed.conv_down.3.weight - torch.Size([80, 32, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.patch_embed.conv_down.4.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.patch_embed.conv_down.4.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.conv1.weight - torch.Size([80, 80, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.conv1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.norm1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.norm1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.conv2.weight - torch.Size([80, 80, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.conv2.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.norm2.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.norm2.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.downsample.reduction.0.weight - torch.Size([160, 80, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.conv1.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.conv1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.norm1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.norm1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.conv2.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.conv2.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.norm2.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.norm2.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.conv1.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.conv1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.norm1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.norm1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.conv2.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.conv2.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.norm2.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.norm2.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.conv1.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.conv1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.norm1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.norm1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.conv2.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.conv2.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.norm2.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.norm2.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.downsample.reduction.0.weight - torch.Size([320, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mixer.in_proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mixer.out_proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mixer.conv1d_x.weight - torch.Size([160, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mixer.conv1d_z.weight - torch.Size([160, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mlp.fc1.weight - torch.Size([1280, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mlp.fc2.weight - torch.Size([320, 1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mixer.in_proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mixer.out_proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mixer.conv1d_x.weight - torch.Size([160, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mixer.conv1d_z.weight - torch.Size([160, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mlp.fc1.weight - torch.Size([1280, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mlp.fc2.weight - torch.Size([320, 1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mixer.in_proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mixer.out_proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mixer.conv1d_x.weight - torch.Size([160, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mixer.conv1d_z.weight - torch.Size([160, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mlp.fc1.weight - torch.Size([1280, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mlp.fc2.weight - torch.Size([320, 1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mixer.in_proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mixer.out_proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mixer.conv1d_x.weight - torch.Size([160, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mixer.conv1d_z.weight - torch.Size([160, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mlp.fc1.weight - torch.Size([1280, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mlp.fc2.weight - torch.Size([320, 1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mixer.qkv.weight - torch.Size([960, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mixer.qkv.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mixer.proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mixer.proj.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mlp.fc1.weight - torch.Size([1280, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mlp.fc2.weight - torch.Size([320, 1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mixer.qkv.weight - torch.Size([960, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mixer.qkv.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mixer.proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mixer.proj.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mlp.fc1.weight - torch.Size([1280, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mlp.fc2.weight - torch.Size([320, 1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mixer.qkv.weight - torch.Size([960, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mixer.qkv.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mixer.proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mixer.proj.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mlp.fc1.weight - torch.Size([1280, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mlp.fc2.weight - torch.Size([320, 1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.mixer.qkv.weight - torch.Size([960, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.mixer.qkv.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.mixer.proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.mixer.proj.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.mlp.fc1.weight - torch.Size([1280, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.mlp.fc2.weight - torch.Size([320, 1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.downsample.reduction.0.weight - torch.Size([640, 320, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.norm1.weight - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.norm1.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mixer.in_proj.weight - torch.Size([640, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mixer.out_proj.weight - torch.Size([640, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mixer.conv1d_x.weight - torch.Size([320, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mixer.conv1d_z.weight - torch.Size([320, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.norm2.weight - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.norm2.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mlp.fc1.weight - torch.Size([2560, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mlp.fc1.bias - torch.Size([2560]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mlp.fc2.weight - torch.Size([640, 2560]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mlp.fc2.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.norm1.weight - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.norm1.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mixer.in_proj.weight - torch.Size([640, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mixer.out_proj.weight - torch.Size([640, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mixer.conv1d_x.weight - torch.Size([320, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mixer.conv1d_z.weight - torch.Size([320, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.norm2.weight - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.norm2.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mlp.fc1.weight - torch.Size([2560, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mlp.fc1.bias - torch.Size([2560]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mlp.fc2.weight - torch.Size([640, 2560]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mlp.fc2.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.norm1.weight - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.norm1.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mixer.qkv.weight - torch.Size([1920, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mixer.qkv.bias - torch.Size([1920]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mixer.proj.weight - torch.Size([640, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mixer.proj.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.norm2.weight - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.norm2.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mlp.fc1.weight - torch.Size([2560, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mlp.fc1.bias - torch.Size([2560]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mlp.fc2.weight - torch.Size([640, 2560]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mlp.fc2.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.norm1.weight - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.norm1.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mixer.qkv.weight - torch.Size([1920, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mixer.qkv.bias - torch.Size([1920]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mixer.proj.weight - torch.Size([640, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mixer.proj.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.norm2.weight - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.norm2.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mlp.fc1.weight - torch.Size([2560, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mlp.fc1.bias - torch.Size([2560]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mlp.fc2.weight - torch.Size([640, 2560]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mlp.fc2.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm0.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm0.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm3.weight - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm3.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.lateral_convs.0.conv.weight - torch.Size([256, 80, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.lateral_convs.1.conv.weight - torch.Size([256, 160, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.lateral_convs.2.conv.weight - torch.Size([256, 320, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.lateral_convs.3.conv.weight - torch.Size([256, 640, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_conv.bias - torch.Size([256]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.bias - torch.Size([3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.weight - torch.Size([12, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.bias - torch.Size([12]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.fc_cls.weight - torch.Size([81, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.fc_cls.bias - torch.Size([81]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.fc_reg.weight - torch.Size([320, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.fc_reg.bias - torch.Size([320]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.shared_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.mask_head.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.mask_head.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.mask_head.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.mask_head.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.mask_head.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.mask_head.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.mask_head.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.mask_head.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.mask_head.upsample.weight - torch.Size([256, 256, 2, 2]): 
Initialized by user-defined `init_weights` in FCNMaskHead  

roi_head.mask_head.upsample.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in FCNMaskHead  

roi_head.mask_head.conv_logits.weight - torch.Size([80, 256, 1, 1]): 
Initialized by user-defined `init_weights` in FCNMaskHead  

roi_head.mask_head.conv_logits.bias - torch.Size([80]): 
Initialized by user-defined `init_weights` in FCNMaskHead  
2025/12/14 21:40:11 - mmengine - INFO - Auto resumed from the latest checkpoint /home/chenhao/MambaVision/work_dirs/mamba_out_vision_t_object_detection/epoch_9.pth.
2025/12/14 21:40:11 - mmengine - INFO - Load checkpoint from /home/chenhao/MambaVision/work_dirs/mamba_out_vision_t_object_detection/epoch_9.pth
2025/12/14 21:40:11 - mmengine - INFO - resumed epoch: 9, iter: 65970
2025/12/14 21:40:11 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2025/12/14 21:40:11 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2025/12/14 21:40:11 - mmengine - INFO - Checkpoints will be saved to /home/chenhao/MambaVision/work_dirs/mamba_out_vision_t_object_detection.
2025/12/14 21:40:46 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/14 21:41:06 - mmengine - INFO - Epoch(train) [10][  50/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 6:40:19  time: 1.0948  data_time: 0.0209  memory: 9529  loss: 0.7202  loss_rpn_cls: 0.0342  loss_rpn_bbox: 0.0399  loss_cls: 0.1778  acc: 95.6055  loss_bbox: 0.2307  loss_mask: 0.2375
2025/12/14 21:41:57 - mmengine - INFO - Epoch(train) [10][ 100/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 6:26:01  time: 1.0214  data_time: 0.0035  memory: 9602  loss: 0.7375  loss_rpn_cls: 0.0340  loss_rpn_bbox: 0.0437  loss_cls: 0.1791  acc: 93.0664  loss_bbox: 0.2340  loss_mask: 0.2467
2025/12/14 21:42:47 - mmengine - INFO - Epoch(train) [10][ 150/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 6:18:09  time: 1.0005  data_time: 0.0039  memory: 9299  loss: 0.7184  loss_rpn_cls: 0.0306  loss_rpn_bbox: 0.0400  loss_cls: 0.1841  acc: 97.0703  loss_bbox: 0.2289  loss_mask: 0.2348
2025/12/14 21:43:37 - mmengine - INFO - Epoch(train) [10][ 200/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 6:13:12  time: 0.9939  data_time: 0.0037  memory: 9235  loss: 0.7295  loss_rpn_cls: 0.0256  loss_rpn_bbox: 0.0376  loss_cls: 0.1814  acc: 86.9629  loss_bbox: 0.2340  loss_mask: 0.2509
2025/12/14 21:44:26 - mmengine - INFO - Epoch(train) [10][ 250/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 6:09:35  time: 0.9896  data_time: 0.0033  memory: 9540  loss: 0.6747  loss_rpn_cls: 0.0287  loss_rpn_bbox: 0.0372  loss_cls: 0.1635  acc: 94.0430  loss_bbox: 0.2100  loss_mask: 0.2353
2025/12/14 21:45:15 - mmengine - INFO - Epoch(train) [10][ 300/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 6:05:45  time: 0.9704  data_time: 0.0031  memory: 9315  loss: 0.7035  loss_rpn_cls: 0.0281  loss_rpn_bbox: 0.0355  loss_cls: 0.1870  acc: 93.6035  loss_bbox: 0.2257  loss_mask: 0.2273
2025/12/14 21:46:05 - mmengine - INFO - Epoch(train) [10][ 350/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 6:04:39  time: 1.0069  data_time: 0.0033  memory: 9285  loss: 0.7687  loss_rpn_cls: 0.0316  loss_rpn_bbox: 0.0407  loss_cls: 0.1989  acc: 92.8223  loss_bbox: 0.2387  loss_mask: 0.2589
2025/12/14 21:46:55 - mmengine - INFO - Epoch(train) [10][ 400/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 6:02:44  time: 0.9872  data_time: 0.0034  memory: 9406  loss: 0.6805  loss_rpn_cls: 0.0303  loss_rpn_bbox: 0.0386  loss_cls: 0.1684  acc: 92.9688  loss_bbox: 0.2131  loss_mask: 0.2303
2025/12/14 21:47:45 - mmengine - INFO - Epoch(train) [10][ 450/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 6:01:32  time: 0.9991  data_time: 0.0031  memory: 9602  loss: 0.7365  loss_rpn_cls: 0.0329  loss_rpn_bbox: 0.0417  loss_cls: 0.1860  acc: 93.0664  loss_bbox: 0.2337  loss_mask: 0.2422
2025/12/14 21:48:34 - mmengine - INFO - Epoch(train) [10][ 500/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:59:59  time: 0.9873  data_time: 0.0030  memory: 9933  loss: 0.7029  loss_rpn_cls: 0.0281  loss_rpn_bbox: 0.0406  loss_cls: 0.1780  acc: 94.3848  loss_bbox: 0.2227  loss_mask: 0.2336
2025/12/14 21:49:24 - mmengine - INFO - Epoch(train) [10][ 550/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:58:49  time: 0.9948  data_time: 0.0032  memory: 9315  loss: 0.7585  loss_rpn_cls: 0.0324  loss_rpn_bbox: 0.0448  loss_cls: 0.1961  acc: 91.8945  loss_bbox: 0.2429  loss_mask: 0.2423
2025/12/14 21:50:14 - mmengine - INFO - Epoch(train) [10][ 600/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:58:04  time: 1.0070  data_time: 0.0031  memory: 9218  loss: 0.7118  loss_rpn_cls: 0.0309  loss_rpn_bbox: 0.0383  loss_cls: 0.1830  acc: 95.9961  loss_bbox: 0.2255  loss_mask: 0.2340
2025/12/14 21:51:03 - mmengine - INFO - Epoch(train) [10][ 650/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:56:41  time: 0.9845  data_time: 0.0030  memory: 9358  loss: 0.7073  loss_rpn_cls: 0.0332  loss_rpn_bbox: 0.0398  loss_cls: 0.1780  acc: 92.1875  loss_bbox: 0.2252  loss_mask: 0.2312
2025/12/14 21:51:53 - mmengine - INFO - Epoch(train) [10][ 700/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:55:33  time: 0.9913  data_time: 0.0031  memory: 9323  loss: 0.7646  loss_rpn_cls: 0.0295  loss_rpn_bbox: 0.0429  loss_cls: 0.2039  acc: 91.2109  loss_bbox: 0.2504  loss_mask: 0.2378
2025/12/14 21:52:42 - mmengine - INFO - Epoch(train) [10][ 750/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:54:19  time: 0.9847  data_time: 0.0029  memory: 9394  loss: 0.7245  loss_rpn_cls: 0.0299  loss_rpn_bbox: 0.0417  loss_cls: 0.1840  acc: 91.8945  loss_bbox: 0.2322  loss_mask: 0.2367
2025/12/14 21:53:32 - mmengine - INFO - Epoch(train) [10][ 800/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:53:15  time: 0.9907  data_time: 0.0030  memory: 9540  loss: 0.7509  loss_rpn_cls: 0.0344  loss_rpn_bbox: 0.0425  loss_cls: 0.1867  acc: 90.3320  loss_bbox: 0.2397  loss_mask: 0.2476
2025/12/14 21:54:21 - mmengine - INFO - Epoch(train) [10][ 850/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:52:03  time: 0.9826  data_time: 0.0028  memory: 9195  loss: 0.7344  loss_rpn_cls: 0.0313  loss_rpn_bbox: 0.0402  loss_cls: 0.1805  acc: 94.2383  loss_bbox: 0.2351  loss_mask: 0.2473
2025/12/14 21:55:11 - mmengine - INFO - Epoch(train) [10][ 900/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:51:12  time: 0.9980  data_time: 0.0031  memory: 9561  loss: 0.7359  loss_rpn_cls: 0.0316  loss_rpn_bbox: 0.0434  loss_cls: 0.1867  acc: 92.2852  loss_bbox: 0.2279  loss_mask: 0.2464
2025/12/14 21:56:00 - mmengine - INFO - Epoch(train) [10][ 950/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:50:15  time: 0.9928  data_time: 0.0030  memory: 9343  loss: 0.7512  loss_rpn_cls: 0.0315  loss_rpn_bbox: 0.0388  loss_cls: 0.1932  acc: 97.2656  loss_bbox: 0.2432  loss_mask: 0.2445
2025/12/14 21:56:50 - mmengine - INFO - Epoch(train) [10][1000/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:49:09  time: 0.9840  data_time: 0.0029  memory: 9395  loss: 0.7703  loss_rpn_cls: 0.0323  loss_rpn_bbox: 0.0411  loss_cls: 0.1987  acc: 85.8398  loss_bbox: 0.2498  loss_mask: 0.2485
2025/12/14 21:57:20 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/14 21:57:40 - mmengine - INFO - Epoch(train) [10][1050/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:48:23  time: 1.0023  data_time: 0.0027  memory: 9578  loss: 0.6874  loss_rpn_cls: 0.0294  loss_rpn_bbox: 0.0384  loss_cls: 0.1664  acc: 94.2871  loss_bbox: 0.2170  loss_mask: 0.2362
2025/12/14 21:58:29 - mmengine - INFO - Epoch(train) [10][1100/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:47:29  time: 0.9933  data_time: 0.0030  memory: 9671  loss: 0.7336  loss_rpn_cls: 0.0345  loss_rpn_bbox: 0.0382  loss_cls: 0.1827  acc: 91.3086  loss_bbox: 0.2312  loss_mask: 0.2470
2025/12/14 21:59:20 - mmengine - INFO - Epoch(train) [10][1150/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:46:41  time: 1.0003  data_time: 0.0028  memory: 9895  loss: 0.7157  loss_rpn_cls: 0.0292  loss_rpn_bbox: 0.0425  loss_cls: 0.1770  acc: 93.6523  loss_bbox: 0.2325  loss_mask: 0.2345
2025/12/14 22:00:09 - mmengine - INFO - Epoch(train) [10][1200/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:45:42  time: 0.9876  data_time: 0.0029  memory: 9733  loss: 0.7326  loss_rpn_cls: 0.0316  loss_rpn_bbox: 0.0397  loss_cls: 0.1866  acc: 93.8477  loss_bbox: 0.2358  loss_mask: 0.2389
2025/12/14 22:00:59 - mmengine - INFO - Epoch(train) [10][1250/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:44:52  time: 0.9972  data_time: 0.0029  memory: 9611  loss: 0.7828  loss_rpn_cls: 0.0350  loss_rpn_bbox: 0.0433  loss_cls: 0.2057  acc: 96.2891  loss_bbox: 0.2483  loss_mask: 0.2504
2025/12/14 22:01:49 - mmengine - INFO - Epoch(train) [10][1300/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:44:13  time: 1.0120  data_time: 0.0032  memory: 9728  loss: 0.8037  loss_rpn_cls: 0.0316  loss_rpn_bbox: 0.0490  loss_cls: 0.1994  acc: 90.3320  loss_bbox: 0.2639  loss_mask: 0.2599
2025/12/14 22:02:40 - mmengine - INFO - Epoch(train) [10][1350/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:43:26  time: 1.0025  data_time: 0.0032  memory: 9454  loss: 0.7310  loss_rpn_cls: 0.0320  loss_rpn_bbox: 0.0376  loss_cls: 0.1925  acc: 93.7988  loss_bbox: 0.2353  loss_mask: 0.2335
2025/12/14 22:03:29 - mmengine - INFO - Epoch(train) [10][1400/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:42:34  time: 0.9954  data_time: 0.0032  memory: 9387  loss: 0.7510  loss_rpn_cls: 0.0361  loss_rpn_bbox: 0.0479  loss_cls: 0.1852  acc: 98.4375  loss_bbox: 0.2356  loss_mask: 0.2462
2025/12/14 22:04:19 - mmengine - INFO - Epoch(train) [10][1450/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:41:47  time: 1.0016  data_time: 0.0029  memory: 9329  loss: 0.6890  loss_rpn_cls: 0.0299  loss_rpn_bbox: 0.0408  loss_cls: 0.1721  acc: 93.5059  loss_bbox: 0.2216  loss_mask: 0.2245
2025/12/14 22:05:11 - mmengine - INFO - Epoch(train) [10][1500/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:41:22  time: 1.0345  data_time: 0.0030  memory: 9360  loss: 0.7478  loss_rpn_cls: 0.0308  loss_rpn_bbox: 0.0393  loss_cls: 0.1988  acc: 92.2363  loss_bbox: 0.2373  loss_mask: 0.2416
2025/12/14 22:06:01 - mmengine - INFO - Epoch(train) [10][1550/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:40:25  time: 0.9893  data_time: 0.0031  memory: 9622  loss: 0.7704  loss_rpn_cls: 0.0380  loss_rpn_bbox: 0.0450  loss_cls: 0.1900  acc: 88.2812  loss_bbox: 0.2448  loss_mask: 0.2526
2025/12/14 22:06:49 - mmengine - INFO - Epoch(train) [10][1600/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:39:20  time: 0.9768  data_time: 0.0029  memory: 9431  loss: 0.6911  loss_rpn_cls: 0.0300  loss_rpn_bbox: 0.0349  loss_cls: 0.1744  acc: 85.9375  loss_bbox: 0.2189  loss_mask: 0.2329
2025/12/14 22:07:39 - mmengine - INFO - Epoch(train) [10][1650/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:38:29  time: 0.9957  data_time: 0.0029  memory: 9257  loss: 0.7247  loss_rpn_cls: 0.0302  loss_rpn_bbox: 0.0386  loss_cls: 0.1865  acc: 94.3359  loss_bbox: 0.2342  loss_mask: 0.2351
2025/12/14 22:08:29 - mmengine - INFO - Epoch(train) [10][1700/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:37:32  time: 0.9864  data_time: 0.0029  memory: 9317  loss: 0.7619  loss_rpn_cls: 0.0314  loss_rpn_bbox: 0.0416  loss_cls: 0.1947  acc: 95.2637  loss_bbox: 0.2452  loss_mask: 0.2489
2025/12/14 22:09:18 - mmengine - INFO - Epoch(train) [10][1750/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:36:33  time: 0.9833  data_time: 0.0029  memory: 9376  loss: 0.7527  loss_rpn_cls: 0.0292  loss_rpn_bbox: 0.0458  loss_cls: 0.1931  acc: 95.2637  loss_bbox: 0.2433  loss_mask: 0.2413
2025/12/14 22:10:07 - mmengine - INFO - Epoch(train) [10][1800/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:35:39  time: 0.9896  data_time: 0.0029  memory: 9210  loss: 0.7390  loss_rpn_cls: 0.0351  loss_rpn_bbox: 0.0435  loss_cls: 0.1864  acc: 96.5332  loss_bbox: 0.2397  loss_mask: 0.2344
2025/12/14 22:10:57 - mmengine - INFO - Epoch(train) [10][1850/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:34:46  time: 0.9926  data_time: 0.0028  memory: 9593  loss: 0.6842  loss_rpn_cls: 0.0303  loss_rpn_bbox: 0.0367  loss_cls: 0.1668  acc: 96.6309  loss_bbox: 0.2179  loss_mask: 0.2326
2025/12/14 22:11:48 - mmengine - INFO - Epoch(train) [10][1900/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:34:05  time: 1.0137  data_time: 0.0029  memory: 9677  loss: 0.7852  loss_rpn_cls: 0.0362  loss_rpn_bbox: 0.0465  loss_cls: 0.1988  acc: 90.1855  loss_bbox: 0.2563  loss_mask: 0.2475
2025/12/14 22:12:37 - mmengine - INFO - Epoch(train) [10][1950/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:33:13  time: 0.9944  data_time: 0.0030  memory: 9764  loss: 0.7512  loss_rpn_cls: 0.0352  loss_rpn_bbox: 0.0465  loss_cls: 0.1997  acc: 91.4551  loss_bbox: 0.2379  loss_mask: 0.2319
2025/12/14 22:13:27 - mmengine - INFO - Epoch(train) [10][2000/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:32:23  time: 0.9961  data_time: 0.0030  memory: 10112  loss: 0.7163  loss_rpn_cls: 0.0325  loss_rpn_bbox: 0.0421  loss_cls: 0.1802  acc: 94.9219  loss_bbox: 0.2221  loss_mask: 0.2394
2025/12/14 22:13:57 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/14 22:14:17 - mmengine - INFO - Epoch(train) [10][2050/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:31:31  time: 0.9944  data_time: 0.0031  memory: 9358  loss: 0.7756  loss_rpn_cls: 0.0375  loss_rpn_bbox: 0.0482  loss_cls: 0.1979  acc: 95.5078  loss_bbox: 0.2521  loss_mask: 0.2399
2025/12/14 22:15:06 - mmengine - INFO - Epoch(train) [10][2100/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:30:31  time: 0.9763  data_time: 0.0027  memory: 10055  loss: 0.7194  loss_rpn_cls: 0.0328  loss_rpn_bbox: 0.0418  loss_cls: 0.1768  acc: 91.6504  loss_bbox: 0.2231  loss_mask: 0.2449
2025/12/14 22:15:55 - mmengine - INFO - Epoch(train) [10][2150/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:29:32  time: 0.9773  data_time: 0.0028  memory: 9246  loss: 0.7266  loss_rpn_cls: 0.0325  loss_rpn_bbox: 0.0408  loss_cls: 0.1842  acc: 94.1895  loss_bbox: 0.2293  loss_mask: 0.2397
2025/12/14 22:16:44 - mmengine - INFO - Epoch(train) [10][2200/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:28:40  time: 0.9917  data_time: 0.0029  memory: 9440  loss: 0.7200  loss_rpn_cls: 0.0289  loss_rpn_bbox: 0.0376  loss_cls: 0.1865  acc: 87.0117  loss_bbox: 0.2287  loss_mask: 0.2383
2025/12/14 22:17:34 - mmengine - INFO - Epoch(train) [10][2250/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:27:50  time: 0.9950  data_time: 0.0027  memory: 9642  loss: 0.7281  loss_rpn_cls: 0.0288  loss_rpn_bbox: 0.0385  loss_cls: 0.1870  acc: 86.9141  loss_bbox: 0.2260  loss_mask: 0.2479
2025/12/14 22:18:23 - mmengine - INFO - Epoch(train) [10][2300/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:26:55  time: 0.9840  data_time: 0.0027  memory: 9329  loss: 0.7475  loss_rpn_cls: 0.0333  loss_rpn_bbox: 0.0435  loss_cls: 0.1909  acc: 92.7246  loss_bbox: 0.2355  loss_mask: 0.2444
2025/12/14 22:19:12 - mmengine - INFO - Epoch(train) [10][2350/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:26:00  time: 0.9842  data_time: 0.0027  memory: 9632  loss: 0.7251  loss_rpn_cls: 0.0333  loss_rpn_bbox: 0.0404  loss_cls: 0.1774  acc: 93.0664  loss_bbox: 0.2378  loss_mask: 0.2363
2025/12/14 22:20:02 - mmengine - INFO - Epoch(train) [10][2400/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:25:06  time: 0.9865  data_time: 0.0027  memory: 9419  loss: 0.7589  loss_rpn_cls: 0.0320  loss_rpn_bbox: 0.0391  loss_cls: 0.1935  acc: 91.3086  loss_bbox: 0.2427  loss_mask: 0.2516
2025/12/14 22:20:51 - mmengine - INFO - Epoch(train) [10][2450/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:24:12  time: 0.9838  data_time: 0.0027  memory: 9399  loss: 0.7689  loss_rpn_cls: 0.0316  loss_rpn_bbox: 0.0413  loss_cls: 0.1940  acc: 90.6250  loss_bbox: 0.2516  loss_mask: 0.2504
2025/12/14 22:21:40 - mmengine - INFO - Epoch(train) [10][2500/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:23:17  time: 0.9827  data_time: 0.0030  memory: 9266  loss: 0.7022  loss_rpn_cls: 0.0282  loss_rpn_bbox: 0.0402  loss_cls: 0.1770  acc: 95.8984  loss_bbox: 0.2303  loss_mask: 0.2266
2025/12/14 22:22:29 - mmengine - INFO - Epoch(train) [10][2550/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:22:20  time: 0.9756  data_time: 0.0028  memory: 9543  loss: 0.7296  loss_rpn_cls: 0.0245  loss_rpn_bbox: 0.0379  loss_cls: 0.1889  acc: 91.0645  loss_bbox: 0.2388  loss_mask: 0.2396
2025/12/14 22:23:18 - mmengine - INFO - Epoch(train) [10][2600/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:21:29  time: 0.9916  data_time: 0.0029  memory: 9292  loss: 0.6828  loss_rpn_cls: 0.0253  loss_rpn_bbox: 0.0369  loss_cls: 0.1744  acc: 90.2832  loss_bbox: 0.2156  loss_mask: 0.2305
2025/12/14 22:24:08 - mmengine - INFO - Epoch(train) [10][2650/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:20:38  time: 0.9932  data_time: 0.0028  memory: 9749  loss: 0.7731  loss_rpn_cls: 0.0340  loss_rpn_bbox: 0.0435  loss_cls: 0.1987  acc: 92.8711  loss_bbox: 0.2499  loss_mask: 0.2470
2025/12/14 22:24:58 - mmengine - INFO - Epoch(train) [10][2700/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:19:49  time: 0.9973  data_time: 0.0028  memory: 9515  loss: 0.8106  loss_rpn_cls: 0.0349  loss_rpn_bbox: 0.0489  loss_cls: 0.2156  acc: 91.7480  loss_bbox: 0.2632  loss_mask: 0.2480
2025/12/14 22:25:48 - mmengine - INFO - Epoch(train) [10][2750/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:19:00  time: 0.9959  data_time: 0.0027  memory: 9371  loss: 0.6988  loss_rpn_cls: 0.0318  loss_rpn_bbox: 0.0383  loss_cls: 0.1803  acc: 94.4336  loss_bbox: 0.2233  loss_mask: 0.2251
2025/12/14 22:26:37 - mmengine - INFO - Epoch(train) [10][2800/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:18:07  time: 0.9844  data_time: 0.0026  memory: 9581  loss: 0.7549  loss_rpn_cls: 0.0318  loss_rpn_bbox: 0.0447  loss_cls: 0.1960  acc: 91.8457  loss_bbox: 0.2358  loss_mask: 0.2466
2025/12/14 22:27:27 - mmengine - INFO - Epoch(train) [10][2850/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:17:19  time: 1.0001  data_time: 0.0028  memory: 9635  loss: 0.7295  loss_rpn_cls: 0.0264  loss_rpn_bbox: 0.0385  loss_cls: 0.1824  acc: 93.7500  loss_bbox: 0.2391  loss_mask: 0.2432
2025/12/14 22:28:17 - mmengine - INFO - Epoch(train) [10][2900/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:16:30  time: 0.9962  data_time: 0.0029  memory: 9425  loss: 0.8010  loss_rpn_cls: 0.0342  loss_rpn_bbox: 0.0436  loss_cls: 0.2147  acc: 93.3594  loss_bbox: 0.2543  loss_mask: 0.2542
2025/12/14 22:29:07 - mmengine - INFO - Epoch(train) [10][2950/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:15:41  time: 0.9992  data_time: 0.0027  memory: 9700  loss: 0.7221  loss_rpn_cls: 0.0294  loss_rpn_bbox: 0.0389  loss_cls: 0.1888  acc: 90.9668  loss_bbox: 0.2273  loss_mask: 0.2377
2025/12/14 22:29:57 - mmengine - INFO - Epoch(train) [10][3000/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:14:53  time: 1.0005  data_time: 0.0029  memory: 9673  loss: 0.7226  loss_rpn_cls: 0.0303  loss_rpn_bbox: 0.0421  loss_cls: 0.1809  acc: 94.6777  loss_bbox: 0.2286  loss_mask: 0.2406
2025/12/14 22:30:27 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/14 22:30:46 - mmengine - INFO - Epoch(train) [10][3050/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:14:03  time: 0.9915  data_time: 0.0028  memory: 9443  loss: 0.7211  loss_rpn_cls: 0.0294  loss_rpn_bbox: 0.0417  loss_cls: 0.1689  acc: 96.1914  loss_bbox: 0.2291  loss_mask: 0.2521
2025/12/14 22:31:36 - mmengine - INFO - Epoch(train) [10][3100/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:13:13  time: 0.9957  data_time: 0.0028  memory: 9629  loss: 0.7463  loss_rpn_cls: 0.0351  loss_rpn_bbox: 0.0430  loss_cls: 0.1828  acc: 90.7715  loss_bbox: 0.2340  loss_mask: 0.2515
2025/12/14 22:32:26 - mmengine - INFO - Epoch(train) [10][3150/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:12:22  time: 0.9893  data_time: 0.0031  memory: 9145  loss: 0.7167  loss_rpn_cls: 0.0276  loss_rpn_bbox: 0.0380  loss_cls: 0.1819  acc: 89.1602  loss_bbox: 0.2274  loss_mask: 0.2418
2025/12/14 22:33:15 - mmengine - INFO - Epoch(train) [10][3200/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:11:31  time: 0.9913  data_time: 0.0028  memory: 9397  loss: 0.7334  loss_rpn_cls: 0.0279  loss_rpn_bbox: 0.0410  loss_cls: 0.1782  acc: 96.7285  loss_bbox: 0.2435  loss_mask: 0.2428
2025/12/14 22:34:05 - mmengine - INFO - Epoch(train) [10][3250/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:10:42  time: 0.9969  data_time: 0.0027  memory: 9657  loss: 0.6907  loss_rpn_cls: 0.0230  loss_rpn_bbox: 0.0364  loss_cls: 0.1699  acc: 94.9219  loss_bbox: 0.2209  loss_mask: 0.2405
2025/12/14 22:34:55 - mmengine - INFO - Epoch(train) [10][3300/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:09:54  time: 1.0015  data_time: 0.0031  memory: 9335  loss: 0.6919  loss_rpn_cls: 0.0278  loss_rpn_bbox: 0.0384  loss_cls: 0.1791  acc: 89.6484  loss_bbox: 0.2162  loss_mask: 0.2304
2025/12/14 22:35:45 - mmengine - INFO - Epoch(train) [10][3350/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:09:04  time: 0.9928  data_time: 0.0030  memory: 9278  loss: 0.7138  loss_rpn_cls: 0.0322  loss_rpn_bbox: 0.0386  loss_cls: 0.1846  acc: 96.4355  loss_bbox: 0.2326  loss_mask: 0.2257
2025/12/14 22:36:35 - mmengine - INFO - Epoch(train) [10][3400/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:08:17  time: 1.0062  data_time: 0.0029  memory: 9701  loss: 0.8147  loss_rpn_cls: 0.0319  loss_rpn_bbox: 0.0495  loss_cls: 0.2133  acc: 93.0664  loss_bbox: 0.2711  loss_mask: 0.2489
2025/12/14 22:37:25 - mmengine - INFO - Epoch(train) [10][3450/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:07:27  time: 0.9945  data_time: 0.0031  memory: 9302  loss: 0.7173  loss_rpn_cls: 0.0283  loss_rpn_bbox: 0.0381  loss_cls: 0.1858  acc: 94.6777  loss_bbox: 0.2227  loss_mask: 0.2424
2025/12/14 22:38:14 - mmengine - INFO - Epoch(train) [10][3500/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:06:33  time: 0.9792  data_time: 0.0029  memory: 9309  loss: 0.7115  loss_rpn_cls: 0.0286  loss_rpn_bbox: 0.0377  loss_cls: 0.1837  acc: 97.1680  loss_bbox: 0.2251  loss_mask: 0.2364
2025/12/14 22:39:04 - mmengine - INFO - Epoch(train) [10][3550/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:05:45  time: 1.0025  data_time: 0.0029  memory: 9499  loss: 0.7391  loss_rpn_cls: 0.0368  loss_rpn_bbox: 0.0450  loss_cls: 0.1846  acc: 96.1914  loss_bbox: 0.2261  loss_mask: 0.2466
2025/12/14 22:39:53 - mmengine - INFO - Epoch(train) [10][3600/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:04:49  time: 0.9707  data_time: 0.0031  memory: 9519  loss: 0.7580  loss_rpn_cls: 0.0333  loss_rpn_bbox: 0.0417  loss_cls: 0.1919  acc: 92.7734  loss_bbox: 0.2399  loss_mask: 0.2511
2025/12/14 22:40:43 - mmengine - INFO - Epoch(train) [10][3650/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:04:02  time: 1.0040  data_time: 0.0034  memory: 9256  loss: 0.7368  loss_rpn_cls: 0.0352  loss_rpn_bbox: 0.0440  loss_cls: 0.1853  acc: 86.0352  loss_bbox: 0.2334  loss_mask: 0.2388
2025/12/14 22:41:33 - mmengine - INFO - Epoch(train) [10][3700/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:03:13  time: 0.9957  data_time: 0.0030  memory: 9456  loss: 0.7312  loss_rpn_cls: 0.0278  loss_rpn_bbox: 0.0388  loss_cls: 0.1878  acc: 92.1387  loss_bbox: 0.2346  loss_mask: 0.2422
2025/12/14 22:42:23 - mmengine - INFO - Epoch(train) [10][3750/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:02:24  time: 1.0011  data_time: 0.0030  memory: 9327  loss: 0.7253  loss_rpn_cls: 0.0276  loss_rpn_bbox: 0.0418  loss_cls: 0.1860  acc: 89.0625  loss_bbox: 0.2340  loss_mask: 0.2358
2025/12/14 22:43:13 - mmengine - INFO - Epoch(train) [10][3800/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:01:39  time: 1.0125  data_time: 0.0030  memory: 9197  loss: 0.7399  loss_rpn_cls: 0.0303  loss_rpn_bbox: 0.0412  loss_cls: 0.1868  acc: 89.9902  loss_bbox: 0.2385  loss_mask: 0.2431
2025/12/14 22:44:03 - mmengine - INFO - Epoch(train) [10][3850/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:00:50  time: 1.0001  data_time: 0.0033  memory: 9971  loss: 0.7452  loss_rpn_cls: 0.0338  loss_rpn_bbox: 0.0442  loss_cls: 0.1878  acc: 85.6445  loss_bbox: 0.2431  loss_mask: 0.2362
2025/12/14 22:44:53 - mmengine - INFO - Epoch(train) [10][3900/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 5:00:01  time: 0.9948  data_time: 0.0031  memory: 9520  loss: 0.7153  loss_rpn_cls: 0.0286  loss_rpn_bbox: 0.0399  loss_cls: 0.1815  acc: 97.2168  loss_bbox: 0.2321  loss_mask: 0.2332
2025/12/14 22:45:43 - mmengine - INFO - Epoch(train) [10][3950/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:59:12  time: 1.0014  data_time: 0.0030  memory: 9639  loss: 0.7000  loss_rpn_cls: 0.0339  loss_rpn_bbox: 0.0370  loss_cls: 0.1711  acc: 91.9434  loss_bbox: 0.2193  loss_mask: 0.2387
2025/12/14 22:46:33 - mmengine - INFO - Epoch(train) [10][4000/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:58:22  time: 0.9933  data_time: 0.0030  memory: 9439  loss: 0.7460  loss_rpn_cls: 0.0338  loss_rpn_bbox: 0.0423  loss_cls: 0.1887  acc: 90.5762  loss_bbox: 0.2441  loss_mask: 0.2372
2025/12/14 22:47:03 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/14 22:47:23 - mmengine - INFO - Epoch(train) [10][4050/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:57:34  time: 1.0009  data_time: 0.0032  memory: 9637  loss: 0.7618  loss_rpn_cls: 0.0298  loss_rpn_bbox: 0.0433  loss_cls: 0.1926  acc: 95.2148  loss_bbox: 0.2443  loss_mask: 0.2517
2025/12/14 22:48:13 - mmengine - INFO - Epoch(train) [10][4100/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:56:43  time: 0.9930  data_time: 0.0030  memory: 9308  loss: 0.7174  loss_rpn_cls: 0.0289  loss_rpn_bbox: 0.0375  loss_cls: 0.1828  acc: 95.3613  loss_bbox: 0.2268  loss_mask: 0.2414
2025/12/14 22:49:02 - mmengine - INFO - Epoch(train) [10][4150/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:55:53  time: 0.9942  data_time: 0.0030  memory: 9667  loss: 0.7427  loss_rpn_cls: 0.0283  loss_rpn_bbox: 0.0433  loss_cls: 0.1922  acc: 91.8945  loss_bbox: 0.2451  loss_mask: 0.2338
2025/12/14 22:49:52 - mmengine - INFO - Epoch(train) [10][4200/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:55:04  time: 0.9967  data_time: 0.0030  memory: 9793  loss: 0.7405  loss_rpn_cls: 0.0339  loss_rpn_bbox: 0.0432  loss_cls: 0.1904  acc: 96.6309  loss_bbox: 0.2323  loss_mask: 0.2407
2025/12/14 22:50:42 - mmengine - INFO - Epoch(train) [10][4250/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:54:15  time: 0.9980  data_time: 0.0032  memory: 9719  loss: 0.7466  loss_rpn_cls: 0.0307  loss_rpn_bbox: 0.0419  loss_cls: 0.1898  acc: 89.7949  loss_bbox: 0.2416  loss_mask: 0.2427
2025/12/14 22:51:31 - mmengine - INFO - Epoch(train) [10][4300/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:53:22  time: 0.9797  data_time: 0.0031  memory: 9300  loss: 0.7455  loss_rpn_cls: 0.0347  loss_rpn_bbox: 0.0417  loss_cls: 0.1888  acc: 92.1875  loss_bbox: 0.2376  loss_mask: 0.2426
2025/12/14 22:52:21 - mmengine - INFO - Epoch(train) [10][4350/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:52:34  time: 1.0055  data_time: 0.0030  memory: 10127  loss: 0.7305  loss_rpn_cls: 0.0287  loss_rpn_bbox: 0.0438  loss_cls: 0.1783  acc: 93.4570  loss_bbox: 0.2414  loss_mask: 0.2383
2025/12/14 22:53:11 - mmengine - INFO - Epoch(train) [10][4400/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:51:45  time: 0.9961  data_time: 0.0029  memory: 9657  loss: 0.7534  loss_rpn_cls: 0.0321  loss_rpn_bbox: 0.0442  loss_cls: 0.1958  acc: 91.2598  loss_bbox: 0.2391  loss_mask: 0.2421
2025/12/14 22:54:01 - mmengine - INFO - Epoch(train) [10][4450/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:50:55  time: 0.9958  data_time: 0.0032  memory: 9305  loss: 0.7047  loss_rpn_cls: 0.0274  loss_rpn_bbox: 0.0362  loss_cls: 0.1745  acc: 91.5527  loss_bbox: 0.2294  loss_mask: 0.2371
2025/12/14 22:54:51 - mmengine - INFO - Epoch(train) [10][4500/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:50:06  time: 0.9985  data_time: 0.0032  memory: 9313  loss: 0.7755  loss_rpn_cls: 0.0306  loss_rpn_bbox: 0.0507  loss_cls: 0.1955  acc: 94.2871  loss_bbox: 0.2544  loss_mask: 0.2441
2025/12/14 22:55:40 - mmengine - INFO - Epoch(train) [10][4550/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:49:15  time: 0.9871  data_time: 0.0030  memory: 9226  loss: 0.7485  loss_rpn_cls: 0.0339  loss_rpn_bbox: 0.0439  loss_cls: 0.1939  acc: 93.7988  loss_bbox: 0.2331  loss_mask: 0.2437
2025/12/14 22:56:29 - mmengine - INFO - Epoch(train) [10][4600/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:48:20  time: 0.9723  data_time: 0.0029  memory: 9477  loss: 0.6953  loss_rpn_cls: 0.0283  loss_rpn_bbox: 0.0350  loss_cls: 0.1785  acc: 93.1641  loss_bbox: 0.2252  loss_mask: 0.2284
2025/12/14 22:57:18 - mmengine - INFO - Epoch(train) [10][4650/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:47:30  time: 0.9916  data_time: 0.0030  memory: 9570  loss: 0.7662  loss_rpn_cls: 0.0358  loss_rpn_bbox: 0.0424  loss_cls: 0.1914  acc: 91.3574  loss_bbox: 0.2424  loss_mask: 0.2541
2025/12/14 22:58:08 - mmengine - INFO - Epoch(train) [10][4700/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:46:38  time: 0.9829  data_time: 0.0034  memory: 9884  loss: 0.7030  loss_rpn_cls: 0.0260  loss_rpn_bbox: 0.0371  loss_cls: 0.1743  acc: 94.3848  loss_bbox: 0.2240  loss_mask: 0.2417
2025/12/14 22:58:58 - mmengine - INFO - Epoch(train) [10][4750/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:45:49  time: 0.9972  data_time: 0.0032  memory: 9321  loss: 0.7063  loss_rpn_cls: 0.0267  loss_rpn_bbox: 0.0385  loss_cls: 0.1832  acc: 93.9453  loss_bbox: 0.2281  loss_mask: 0.2298
2025/12/14 22:59:47 - mmengine - INFO - Epoch(train) [10][4800/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:44:58  time: 0.9904  data_time: 0.0030  memory: 9284  loss: 0.7367  loss_rpn_cls: 0.0308  loss_rpn_bbox: 0.0430  loss_cls: 0.1870  acc: 96.0449  loss_bbox: 0.2356  loss_mask: 0.2402
2025/12/14 23:00:38 - mmengine - INFO - Epoch(train) [10][4850/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:44:13  time: 1.0206  data_time: 0.0030  memory: 9439  loss: 0.7746  loss_rpn_cls: 0.0361  loss_rpn_bbox: 0.0452  loss_cls: 0.2029  acc: 91.5039  loss_bbox: 0.2521  loss_mask: 0.2383
2025/12/14 23:01:28 - mmengine - INFO - Epoch(train) [10][4900/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:43:25  time: 1.0008  data_time: 0.0030  memory: 9170  loss: 0.7449  loss_rpn_cls: 0.0281  loss_rpn_bbox: 0.0397  loss_cls: 0.1873  acc: 96.4355  loss_bbox: 0.2423  loss_mask: 0.2475
2025/12/14 23:02:19 - mmengine - INFO - Epoch(train) [10][4950/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:42:37  time: 1.0092  data_time: 0.0034  memory: 9320  loss: 0.7413  loss_rpn_cls: 0.0286  loss_rpn_bbox: 0.0418  loss_cls: 0.1967  acc: 95.7520  loss_bbox: 0.2328  loss_mask: 0.2414
2025/12/14 23:03:09 - mmengine - INFO - Epoch(train) [10][5000/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:41:51  time: 1.0151  data_time: 0.0032  memory: 9630  loss: 0.7659  loss_rpn_cls: 0.0337  loss_rpn_bbox: 0.0450  loss_cls: 0.1970  acc: 91.3574  loss_bbox: 0.2498  loss_mask: 0.2405
2025/12/14 23:03:40 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/14 23:04:00 - mmengine - INFO - Epoch(train) [10][5050/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:41:03  time: 1.0057  data_time: 0.0030  memory: 9334  loss: 0.7283  loss_rpn_cls: 0.0347  loss_rpn_bbox: 0.0399  loss_cls: 0.1869  acc: 92.6758  loss_bbox: 0.2292  loss_mask: 0.2376
2025/12/14 23:04:51 - mmengine - INFO - Epoch(train) [10][5100/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:40:18  time: 1.0275  data_time: 0.0029  memory: 9847  loss: 0.7324  loss_rpn_cls: 0.0284  loss_rpn_bbox: 0.0416  loss_cls: 0.1839  acc: 93.9453  loss_bbox: 0.2397  loss_mask: 0.2387
2025/12/14 23:05:41 - mmengine - INFO - Epoch(train) [10][5150/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:39:29  time: 1.0014  data_time: 0.0028  memory: 9372  loss: 0.7087  loss_rpn_cls: 0.0250  loss_rpn_bbox: 0.0396  loss_cls: 0.1863  acc: 95.9473  loss_bbox: 0.2257  loss_mask: 0.2321
2025/12/14 23:06:31 - mmengine - INFO - Epoch(train) [10][5200/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:38:41  time: 1.0060  data_time: 0.0032  memory: 9931  loss: 0.7313  loss_rpn_cls: 0.0285  loss_rpn_bbox: 0.0407  loss_cls: 0.1855  acc: 95.5078  loss_bbox: 0.2398  loss_mask: 0.2368
2025/12/14 23:07:23 - mmengine - INFO - Epoch(train) [10][5250/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:37:58  time: 1.0371  data_time: 0.0031  memory: 9601  loss: 0.7287  loss_rpn_cls: 0.0323  loss_rpn_bbox: 0.0373  loss_cls: 0.1924  acc: 93.8477  loss_bbox: 0.2329  loss_mask: 0.2338
2025/12/14 23:08:13 - mmengine - INFO - Epoch(train) [10][5300/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:37:09  time: 1.0031  data_time: 0.0030  memory: 9461  loss: 0.7488  loss_rpn_cls: 0.0295  loss_rpn_bbox: 0.0448  loss_cls: 0.1957  acc: 95.9961  loss_bbox: 0.2384  loss_mask: 0.2405
2025/12/14 23:09:04 - mmengine - INFO - Epoch(train) [10][5350/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:36:20  time: 1.0008  data_time: 0.0029  memory: 9609  loss: 0.7593  loss_rpn_cls: 0.0308  loss_rpn_bbox: 0.0393  loss_cls: 0.1976  acc: 92.1387  loss_bbox: 0.2430  loss_mask: 0.2486
2025/12/14 23:09:54 - mmengine - INFO - Epoch(train) [10][5400/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:35:31  time: 0.9991  data_time: 0.0028  memory: 9540  loss: 0.6961  loss_rpn_cls: 0.0265  loss_rpn_bbox: 0.0372  loss_cls: 0.1801  acc: 95.4102  loss_bbox: 0.2231  loss_mask: 0.2293
2025/12/14 23:10:45 - mmengine - INFO - Epoch(train) [10][5450/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:34:46  time: 1.0272  data_time: 0.0031  memory: 9622  loss: 0.6958  loss_rpn_cls: 0.0256  loss_rpn_bbox: 0.0393  loss_cls: 0.1742  acc: 94.9219  loss_bbox: 0.2188  loss_mask: 0.2379
2025/12/14 23:11:36 - mmengine - INFO - Epoch(train) [10][5500/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:33:58  time: 1.0134  data_time: 0.0032  memory: 9848  loss: 0.7069  loss_rpn_cls: 0.0311  loss_rpn_bbox: 0.0396  loss_cls: 0.1775  acc: 92.9688  loss_bbox: 0.2247  loss_mask: 0.2340
2025/12/14 23:12:26 - mmengine - INFO - Epoch(train) [10][5550/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:33:09  time: 0.9996  data_time: 0.0030  memory: 9302  loss: 0.7085  loss_rpn_cls: 0.0317  loss_rpn_bbox: 0.0384  loss_cls: 0.1742  acc: 91.6016  loss_bbox: 0.2165  loss_mask: 0.2477
2025/12/14 23:13:16 - mmengine - INFO - Epoch(train) [10][5600/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:32:20  time: 1.0070  data_time: 0.0029  memory: 9624  loss: 0.7887  loss_rpn_cls: 0.0368  loss_rpn_bbox: 0.0474  loss_cls: 0.2035  acc: 87.2559  loss_bbox: 0.2561  loss_mask: 0.2449
2025/12/14 23:14:06 - mmengine - INFO - Epoch(train) [10][5650/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:31:32  time: 1.0035  data_time: 0.0030  memory: 9494  loss: 0.7182  loss_rpn_cls: 0.0277  loss_rpn_bbox: 0.0398  loss_cls: 0.1822  acc: 90.6250  loss_bbox: 0.2305  loss_mask: 0.2381
2025/12/14 23:14:56 - mmengine - INFO - Epoch(train) [10][5700/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:30:42  time: 0.9979  data_time: 0.0034  memory: 9292  loss: 0.7377  loss_rpn_cls: 0.0311  loss_rpn_bbox: 0.0409  loss_cls: 0.1864  acc: 95.1660  loss_bbox: 0.2355  loss_mask: 0.2438
2025/12/14 23:15:46 - mmengine - INFO - Epoch(train) [10][5750/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:29:52  time: 0.9953  data_time: 0.0032  memory: 9274  loss: 0.7479  loss_rpn_cls: 0.0306  loss_rpn_bbox: 0.0416  loss_cls: 0.1874  acc: 98.0957  loss_bbox: 0.2498  loss_mask: 0.2385
2025/12/14 23:16:36 - mmengine - INFO - Epoch(train) [10][5800/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:29:03  time: 1.0083  data_time: 0.0030  memory: 9281  loss: 0.6932  loss_rpn_cls: 0.0306  loss_rpn_bbox: 0.0403  loss_cls: 0.1685  acc: 97.0215  loss_bbox: 0.2238  loss_mask: 0.2299
2025/12/14 23:17:26 - mmengine - INFO - Epoch(train) [10][5850/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:28:14  time: 0.9999  data_time: 0.0030  memory: 9386  loss: 0.7222  loss_rpn_cls: 0.0303  loss_rpn_bbox: 0.0426  loss_cls: 0.1846  acc: 90.9180  loss_bbox: 0.2292  loss_mask: 0.2355
2025/12/14 23:18:17 - mmengine - INFO - Epoch(train) [10][5900/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:27:25  time: 1.0066  data_time: 0.0032  memory: 9390  loss: 0.7176  loss_rpn_cls: 0.0271  loss_rpn_bbox: 0.0397  loss_cls: 0.1807  acc: 92.7246  loss_bbox: 0.2276  loss_mask: 0.2425
2025/12/14 23:19:06 - mmengine - INFO - Epoch(train) [10][5950/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:26:36  time: 0.9984  data_time: 0.0032  memory: 9575  loss: 0.7355  loss_rpn_cls: 0.0298  loss_rpn_bbox: 0.0400  loss_cls: 0.1906  acc: 93.8477  loss_bbox: 0.2325  loss_mask: 0.2426
2025/12/14 23:19:57 - mmengine - INFO - Epoch(train) [10][6000/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:25:48  time: 1.0116  data_time: 0.0029  memory: 9553  loss: 0.7385  loss_rpn_cls: 0.0265  loss_rpn_bbox: 0.0358  loss_cls: 0.1886  acc: 94.2383  loss_bbox: 0.2413  loss_mask: 0.2463
2025/12/14 23:20:28 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/14 23:20:48 - mmengine - INFO - Epoch(train) [10][6050/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:25:01  time: 1.0245  data_time: 0.0028  memory: 9381  loss: 0.6851  loss_rpn_cls: 0.0242  loss_rpn_bbox: 0.0338  loss_cls: 0.1677  acc: 95.4590  loss_bbox: 0.2173  loss_mask: 0.2422
2025/12/14 23:21:39 - mmengine - INFO - Epoch(train) [10][6100/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:24:13  time: 1.0098  data_time: 0.0033  memory: 9278  loss: 0.7483  loss_rpn_cls: 0.0302  loss_rpn_bbox: 0.0440  loss_cls: 0.1842  acc: 93.6035  loss_bbox: 0.2403  loss_mask: 0.2497
2025/12/14 23:22:30 - mmengine - INFO - Epoch(train) [10][6150/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:23:26  time: 1.0159  data_time: 0.0032  memory: 9353  loss: 0.7427  loss_rpn_cls: 0.0298  loss_rpn_bbox: 0.0407  loss_cls: 0.1800  acc: 91.5039  loss_bbox: 0.2474  loss_mask: 0.2449
2025/12/14 23:23:19 - mmengine - INFO - Epoch(train) [10][6200/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:22:35  time: 0.9962  data_time: 0.0030  memory: 9131  loss: 0.7262  loss_rpn_cls: 0.0273  loss_rpn_bbox: 0.0388  loss_cls: 0.1773  acc: 93.1641  loss_bbox: 0.2312  loss_mask: 0.2516
2025/12/14 23:24:09 - mmengine - INFO - Epoch(train) [10][6250/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:21:46  time: 0.9992  data_time: 0.0029  memory: 10167  loss: 0.7227  loss_rpn_cls: 0.0298  loss_rpn_bbox: 0.0377  loss_cls: 0.1800  acc: 91.0645  loss_bbox: 0.2331  loss_mask: 0.2420
2025/12/14 23:25:00 - mmengine - INFO - Epoch(train) [10][6300/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:20:57  time: 1.0076  data_time: 0.0029  memory: 9309  loss: 0.7523  loss_rpn_cls: 0.0302  loss_rpn_bbox: 0.0415  loss_cls: 0.1871  acc: 92.5781  loss_bbox: 0.2456  loss_mask: 0.2480
2025/12/14 23:25:51 - mmengine - INFO - Epoch(train) [10][6350/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:20:10  time: 1.0208  data_time: 0.0034  memory: 9480  loss: 0.7381  loss_rpn_cls: 0.0347  loss_rpn_bbox: 0.0439  loss_cls: 0.1867  acc: 93.7988  loss_bbox: 0.2341  loss_mask: 0.2387
2025/12/14 23:26:42 - mmengine - INFO - Epoch(train) [10][6400/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:19:23  time: 1.0208  data_time: 0.0031  memory: 9429  loss: 0.6986  loss_rpn_cls: 0.0302  loss_rpn_bbox: 0.0359  loss_cls: 0.1695  acc: 93.5547  loss_bbox: 0.2225  loss_mask: 0.2406
2025/12/14 23:27:32 - mmengine - INFO - Epoch(train) [10][6450/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:18:33  time: 1.0012  data_time: 0.0030  memory: 9349  loss: 0.7050  loss_rpn_cls: 0.0279  loss_rpn_bbox: 0.0381  loss_cls: 0.1764  acc: 94.2871  loss_bbox: 0.2287  loss_mask: 0.2340
2025/12/14 23:28:23 - mmengine - INFO - Epoch(train) [10][6500/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:17:47  time: 1.0270  data_time: 0.0029  memory: 9535  loss: 0.7247  loss_rpn_cls: 0.0336  loss_rpn_bbox: 0.0428  loss_cls: 0.1854  acc: 91.2598  loss_bbox: 0.2318  loss_mask: 0.2311
2025/12/14 23:29:15 - mmengine - INFO - Epoch(train) [10][6550/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:17:01  time: 1.0320  data_time: 0.0031  memory: 9392  loss: 0.6839  loss_rpn_cls: 0.0255  loss_rpn_bbox: 0.0370  loss_cls: 0.1723  acc: 93.7012  loss_bbox: 0.2147  loss_mask: 0.2343
2025/12/14 23:30:07 - mmengine - INFO - Epoch(train) [10][6600/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:16:15  time: 1.0316  data_time: 0.0031  memory: 9611  loss: 0.7143  loss_rpn_cls: 0.0267  loss_rpn_bbox: 0.0385  loss_cls: 0.1837  acc: 94.1406  loss_bbox: 0.2290  loss_mask: 0.2364
2025/12/14 23:30:57 - mmengine - INFO - Epoch(train) [10][6650/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:15:27  time: 1.0161  data_time: 0.0030  memory: 9483  loss: 0.7452  loss_rpn_cls: 0.0312  loss_rpn_bbox: 0.0404  loss_cls: 0.1900  acc: 91.6016  loss_bbox: 0.2379  loss_mask: 0.2457
2025/12/14 23:31:48 - mmengine - INFO - Epoch(train) [10][6700/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:14:39  time: 1.0209  data_time: 0.0030  memory: 9516  loss: 0.6934  loss_rpn_cls: 0.0356  loss_rpn_bbox: 0.0411  loss_cls: 0.1740  acc: 93.5547  loss_bbox: 0.2184  loss_mask: 0.2243
2025/12/14 23:32:40 - mmengine - INFO - Epoch(train) [10][6750/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:13:52  time: 1.0266  data_time: 0.0030  memory: 9541  loss: 0.7155  loss_rpn_cls: 0.0282  loss_rpn_bbox: 0.0412  loss_cls: 0.1841  acc: 90.1855  loss_bbox: 0.2296  loss_mask: 0.2324
2025/12/14 23:33:30 - mmengine - INFO - Epoch(train) [10][6800/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:13:03  time: 1.0097  data_time: 0.0031  memory: 9571  loss: 0.7179  loss_rpn_cls: 0.0262  loss_rpn_bbox: 0.0413  loss_cls: 0.1756  acc: 93.1641  loss_bbox: 0.2371  loss_mask: 0.2376
2025/12/14 23:34:21 - mmengine - INFO - Epoch(train) [10][6850/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:12:15  time: 1.0163  data_time: 0.0030  memory: 9407  loss: 0.7374  loss_rpn_cls: 0.0342  loss_rpn_bbox: 0.0400  loss_cls: 0.1964  acc: 95.9473  loss_bbox: 0.2325  loss_mask: 0.2344
2025/12/14 23:35:12 - mmengine - INFO - Epoch(train) [10][6900/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:11:26  time: 1.0096  data_time: 0.0032  memory: 9358  loss: 0.7369  loss_rpn_cls: 0.0320  loss_rpn_bbox: 0.0449  loss_cls: 0.1885  acc: 91.3086  loss_bbox: 0.2414  loss_mask: 0.2302
2025/12/14 23:36:03 - mmengine - INFO - Epoch(train) [10][6950/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:10:38  time: 1.0184  data_time: 0.0034  memory: 9625  loss: 0.7625  loss_rpn_cls: 0.0303  loss_rpn_bbox: 0.0447  loss_cls: 0.1954  acc: 94.4824  loss_bbox: 0.2436  loss_mask: 0.2484
2025/12/14 23:36:54 - mmengine - INFO - Epoch(train) [10][7000/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:09:51  time: 1.0220  data_time: 0.0035  memory: 9314  loss: 0.7366  loss_rpn_cls: 0.0321  loss_rpn_bbox: 0.0377  loss_cls: 0.1879  acc: 91.1621  loss_bbox: 0.2377  loss_mask: 0.2413
2025/12/14 23:37:25 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/14 23:37:45 - mmengine - INFO - Epoch(train) [10][7050/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:09:03  time: 1.0220  data_time: 0.0031  memory: 9566  loss: 0.7584  loss_rpn_cls: 0.0320  loss_rpn_bbox: 0.0425  loss_cls: 0.1842  acc: 96.8750  loss_bbox: 0.2413  loss_mask: 0.2585
2025/12/14 23:38:36 - mmengine - INFO - Epoch(train) [10][7100/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:08:16  time: 1.0278  data_time: 0.0032  memory: 9562  loss: 0.7218  loss_rpn_cls: 0.0299  loss_rpn_bbox: 0.0369  loss_cls: 0.1838  acc: 92.5781  loss_bbox: 0.2313  loss_mask: 0.2398
2025/12/14 23:39:27 - mmengine - INFO - Epoch(train) [10][7150/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:07:27  time: 1.0134  data_time: 0.0032  memory: 9628  loss: 0.7124  loss_rpn_cls: 0.0297  loss_rpn_bbox: 0.0407  loss_cls: 0.1737  acc: 92.0410  loss_bbox: 0.2235  loss_mask: 0.2448
2025/12/14 23:40:19 - mmengine - INFO - Epoch(train) [10][7200/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:06:41  time: 1.0351  data_time: 0.0034  memory: 9112  loss: 0.7169  loss_rpn_cls: 0.0297  loss_rpn_bbox: 0.0373  loss_cls: 0.1760  acc: 93.7988  loss_bbox: 0.2329  loss_mask: 0.2410
2025/12/14 23:41:09 - mmengine - INFO - Epoch(train) [10][7250/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:05:51  time: 1.0070  data_time: 0.0034  memory: 9405  loss: 0.7332  loss_rpn_cls: 0.0318  loss_rpn_bbox: 0.0409  loss_cls: 0.1875  acc: 97.1191  loss_bbox: 0.2354  loss_mask: 0.2376
2025/12/14 23:42:00 - mmengine - INFO - Epoch(train) [10][7300/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:05:03  time: 1.0188  data_time: 0.0035  memory: 9465  loss: 0.6891  loss_rpn_cls: 0.0332  loss_rpn_bbox: 0.0400  loss_cls: 0.1643  acc: 92.2363  loss_bbox: 0.2156  loss_mask: 0.2360
2025/12/14 23:42:30 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/14 23:42:30 - mmengine - INFO - Saving checkpoint at 10 epochs
2025/12/14 23:43:28 - mmengine - INFO - Epoch(val) [10][ 50/313]    eta: 0:04:40  time: 1.0682  data_time: 0.0199  memory: 9417  
2025/12/14 23:44:18 - mmengine - INFO - Epoch(val) [10][100/313]    eta: 0:03:41  time: 1.0124  data_time: 0.0008  memory: 2466  
2025/12/14 23:45:09 - mmengine - INFO - Epoch(val) [10][150/313]    eta: 0:02:48  time: 1.0159  data_time: 0.0008  memory: 2551  
2025/12/14 23:46:00 - mmengine - INFO - Epoch(val) [10][200/313]    eta: 0:01:56  time: 1.0213  data_time: 0.0009  memory: 2637  
2025/12/14 23:46:52 - mmengine - INFO - Epoch(val) [10][250/313]    eta: 0:01:04  time: 1.0283  data_time: 0.0010  memory: 2637  
2025/12/14 23:47:43 - mmengine - INFO - Epoch(val) [10][300/313]    eta: 0:00:13  time: 1.0322  data_time: 0.0010  memory: 2552  
2025/12/14 23:48:07 - mmengine - INFO - Evaluating bbox...
2025/12/14 23:48:44 - mmengine - INFO - bbox_mAP_copypaste: 0.445 0.662 0.485 0.286 0.479 0.577
2025/12/14 23:48:44 - mmengine - INFO - Evaluating segm...
2025/12/14 23:49:29 - mmengine - INFO - segm_mAP_copypaste: 0.395 0.624 0.423 0.209 0.427 0.577
2025/12/14 23:49:30 - mmengine - INFO - Epoch(val) [10][313/313]    coco/bbox_mAP: 0.4450  coco/bbox_mAP_50: 0.6620  coco/bbox_mAP_75: 0.4850  coco/bbox_mAP_s: 0.2860  coco/bbox_mAP_m: 0.4790  coco/bbox_mAP_l: 0.5770  coco/segm_mAP: 0.3950  coco/segm_mAP_50: 0.6240  coco/segm_mAP_75: 0.4230  coco/segm_mAP_s: 0.2090  coco/segm_mAP_m: 0.4270  coco/segm_mAP_l: 0.5770  data_time: 0.0039  time: 1.0273
2025/12/14 23:50:23 - mmengine - INFO - Epoch(train) [11][  50/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:03:50  time: 1.0633  data_time: 0.0135  memory: 9409  loss: 0.7268  loss_rpn_cls: 0.0321  loss_rpn_bbox: 0.0410  loss_cls: 0.1847  acc: 90.5762  loss_bbox: 0.2288  loss_mask: 0.2401
2025/12/14 23:51:14 - mmengine - INFO - Epoch(train) [11][ 100/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:03:03  time: 1.0308  data_time: 0.0033  memory: 9411  loss: 0.6997  loss_rpn_cls: 0.0259  loss_rpn_bbox: 0.0383  loss_cls: 0.1708  acc: 91.2109  loss_bbox: 0.2300  loss_mask: 0.2346
2025/12/14 23:52:06 - mmengine - INFO - Epoch(train) [11][ 150/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:02:16  time: 1.0374  data_time: 0.0033  memory: 9418  loss: 0.7044  loss_rpn_cls: 0.0265  loss_rpn_bbox: 0.0361  loss_cls: 0.1854  acc: 95.5566  loss_bbox: 0.2233  loss_mask: 0.2331
2025/12/14 23:52:58 - mmengine - INFO - Epoch(train) [11][ 200/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:01:29  time: 1.0346  data_time: 0.0032  memory: 9373  loss: 0.7162  loss_rpn_cls: 0.0293  loss_rpn_bbox: 0.0411  loss_cls: 0.1876  acc: 95.4102  loss_bbox: 0.2275  loss_mask: 0.2308
2025/12/14 23:53:50 - mmengine - INFO - Epoch(train) [11][ 250/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 4:00:43  time: 1.0443  data_time: 0.0032  memory: 9531  loss: 0.7396  loss_rpn_cls: 0.0325  loss_rpn_bbox: 0.0421  loss_cls: 0.1921  acc: 92.1875  loss_bbox: 0.2385  loss_mask: 0.2345
2025/12/14 23:54:42 - mmengine - INFO - Epoch(train) [11][ 300/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:59:56  time: 1.0291  data_time: 0.0031  memory: 9730  loss: 0.7249  loss_rpn_cls: 0.0347  loss_rpn_bbox: 0.0405  loss_cls: 0.1826  acc: 92.5293  loss_bbox: 0.2312  loss_mask: 0.2358
2025/12/14 23:55:33 - mmengine - INFO - Epoch(train) [11][ 350/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:59:08  time: 1.0256  data_time: 0.0031  memory: 9488  loss: 0.7309  loss_rpn_cls: 0.0263  loss_rpn_bbox: 0.0391  loss_cls: 0.1841  acc: 94.1895  loss_bbox: 0.2346  loss_mask: 0.2468
2025/12/14 23:56:24 - mmengine - INFO - Epoch(train) [11][ 400/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:58:19  time: 1.0172  data_time: 0.0031  memory: 9751  loss: 0.7319  loss_rpn_cls: 0.0288  loss_rpn_bbox: 0.0374  loss_cls: 0.1874  acc: 93.2617  loss_bbox: 0.2389  loss_mask: 0.2394
2025/12/14 23:57:15 - mmengine - INFO - Epoch(train) [11][ 450/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:57:31  time: 1.0257  data_time: 0.0030  memory: 9748  loss: 0.6822  loss_rpn_cls: 0.0291  loss_rpn_bbox: 0.0391  loss_cls: 0.1697  acc: 93.2129  loss_bbox: 0.2119  loss_mask: 0.2324
2025/12/14 23:58:06 - mmengine - INFO - Epoch(train) [11][ 500/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:56:43  time: 1.0254  data_time: 0.0030  memory: 9241  loss: 0.7545  loss_rpn_cls: 0.0319  loss_rpn_bbox: 0.0439  loss_cls: 0.1956  acc: 92.9199  loss_bbox: 0.2444  loss_mask: 0.2389
2025/12/14 23:58:58 - mmengine - INFO - Epoch(train) [11][ 550/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:55:55  time: 1.0257  data_time: 0.0031  memory: 9768  loss: 0.6804  loss_rpn_cls: 0.0284  loss_rpn_bbox: 0.0398  loss_cls: 0.1749  acc: 93.8965  loss_bbox: 0.2144  loss_mask: 0.2229
2025/12/14 23:59:49 - mmengine - INFO - Epoch(train) [11][ 600/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:55:07  time: 1.0314  data_time: 0.0030  memory: 9694  loss: 0.7008  loss_rpn_cls: 0.0310  loss_rpn_bbox: 0.0392  loss_cls: 0.1805  acc: 96.4355  loss_bbox: 0.2280  loss_mask: 0.2221
2025/12/15 00:00:41 - mmengine - INFO - Epoch(train) [11][ 650/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:54:19  time: 1.0326  data_time: 0.0030  memory: 9810  loss: 0.7358  loss_rpn_cls: 0.0354  loss_rpn_bbox: 0.0437  loss_cls: 0.1800  acc: 91.9434  loss_bbox: 0.2380  loss_mask: 0.2387
2025/12/15 00:01:31 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/15 00:01:31 - mmengine - INFO - Epoch(train) [11][ 700/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:53:30  time: 1.0107  data_time: 0.0030  memory: 9734  loss: 0.6718  loss_rpn_cls: 0.0279  loss_rpn_bbox: 0.0359  loss_cls: 0.1696  acc: 97.0215  loss_bbox: 0.2133  loss_mask: 0.2251
2025/12/15 00:02:22 - mmengine - INFO - Epoch(train) [11][ 750/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:52:40  time: 1.0124  data_time: 0.0030  memory: 9652  loss: 0.7100  loss_rpn_cls: 0.0288  loss_rpn_bbox: 0.0449  loss_cls: 0.1774  acc: 94.2383  loss_bbox: 0.2298  loss_mask: 0.2291
2025/12/15 00:03:13 - mmengine - INFO - Epoch(train) [11][ 800/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:51:52  time: 1.0223  data_time: 0.0030  memory: 9526  loss: 0.6974  loss_rpn_cls: 0.0255  loss_rpn_bbox: 0.0396  loss_cls: 0.1697  acc: 95.8496  loss_bbox: 0.2270  loss_mask: 0.2356
2025/12/15 00:04:04 - mmengine - INFO - Epoch(train) [11][ 850/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:51:03  time: 1.0173  data_time: 0.0030  memory: 9489  loss: 0.7164  loss_rpn_cls: 0.0278  loss_rpn_bbox: 0.0404  loss_cls: 0.1771  acc: 94.6289  loss_bbox: 0.2321  loss_mask: 0.2389
2025/12/15 00:04:55 - mmengine - INFO - Epoch(train) [11][ 900/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:50:14  time: 1.0236  data_time: 0.0030  memory: 9378  loss: 0.7590  loss_rpn_cls: 0.0325  loss_rpn_bbox: 0.0457  loss_cls: 0.1994  acc: 94.1895  loss_bbox: 0.2415  loss_mask: 0.2399
2025/12/15 00:05:46 - mmengine - INFO - Epoch(train) [11][ 950/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:49:25  time: 1.0147  data_time: 0.0030  memory: 9336  loss: 0.7331  loss_rpn_cls: 0.0330  loss_rpn_bbox: 0.0420  loss_cls: 0.1930  acc: 97.3145  loss_bbox: 0.2352  loss_mask: 0.2299
2025/12/15 00:06:37 - mmengine - INFO - Epoch(train) [11][1000/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:48:36  time: 1.0181  data_time: 0.0030  memory: 9422  loss: 0.7252  loss_rpn_cls: 0.0309  loss_rpn_bbox: 0.0404  loss_cls: 0.1819  acc: 88.6230  loss_bbox: 0.2329  loss_mask: 0.2390
2025/12/15 00:07:28 - mmengine - INFO - Epoch(train) [11][1050/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:47:47  time: 1.0186  data_time: 0.0030  memory: 9581  loss: 0.7153  loss_rpn_cls: 0.0333  loss_rpn_bbox: 0.0437  loss_cls: 0.1752  acc: 88.4766  loss_bbox: 0.2234  loss_mask: 0.2399
2025/12/15 00:08:20 - mmengine - INFO - Epoch(train) [11][1100/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:46:59  time: 1.0353  data_time: 0.0030  memory: 9425  loss: 0.7685  loss_rpn_cls: 0.0305  loss_rpn_bbox: 0.0448  loss_cls: 0.1958  acc: 93.9453  loss_bbox: 0.2499  loss_mask: 0.2475
2025/12/15 00:09:11 - mmengine - INFO - Epoch(train) [11][1150/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:46:10  time: 1.0249  data_time: 0.0032  memory: 9232  loss: 0.7262  loss_rpn_cls: 0.0298  loss_rpn_bbox: 0.0427  loss_cls: 0.1885  acc: 95.0684  loss_bbox: 0.2338  loss_mask: 0.2313
2025/12/15 00:10:03 - mmengine - INFO - Epoch(train) [11][1200/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:45:23  time: 1.0405  data_time: 0.0033  memory: 9478  loss: 0.7523  loss_rpn_cls: 0.0340  loss_rpn_bbox: 0.0450  loss_cls: 0.1921  acc: 91.6504  loss_bbox: 0.2398  loss_mask: 0.2413
2025/12/15 00:10:55 - mmengine - INFO - Epoch(train) [11][1250/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:44:35  time: 1.0348  data_time: 0.0031  memory: 9565  loss: 0.7358  loss_rpn_cls: 0.0307  loss_rpn_bbox: 0.0438  loss_cls: 0.1817  acc: 93.1152  loss_bbox: 0.2337  loss_mask: 0.2460
2025/12/15 00:11:47 - mmengine - INFO - Epoch(train) [11][1300/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:43:48  time: 1.0417  data_time: 0.0031  memory: 10634  loss: 0.6752  loss_rpn_cls: 0.0262  loss_rpn_bbox: 0.0400  loss_cls: 0.1609  acc: 93.6523  loss_bbox: 0.2193  loss_mask: 0.2289
2025/12/15 00:12:37 - mmengine - INFO - Epoch(train) [11][1350/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:42:58  time: 1.0074  data_time: 0.0030  memory: 9747  loss: 0.6738  loss_rpn_cls: 0.0297  loss_rpn_bbox: 0.0341  loss_cls: 0.1643  acc: 98.9258  loss_bbox: 0.2169  loss_mask: 0.2288
2025/12/15 00:13:28 - mmengine - INFO - Epoch(train) [11][1400/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:42:08  time: 1.0118  data_time: 0.0031  memory: 9258  loss: 0.7081  loss_rpn_cls: 0.0328  loss_rpn_bbox: 0.0403  loss_cls: 0.1754  acc: 90.0391  loss_bbox: 0.2221  loss_mask: 0.2376
2025/12/15 00:14:19 - mmengine - INFO - Epoch(train) [11][1450/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:41:20  time: 1.0303  data_time: 0.0031  memory: 9244  loss: 0.7167  loss_rpn_cls: 0.0301  loss_rpn_bbox: 0.0397  loss_cls: 0.1726  acc: 93.8965  loss_bbox: 0.2347  loss_mask: 0.2395
2025/12/15 00:15:11 - mmengine - INFO - Epoch(train) [11][1500/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:40:31  time: 1.0323  data_time: 0.0031  memory: 9414  loss: 0.7674  loss_rpn_cls: 0.0343  loss_rpn_bbox: 0.0455  loss_cls: 0.1924  acc: 87.5000  loss_bbox: 0.2517  loss_mask: 0.2435
2025/12/15 00:16:02 - mmengine - INFO - Epoch(train) [11][1550/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:39:42  time: 1.0193  data_time: 0.0032  memory: 9409  loss: 0.7741  loss_rpn_cls: 0.0334  loss_rpn_bbox: 0.0492  loss_cls: 0.1961  acc: 95.5078  loss_bbox: 0.2500  loss_mask: 0.2454
2025/12/15 00:16:53 - mmengine - INFO - Epoch(train) [11][1600/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:38:52  time: 1.0147  data_time: 0.0030  memory: 9358  loss: 0.6987  loss_rpn_cls: 0.0283  loss_rpn_bbox: 0.0378  loss_cls: 0.1730  acc: 92.7734  loss_bbox: 0.2232  loss_mask: 0.2365
2025/12/15 00:17:45 - mmengine - INFO - Epoch(train) [11][1650/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:38:05  time: 1.0445  data_time: 0.0046  memory: 9441  loss: 0.7316  loss_rpn_cls: 0.0318  loss_rpn_bbox: 0.0404  loss_cls: 0.1880  acc: 97.1191  loss_bbox: 0.2332  loss_mask: 0.2383
2025/12/15 00:18:37 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/15 00:18:37 - mmengine - INFO - Epoch(train) [11][1700/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:37:17  time: 1.0413  data_time: 0.0032  memory: 9274  loss: 0.6739  loss_rpn_cls: 0.0296  loss_rpn_bbox: 0.0341  loss_cls: 0.1690  acc: 93.9941  loss_bbox: 0.2146  loss_mask: 0.2267
2025/12/15 00:19:29 - mmengine - INFO - Epoch(train) [11][1750/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:36:30  time: 1.0448  data_time: 0.0033  memory: 10143  loss: 0.7261  loss_rpn_cls: 0.0290  loss_rpn_bbox: 0.0398  loss_cls: 0.1831  acc: 92.0410  loss_bbox: 0.2306  loss_mask: 0.2436
2025/12/15 00:20:21 - mmengine - INFO - Epoch(train) [11][1800/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:35:41  time: 1.0274  data_time: 0.0032  memory: 9448  loss: 0.7560  loss_rpn_cls: 0.0315  loss_rpn_bbox: 0.0451  loss_cls: 0.1899  acc: 93.4570  loss_bbox: 0.2469  loss_mask: 0.2426
2025/12/15 00:21:12 - mmengine - INFO - Epoch(train) [11][1850/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:34:53  time: 1.0345  data_time: 0.0032  memory: 9628  loss: 0.7319  loss_rpn_cls: 0.0319  loss_rpn_bbox: 0.0398  loss_cls: 0.1958  acc: 92.8223  loss_bbox: 0.2327  loss_mask: 0.2317
2025/12/15 00:22:03 - mmengine - INFO - Epoch(train) [11][1900/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:34:03  time: 1.0124  data_time: 0.0032  memory: 9531  loss: 0.7375  loss_rpn_cls: 0.0308  loss_rpn_bbox: 0.0456  loss_cls: 0.1901  acc: 95.9961  loss_bbox: 0.2395  loss_mask: 0.2314
2025/12/15 00:22:54 - mmengine - INFO - Epoch(train) [11][1950/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:33:13  time: 1.0164  data_time: 0.0032  memory: 9638  loss: 0.6796  loss_rpn_cls: 0.0275  loss_rpn_bbox: 0.0366  loss_cls: 0.1660  acc: 96.6797  loss_bbox: 0.2161  loss_mask: 0.2334
2025/12/15 00:23:44 - mmengine - INFO - Epoch(train) [11][2000/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:32:23  time: 1.0052  data_time: 0.0033  memory: 9576  loss: 0.6935  loss_rpn_cls: 0.0258  loss_rpn_bbox: 0.0390  loss_cls: 0.1682  acc: 96.1426  loss_bbox: 0.2280  loss_mask: 0.2324
2025/12/15 00:24:36 - mmengine - INFO - Epoch(train) [11][2050/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:31:35  time: 1.0417  data_time: 0.0033  memory: 9641  loss: 0.7866  loss_rpn_cls: 0.0349  loss_rpn_bbox: 0.0452  loss_cls: 0.1974  acc: 88.0859  loss_bbox: 0.2533  loss_mask: 0.2557
2025/12/15 00:25:27 - mmengine - INFO - Epoch(train) [11][2100/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:30:45  time: 1.0206  data_time: 0.0032  memory: 9604  loss: 0.7386  loss_rpn_cls: 0.0283  loss_rpn_bbox: 0.0403  loss_cls: 0.1904  acc: 93.8477  loss_bbox: 0.2351  loss_mask: 0.2446
2025/12/15 00:26:18 - mmengine - INFO - Epoch(train) [11][2150/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:29:56  time: 1.0192  data_time: 0.0032  memory: 9294  loss: 0.7205  loss_rpn_cls: 0.0302  loss_rpn_bbox: 0.0407  loss_cls: 0.1868  acc: 96.6797  loss_bbox: 0.2309  loss_mask: 0.2319
2025/12/15 00:27:09 - mmengine - INFO - Epoch(train) [11][2200/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:29:06  time: 1.0155  data_time: 0.0032  memory: 9303  loss: 0.6835  loss_rpn_cls: 0.0264  loss_rpn_bbox: 0.0366  loss_cls: 0.1755  acc: 90.3809  loss_bbox: 0.2164  loss_mask: 0.2285
2025/12/15 00:27:59 - mmengine - INFO - Epoch(train) [11][2250/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:28:16  time: 1.0099  data_time: 0.0032  memory: 9537  loss: 0.6745  loss_rpn_cls: 0.0269  loss_rpn_bbox: 0.0356  loss_cls: 0.1718  acc: 96.1914  loss_bbox: 0.2138  loss_mask: 0.2263
2025/12/15 00:28:52 - mmengine - INFO - Epoch(train) [11][2300/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:27:28  time: 1.0414  data_time: 0.0034  memory: 9513  loss: 0.6809  loss_rpn_cls: 0.0262  loss_rpn_bbox: 0.0364  loss_cls: 0.1727  acc: 88.8184  loss_bbox: 0.2160  loss_mask: 0.2296
2025/12/15 00:29:43 - mmengine - INFO - Epoch(train) [11][2350/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:26:39  time: 1.0325  data_time: 0.0033  memory: 9353  loss: 0.7551  loss_rpn_cls: 0.0336  loss_rpn_bbox: 0.0442  loss_cls: 0.1963  acc: 93.7012  loss_bbox: 0.2434  loss_mask: 0.2375
2025/12/15 00:30:34 - mmengine - INFO - Epoch(train) [11][2400/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:25:50  time: 1.0240  data_time: 0.0033  memory: 9909  loss: 0.7406  loss_rpn_cls: 0.0292  loss_rpn_bbox: 0.0431  loss_cls: 0.1858  acc: 91.8945  loss_bbox: 0.2379  loss_mask: 0.2447
2025/12/15 00:31:25 - mmengine - INFO - Epoch(train) [11][2450/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:25:00  time: 1.0172  data_time: 0.0033  memory: 9345  loss: 0.6948  loss_rpn_cls: 0.0292  loss_rpn_bbox: 0.0376  loss_cls: 0.1824  acc: 91.6504  loss_bbox: 0.2226  loss_mask: 0.2230
2025/12/15 00:32:16 - mmengine - INFO - Epoch(train) [11][2500/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:24:10  time: 1.0199  data_time: 0.0034  memory: 9824  loss: 0.6992  loss_rpn_cls: 0.0285  loss_rpn_bbox: 0.0395  loss_cls: 0.1704  acc: 92.7734  loss_bbox: 0.2274  loss_mask: 0.2334
2025/12/15 00:33:07 - mmengine - INFO - Epoch(train) [11][2550/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:23:20  time: 1.0097  data_time: 0.0033  memory: 9433  loss: 0.7350  loss_rpn_cls: 0.0318  loss_rpn_bbox: 0.0427  loss_cls: 0.1798  acc: 89.6484  loss_bbox: 0.2438  loss_mask: 0.2369
2025/12/15 00:33:57 - mmengine - INFO - Epoch(train) [11][2600/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:22:30  time: 1.0131  data_time: 0.0034  memory: 9573  loss: 0.7496  loss_rpn_cls: 0.0275  loss_rpn_bbox: 0.0405  loss_cls: 0.1922  acc: 90.9668  loss_bbox: 0.2437  loss_mask: 0.2457
2025/12/15 00:34:49 - mmengine - INFO - Epoch(train) [11][2650/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:21:41  time: 1.0327  data_time: 0.0033  memory: 9380  loss: 0.7769  loss_rpn_cls: 0.0308  loss_rpn_bbox: 0.0433  loss_cls: 0.1986  acc: 90.9668  loss_bbox: 0.2526  loss_mask: 0.2516
2025/12/15 00:35:40 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/15 00:35:40 - mmengine - INFO - Epoch(train) [11][2700/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:20:51  time: 1.0091  data_time: 0.0032  memory: 9289  loss: 0.6923  loss_rpn_cls: 0.0292  loss_rpn_bbox: 0.0359  loss_cls: 0.1671  acc: 95.9473  loss_bbox: 0.2212  loss_mask: 0.2389
2025/12/15 00:36:30 - mmengine - INFO - Epoch(train) [11][2750/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:20:01  time: 1.0175  data_time: 0.0032  memory: 9712  loss: 0.6971  loss_rpn_cls: 0.0309  loss_rpn_bbox: 0.0402  loss_cls: 0.1731  acc: 98.4375  loss_bbox: 0.2200  loss_mask: 0.2329
2025/12/15 00:37:22 - mmengine - INFO - Epoch(train) [11][2800/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:19:12  time: 1.0369  data_time: 0.0034  memory: 9549  loss: 0.7529  loss_rpn_cls: 0.0310  loss_rpn_bbox: 0.0443  loss_cls: 0.1928  acc: 93.4570  loss_bbox: 0.2435  loss_mask: 0.2413
2025/12/15 00:38:13 - mmengine - INFO - Epoch(train) [11][2850/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:18:23  time: 1.0227  data_time: 0.0033  memory: 9772  loss: 0.7009  loss_rpn_cls: 0.0274  loss_rpn_bbox: 0.0397  loss_cls: 0.1769  acc: 91.4551  loss_bbox: 0.2226  loss_mask: 0.2343
2025/12/15 00:39:04 - mmengine - INFO - Epoch(train) [11][2900/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:17:33  time: 1.0148  data_time: 0.0033  memory: 9293  loss: 0.7124  loss_rpn_cls: 0.0294  loss_rpn_bbox: 0.0381  loss_cls: 0.1833  acc: 88.1348  loss_bbox: 0.2285  loss_mask: 0.2331
2025/12/15 00:39:56 - mmengine - INFO - Epoch(train) [11][2950/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:16:44  time: 1.0299  data_time: 0.0033  memory: 9534  loss: 0.7734  loss_rpn_cls: 0.0340  loss_rpn_bbox: 0.0450  loss_cls: 0.2002  acc: 92.9688  loss_bbox: 0.2561  loss_mask: 0.2381
2025/12/15 00:40:46 - mmengine - INFO - Epoch(train) [11][3000/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:15:53  time: 1.0071  data_time: 0.0033  memory: 9108  loss: 0.7313  loss_rpn_cls: 0.0288  loss_rpn_bbox: 0.0463  loss_cls: 0.1858  acc: 91.2598  loss_bbox: 0.2315  loss_mask: 0.2390
2025/12/15 00:41:37 - mmengine - INFO - Epoch(train) [11][3050/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:15:04  time: 1.0231  data_time: 0.0034  memory: 9253  loss: 0.7020  loss_rpn_cls: 0.0288  loss_rpn_bbox: 0.0421  loss_cls: 0.1861  acc: 96.2891  loss_bbox: 0.2224  loss_mask: 0.2226
2025/12/15 00:42:28 - mmengine - INFO - Epoch(train) [11][3100/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:14:14  time: 1.0220  data_time: 0.0032  memory: 9377  loss: 0.7382  loss_rpn_cls: 0.0308  loss_rpn_bbox: 0.0426  loss_cls: 0.1837  acc: 90.3809  loss_bbox: 0.2372  loss_mask: 0.2439
2025/12/15 00:43:20 - mmengine - INFO - Epoch(train) [11][3150/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:13:25  time: 1.0296  data_time: 0.0033  memory: 9427  loss: 0.7482  loss_rpn_cls: 0.0325  loss_rpn_bbox: 0.0394  loss_cls: 0.1980  acc: 92.2852  loss_bbox: 0.2386  loss_mask: 0.2396
2025/12/15 00:44:11 - mmengine - INFO - Epoch(train) [11][3200/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:12:35  time: 1.0289  data_time: 0.0033  memory: 9243  loss: 0.7008  loss_rpn_cls: 0.0251  loss_rpn_bbox: 0.0378  loss_cls: 0.1760  acc: 94.3359  loss_bbox: 0.2236  loss_mask: 0.2383
2025/12/15 00:45:03 - mmengine - INFO - Epoch(train) [11][3250/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:11:46  time: 1.0266  data_time: 0.0034  memory: 9416  loss: 0.7076  loss_rpn_cls: 0.0320  loss_rpn_bbox: 0.0419  loss_cls: 0.1738  acc: 89.5020  loss_bbox: 0.2198  loss_mask: 0.2401
2025/12/15 00:45:54 - mmengine - INFO - Epoch(train) [11][3300/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:10:56  time: 1.0240  data_time: 0.0035  memory: 9451  loss: 0.7065  loss_rpn_cls: 0.0275  loss_rpn_bbox: 0.0393  loss_cls: 0.1736  acc: 92.2852  loss_bbox: 0.2267  loss_mask: 0.2394
2025/12/15 00:46:44 - mmengine - INFO - Epoch(train) [11][3350/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:10:06  time: 1.0133  data_time: 0.0033  memory: 9510  loss: 0.7502  loss_rpn_cls: 0.0276  loss_rpn_bbox: 0.0392  loss_cls: 0.1919  acc: 93.0176  loss_bbox: 0.2481  loss_mask: 0.2435
2025/12/15 00:47:36 - mmengine - INFO - Epoch(train) [11][3400/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:09:17  time: 1.0324  data_time: 0.0033  memory: 9395  loss: 0.6957  loss_rpn_cls: 0.0264  loss_rpn_bbox: 0.0403  loss_cls: 0.1810  acc: 92.6270  loss_bbox: 0.2222  loss_mask: 0.2258
2025/12/15 00:48:27 - mmengine - INFO - Epoch(train) [11][3450/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:08:27  time: 1.0112  data_time: 0.0034  memory: 10380  loss: 0.7693  loss_rpn_cls: 0.0314  loss_rpn_bbox: 0.0446  loss_cls: 0.1961  acc: 85.3027  loss_bbox: 0.2523  loss_mask: 0.2449
2025/12/15 00:49:19 - mmengine - INFO - Epoch(train) [11][3500/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:07:38  time: 1.0409  data_time: 0.0034  memory: 9605  loss: 0.7167  loss_rpn_cls: 0.0305  loss_rpn_bbox: 0.0406  loss_cls: 0.1873  acc: 93.4082  loss_bbox: 0.2295  loss_mask: 0.2289
2025/12/15 00:50:10 - mmengine - INFO - Epoch(train) [11][3550/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:06:48  time: 1.0179  data_time: 0.0034  memory: 9318  loss: 0.7203  loss_rpn_cls: 0.0287  loss_rpn_bbox: 0.0417  loss_cls: 0.1855  acc: 91.5527  loss_bbox: 0.2266  loss_mask: 0.2378
2025/12/15 00:51:02 - mmengine - INFO - Epoch(train) [11][3600/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:05:59  time: 1.0430  data_time: 0.0034  memory: 9342  loss: 0.7166  loss_rpn_cls: 0.0301  loss_rpn_bbox: 0.0421  loss_cls: 0.1759  acc: 97.3633  loss_bbox: 0.2382  loss_mask: 0.2303
2025/12/15 00:51:53 - mmengine - INFO - Epoch(train) [11][3650/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:05:10  time: 1.0295  data_time: 0.0033  memory: 9557  loss: 0.7027  loss_rpn_cls: 0.0291  loss_rpn_bbox: 0.0391  loss_cls: 0.1733  acc: 96.5820  loss_bbox: 0.2190  loss_mask: 0.2423
2025/12/15 00:52:45 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/15 00:52:45 - mmengine - INFO - Epoch(train) [11][3700/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:04:20  time: 1.0245  data_time: 0.0033  memory: 9162  loss: 0.7231  loss_rpn_cls: 0.0300  loss_rpn_bbox: 0.0392  loss_cls: 0.1848  acc: 94.6289  loss_bbox: 0.2307  loss_mask: 0.2383
2025/12/15 00:53:36 - mmengine - INFO - Epoch(train) [11][3750/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:03:30  time: 1.0232  data_time: 0.0033  memory: 9435  loss: 0.7619  loss_rpn_cls: 0.0338  loss_rpn_bbox: 0.0400  loss_cls: 0.1987  acc: 89.5020  loss_bbox: 0.2432  loss_mask: 0.2462
2025/12/15 00:54:27 - mmengine - INFO - Epoch(train) [11][3800/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:02:41  time: 1.0219  data_time: 0.0034  memory: 9176  loss: 0.7174  loss_rpn_cls: 0.0292  loss_rpn_bbox: 0.0430  loss_cls: 0.1758  acc: 90.5273  loss_bbox: 0.2317  loss_mask: 0.2378
2025/12/15 00:55:18 - mmengine - INFO - Epoch(train) [11][3850/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:01:51  time: 1.0215  data_time: 0.0034  memory: 9817  loss: 0.7020  loss_rpn_cls: 0.0249  loss_rpn_bbox: 0.0398  loss_cls: 0.1775  acc: 93.3105  loss_bbox: 0.2287  loss_mask: 0.2311
2025/12/15 00:56:08 - mmengine - INFO - Epoch(train) [11][3900/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:01:00  time: 1.0086  data_time: 0.0033  memory: 9211  loss: 0.7423  loss_rpn_cls: 0.0260  loss_rpn_bbox: 0.0430  loss_cls: 0.1889  acc: 94.9707  loss_bbox: 0.2358  loss_mask: 0.2486
2025/12/15 00:57:01 - mmengine - INFO - Epoch(train) [11][3950/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 3:00:11  time: 1.0433  data_time: 0.0033  memory: 9305  loss: 0.7008  loss_rpn_cls: 0.0280  loss_rpn_bbox: 0.0356  loss_cls: 0.1757  acc: 96.8750  loss_bbox: 0.2212  loss_mask: 0.2403
2025/12/15 00:57:52 - mmengine - INFO - Epoch(train) [11][4000/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:59:22  time: 1.0246  data_time: 0.0033  memory: 9260  loss: 0.7182  loss_rpn_cls: 0.0298  loss_rpn_bbox: 0.0360  loss_cls: 0.1866  acc: 92.1875  loss_bbox: 0.2303  loss_mask: 0.2354
2025/12/15 00:58:43 - mmengine - INFO - Epoch(train) [11][4050/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:58:31  time: 1.0153  data_time: 0.0033  memory: 9527  loss: 0.7048  loss_rpn_cls: 0.0272  loss_rpn_bbox: 0.0380  loss_cls: 0.1761  acc: 93.6523  loss_bbox: 0.2312  loss_mask: 0.2324
2025/12/15 00:59:34 - mmengine - INFO - Epoch(train) [11][4100/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:57:42  time: 1.0254  data_time: 0.0034  memory: 9383  loss: 0.7291  loss_rpn_cls: 0.0297  loss_rpn_bbox: 0.0400  loss_cls: 0.1794  acc: 87.1094  loss_bbox: 0.2315  loss_mask: 0.2486
2025/12/15 01:00:25 - mmengine - INFO - Epoch(train) [11][4150/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:56:52  time: 1.0328  data_time: 0.0034  memory: 9424  loss: 0.6853  loss_rpn_cls: 0.0281  loss_rpn_bbox: 0.0384  loss_cls: 0.1714  acc: 93.8477  loss_bbox: 0.2226  loss_mask: 0.2248
2025/12/15 01:01:17 - mmengine - INFO - Epoch(train) [11][4200/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:56:03  time: 1.0308  data_time: 0.0033  memory: 9666  loss: 0.7054  loss_rpn_cls: 0.0324  loss_rpn_bbox: 0.0423  loss_cls: 0.1768  acc: 94.7266  loss_bbox: 0.2150  loss_mask: 0.2389
2025/12/15 01:02:08 - mmengine - INFO - Epoch(train) [11][4250/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:55:13  time: 1.0240  data_time: 0.0034  memory: 9352  loss: 0.7247  loss_rpn_cls: 0.0273  loss_rpn_bbox: 0.0411  loss_cls: 0.1802  acc: 89.1602  loss_bbox: 0.2371  loss_mask: 0.2391
2025/12/15 01:02:59 - mmengine - INFO - Epoch(train) [11][4300/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:54:23  time: 1.0233  data_time: 0.0036  memory: 9409  loss: 0.7143  loss_rpn_cls: 0.0272  loss_rpn_bbox: 0.0385  loss_cls: 0.1827  acc: 95.8496  loss_bbox: 0.2314  loss_mask: 0.2344
2025/12/15 01:03:50 - mmengine - INFO - Epoch(train) [11][4350/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:53:33  time: 1.0207  data_time: 0.0037  memory: 9292  loss: 0.6936  loss_rpn_cls: 0.0298  loss_rpn_bbox: 0.0363  loss_cls: 0.1764  acc: 96.1426  loss_bbox: 0.2189  loss_mask: 0.2322
2025/12/15 01:04:41 - mmengine - INFO - Epoch(train) [11][4400/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:52:42  time: 1.0113  data_time: 0.0036  memory: 9368  loss: 0.7242  loss_rpn_cls: 0.0310  loss_rpn_bbox: 0.0411  loss_cls: 0.1806  acc: 94.2383  loss_bbox: 0.2333  loss_mask: 0.2382
2025/12/15 01:05:32 - mmengine - INFO - Epoch(train) [11][4450/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:51:52  time: 1.0201  data_time: 0.0037  memory: 9412  loss: 0.7043  loss_rpn_cls: 0.0263  loss_rpn_bbox: 0.0392  loss_cls: 0.1719  acc: 97.4121  loss_bbox: 0.2293  loss_mask: 0.2376
2025/12/15 01:06:25 - mmengine - INFO - Epoch(train) [11][4500/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:51:03  time: 1.0481  data_time: 0.0036  memory: 9622  loss: 0.7351  loss_rpn_cls: 0.0317  loss_rpn_bbox: 0.0368  loss_cls: 0.1863  acc: 98.7305  loss_bbox: 0.2387  loss_mask: 0.2417
2025/12/15 01:07:16 - mmengine - INFO - Epoch(train) [11][4550/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:50:14  time: 1.0291  data_time: 0.0036  memory: 9298  loss: 0.7562  loss_rpn_cls: 0.0334  loss_rpn_bbox: 0.0482  loss_cls: 0.1948  acc: 91.5527  loss_bbox: 0.2433  loss_mask: 0.2366
2025/12/15 01:08:08 - mmengine - INFO - Epoch(train) [11][4600/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:49:24  time: 1.0324  data_time: 0.0036  memory: 9657  loss: 0.6591  loss_rpn_cls: 0.0275  loss_rpn_bbox: 0.0358  loss_cls: 0.1678  acc: 92.1875  loss_bbox: 0.2069  loss_mask: 0.2211
2025/12/15 01:09:00 - mmengine - INFO - Epoch(train) [11][4650/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:48:35  time: 1.0483  data_time: 0.0036  memory: 9466  loss: 0.7206  loss_rpn_cls: 0.0263  loss_rpn_bbox: 0.0394  loss_cls: 0.1826  acc: 91.5527  loss_bbox: 0.2379  loss_mask: 0.2344
2025/12/15 01:09:52 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/15 01:09:52 - mmengine - INFO - Epoch(train) [11][4700/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:47:46  time: 1.0347  data_time: 0.0036  memory: 9355  loss: 0.7302  loss_rpn_cls: 0.0312  loss_rpn_bbox: 0.0435  loss_cls: 0.1796  acc: 96.9238  loss_bbox: 0.2385  loss_mask: 0.2374
2025/12/15 01:10:43 - mmengine - INFO - Epoch(train) [11][4750/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:46:56  time: 1.0276  data_time: 0.0036  memory: 10341  loss: 0.7316  loss_rpn_cls: 0.0260  loss_rpn_bbox: 0.0421  loss_cls: 0.1899  acc: 95.1660  loss_bbox: 0.2363  loss_mask: 0.2374
2025/12/15 01:11:34 - mmengine - INFO - Epoch(train) [11][4800/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:46:06  time: 1.0154  data_time: 0.0037  memory: 9576  loss: 0.7251  loss_rpn_cls: 0.0330  loss_rpn_bbox: 0.0398  loss_cls: 0.1871  acc: 96.9727  loss_bbox: 0.2337  loss_mask: 0.2314
2025/12/15 01:12:25 - mmengine - INFO - Epoch(train) [11][4850/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:45:15  time: 1.0210  data_time: 0.0037  memory: 9300  loss: 0.6801  loss_rpn_cls: 0.0249  loss_rpn_bbox: 0.0331  loss_cls: 0.1674  acc: 93.1641  loss_bbox: 0.2195  loss_mask: 0.2352
2025/12/15 01:13:16 - mmengine - INFO - Epoch(train) [11][4900/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:44:25  time: 1.0167  data_time: 0.0038  memory: 9560  loss: 0.7091  loss_rpn_cls: 0.0287  loss_rpn_bbox: 0.0376  loss_cls: 0.1786  acc: 93.6523  loss_bbox: 0.2205  loss_mask: 0.2437
2025/12/15 01:14:07 - mmengine - INFO - Epoch(train) [11][4950/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:43:35  time: 1.0152  data_time: 0.0037  memory: 9368  loss: 0.7201  loss_rpn_cls: 0.0297  loss_rpn_bbox: 0.0427  loss_cls: 0.1801  acc: 95.9961  loss_bbox: 0.2306  loss_mask: 0.2369
2025/12/15 01:14:57 - mmengine - INFO - Epoch(train) [11][5000/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:42:44  time: 1.0122  data_time: 0.0037  memory: 9316  loss: 0.7150  loss_rpn_cls: 0.0306  loss_rpn_bbox: 0.0379  loss_cls: 0.1779  acc: 93.6523  loss_bbox: 0.2293  loss_mask: 0.2393
2025/12/15 01:15:48 - mmengine - INFO - Epoch(train) [11][5050/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:41:54  time: 1.0227  data_time: 0.0037  memory: 9342  loss: 0.6806  loss_rpn_cls: 0.0252  loss_rpn_bbox: 0.0357  loss_cls: 0.1712  acc: 94.1406  loss_bbox: 0.2132  loss_mask: 0.2353
2025/12/15 01:16:40 - mmengine - INFO - Epoch(train) [11][5100/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:41:04  time: 1.0234  data_time: 0.0038  memory: 9343  loss: 0.7869  loss_rpn_cls: 0.0362  loss_rpn_bbox: 0.0505  loss_cls: 0.2026  acc: 96.6797  loss_bbox: 0.2570  loss_mask: 0.2406
2025/12/15 01:17:31 - mmengine - INFO - Epoch(train) [11][5150/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:40:14  time: 1.0342  data_time: 0.0037  memory: 9269  loss: 0.7510  loss_rpn_cls: 0.0355  loss_rpn_bbox: 0.0440  loss_cls: 0.1917  acc: 92.6758  loss_bbox: 0.2391  loss_mask: 0.2407
2025/12/15 01:18:22 - mmengine - INFO - Epoch(train) [11][5200/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:39:24  time: 1.0148  data_time: 0.0038  memory: 9291  loss: 0.7177  loss_rpn_cls: 0.0308  loss_rpn_bbox: 0.0431  loss_cls: 0.1721  acc: 92.7734  loss_bbox: 0.2244  loss_mask: 0.2473
2025/12/15 01:19:14 - mmengine - INFO - Epoch(train) [11][5250/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:38:35  time: 1.0413  data_time: 0.0042  memory: 9468  loss: 0.7281  loss_rpn_cls: 0.0271  loss_rpn_bbox: 0.0390  loss_cls: 0.1868  acc: 91.9922  loss_bbox: 0.2379  loss_mask: 0.2372
2025/12/15 01:20:06 - mmengine - INFO - Epoch(train) [11][5300/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:37:45  time: 1.0401  data_time: 0.0040  memory: 9443  loss: 0.7154  loss_rpn_cls: 0.0291  loss_rpn_bbox: 0.0424  loss_cls: 0.1768  acc: 91.3086  loss_bbox: 0.2226  loss_mask: 0.2446
2025/12/15 01:20:57 - mmengine - INFO - Epoch(train) [11][5350/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:36:55  time: 1.0165  data_time: 0.0035  memory: 9403  loss: 0.7182  loss_rpn_cls: 0.0286  loss_rpn_bbox: 0.0367  loss_cls: 0.1789  acc: 94.6777  loss_bbox: 0.2275  loss_mask: 0.2466
2025/12/15 01:21:49 - mmengine - INFO - Epoch(train) [11][5400/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:36:05  time: 1.0304  data_time: 0.0035  memory: 9313  loss: 0.7090  loss_rpn_cls: 0.0327  loss_rpn_bbox: 0.0414  loss_cls: 0.1855  acc: 96.1426  loss_bbox: 0.2248  loss_mask: 0.2246
2025/12/15 01:22:40 - mmengine - INFO - Epoch(train) [11][5450/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:35:15  time: 1.0373  data_time: 0.0034  memory: 9283  loss: 0.6508  loss_rpn_cls: 0.0242  loss_rpn_bbox: 0.0352  loss_cls: 0.1580  acc: 92.9199  loss_bbox: 0.2058  loss_mask: 0.2275
2025/12/15 01:23:32 - mmengine - INFO - Epoch(train) [11][5500/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:34:26  time: 1.0408  data_time: 0.0037  memory: 9538  loss: 0.6921  loss_rpn_cls: 0.0313  loss_rpn_bbox: 0.0380  loss_cls: 0.1657  acc: 91.0156  loss_bbox: 0.2199  loss_mask: 0.2372
2025/12/15 01:24:24 - mmengine - INFO - Epoch(train) [11][5550/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:33:36  time: 1.0336  data_time: 0.0038  memory: 9568  loss: 0.7398  loss_rpn_cls: 0.0326  loss_rpn_bbox: 0.0441  loss_cls: 0.1911  acc: 90.0391  loss_bbox: 0.2371  loss_mask: 0.2349
2025/12/15 01:25:16 - mmengine - INFO - Epoch(train) [11][5600/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:32:46  time: 1.0370  data_time: 0.0038  memory: 9419  loss: 0.7030  loss_rpn_cls: 0.0290  loss_rpn_bbox: 0.0361  loss_cls: 0.1817  acc: 96.0449  loss_bbox: 0.2259  loss_mask: 0.2303
2025/12/15 01:26:08 - mmengine - INFO - Epoch(train) [11][5650/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:31:56  time: 1.0308  data_time: 0.0037  memory: 9838  loss: 0.6802  loss_rpn_cls: 0.0283  loss_rpn_bbox: 0.0375  loss_cls: 0.1670  acc: 96.6309  loss_bbox: 0.2242  loss_mask: 0.2232
2025/12/15 01:27:00 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/15 01:27:00 - mmengine - INFO - Epoch(train) [11][5700/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:31:07  time: 1.0392  data_time: 0.0037  memory: 9207  loss: 0.7009  loss_rpn_cls: 0.0268  loss_rpn_bbox: 0.0363  loss_cls: 0.1786  acc: 95.4102  loss_bbox: 0.2274  loss_mask: 0.2319
2025/12/15 01:27:53 - mmengine - INFO - Epoch(train) [11][5750/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:30:18  time: 1.0609  data_time: 0.0035  memory: 9471  loss: 0.7641  loss_rpn_cls: 0.0308  loss_rpn_bbox: 0.0436  loss_cls: 0.1949  acc: 90.0391  loss_bbox: 0.2478  loss_mask: 0.2470
2025/12/15 01:28:46 - mmengine - INFO - Epoch(train) [11][5800/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:29:29  time: 1.0594  data_time: 0.0036  memory: 9447  loss: 0.7729  loss_rpn_cls: 0.0363  loss_rpn_bbox: 0.0429  loss_cls: 0.1930  acc: 95.4102  loss_bbox: 0.2508  loss_mask: 0.2498
2025/12/15 01:29:38 - mmengine - INFO - Epoch(train) [11][5850/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:28:39  time: 1.0490  data_time: 0.0035  memory: 9857  loss: 0.7391  loss_rpn_cls: 0.0296  loss_rpn_bbox: 0.0435  loss_cls: 0.1883  acc: 90.2344  loss_bbox: 0.2295  loss_mask: 0.2481
2025/12/15 01:30:30 - mmengine - INFO - Epoch(train) [11][5900/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:27:49  time: 1.0311  data_time: 0.0034  memory: 9375  loss: 0.7890  loss_rpn_cls: 0.0344  loss_rpn_bbox: 0.0447  loss_cls: 0.2029  acc: 95.0195  loss_bbox: 0.2580  loss_mask: 0.2489
2025/12/15 01:31:21 - mmengine - INFO - Epoch(train) [11][5950/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:26:59  time: 1.0327  data_time: 0.0034  memory: 9582  loss: 0.7466  loss_rpn_cls: 0.0313  loss_rpn_bbox: 0.0425  loss_cls: 0.1966  acc: 93.5059  loss_bbox: 0.2452  loss_mask: 0.2310
2025/12/15 01:32:12 - mmengine - INFO - Epoch(train) [11][6000/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:26:09  time: 1.0201  data_time: 0.0033  memory: 9242  loss: 0.7276  loss_rpn_cls: 0.0337  loss_rpn_bbox: 0.0415  loss_cls: 0.1827  acc: 91.3574  loss_bbox: 0.2329  loss_mask: 0.2368
2025/12/15 01:33:03 - mmengine - INFO - Epoch(train) [11][6050/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:25:18  time: 1.0055  data_time: 0.0033  memory: 9417  loss: 0.6917  loss_rpn_cls: 0.0321  loss_rpn_bbox: 0.0382  loss_cls: 0.1702  acc: 95.7031  loss_bbox: 0.2179  loss_mask: 0.2334
2025/12/15 01:33:54 - mmengine - INFO - Epoch(train) [11][6100/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:24:28  time: 1.0246  data_time: 0.0035  memory: 9393  loss: 0.7031  loss_rpn_cls: 0.0269  loss_rpn_bbox: 0.0363  loss_cls: 0.1723  acc: 96.6797  loss_bbox: 0.2236  loss_mask: 0.2440
2025/12/15 01:34:45 - mmengine - INFO - Epoch(train) [11][6150/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:23:38  time: 1.0325  data_time: 0.0033  memory: 9213  loss: 0.7197  loss_rpn_cls: 0.0289  loss_rpn_bbox: 0.0372  loss_cls: 0.1862  acc: 89.1113  loss_bbox: 0.2280  loss_mask: 0.2395
2025/12/15 01:35:37 - mmengine - INFO - Epoch(train) [11][6200/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:22:48  time: 1.0321  data_time: 0.0033  memory: 9471  loss: 0.7475  loss_rpn_cls: 0.0287  loss_rpn_bbox: 0.0389  loss_cls: 0.1880  acc: 91.5039  loss_bbox: 0.2393  loss_mask: 0.2525
2025/12/15 01:36:29 - mmengine - INFO - Epoch(train) [11][6250/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:21:58  time: 1.0351  data_time: 0.0034  memory: 9438  loss: 0.7252  loss_rpn_cls: 0.0300  loss_rpn_bbox: 0.0400  loss_cls: 0.1844  acc: 89.9902  loss_bbox: 0.2369  loss_mask: 0.2339
2025/12/15 01:37:20 - mmengine - INFO - Epoch(train) [11][6300/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:21:08  time: 1.0315  data_time: 0.0035  memory: 9375  loss: 0.7286  loss_rpn_cls: 0.0337  loss_rpn_bbox: 0.0404  loss_cls: 0.1787  acc: 98.2910  loss_bbox: 0.2311  loss_mask: 0.2448
2025/12/15 01:38:12 - mmengine - INFO - Epoch(train) [11][6350/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:20:18  time: 1.0276  data_time: 0.0036  memory: 9389  loss: 0.6922  loss_rpn_cls: 0.0272  loss_rpn_bbox: 0.0378  loss_cls: 0.1747  acc: 97.8516  loss_bbox: 0.2181  loss_mask: 0.2343
2025/12/15 01:39:02 - mmengine - INFO - Epoch(train) [11][6400/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:19:27  time: 1.0065  data_time: 0.0034  memory: 9707  loss: 0.7661  loss_rpn_cls: 0.0295  loss_rpn_bbox: 0.0442  loss_cls: 0.1922  acc: 92.2363  loss_bbox: 0.2458  loss_mask: 0.2544
2025/12/15 01:39:54 - mmengine - INFO - Epoch(train) [11][6450/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:18:37  time: 1.0317  data_time: 0.0034  memory: 9469  loss: 0.7603  loss_rpn_cls: 0.0341  loss_rpn_bbox: 0.0413  loss_cls: 0.1980  acc: 92.7734  loss_bbox: 0.2444  loss_mask: 0.2426
2025/12/15 01:40:45 - mmengine - INFO - Epoch(train) [11][6500/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:17:46  time: 1.0230  data_time: 0.0037  memory: 9241  loss: 0.7462  loss_rpn_cls: 0.0326  loss_rpn_bbox: 0.0431  loss_cls: 0.1941  acc: 95.0684  loss_bbox: 0.2383  loss_mask: 0.2381
2025/12/15 01:41:38 - mmengine - INFO - Epoch(train) [11][6550/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:16:57  time: 1.0543  data_time: 0.0038  memory: 9284  loss: 0.6813  loss_rpn_cls: 0.0293  loss_rpn_bbox: 0.0368  loss_cls: 0.1771  acc: 90.4297  loss_bbox: 0.2151  loss_mask: 0.2229
2025/12/15 01:42:29 - mmengine - INFO - Epoch(train) [11][6600/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:16:06  time: 1.0203  data_time: 0.0038  memory: 9659  loss: 0.6975  loss_rpn_cls: 0.0266  loss_rpn_bbox: 0.0374  loss_cls: 0.1734  acc: 92.3340  loss_bbox: 0.2316  loss_mask: 0.2285
2025/12/15 01:43:20 - mmengine - INFO - Epoch(train) [11][6650/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:15:16  time: 1.0336  data_time: 0.0038  memory: 9358  loss: 0.7130  loss_rpn_cls: 0.0271  loss_rpn_bbox: 0.0382  loss_cls: 0.1762  acc: 92.2363  loss_bbox: 0.2264  loss_mask: 0.2450
2025/12/15 01:44:13 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/15 01:44:13 - mmengine - INFO - Epoch(train) [11][6700/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:14:27  time: 1.0521  data_time: 0.0037  memory: 9647  loss: 0.7604  loss_rpn_cls: 0.0365  loss_rpn_bbox: 0.0428  loss_cls: 0.1924  acc: 96.6309  loss_bbox: 0.2461  loss_mask: 0.2427
2025/12/15 01:45:05 - mmengine - INFO - Epoch(train) [11][6750/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:13:37  time: 1.0374  data_time: 0.0038  memory: 9724  loss: 0.7394  loss_rpn_cls: 0.0329  loss_rpn_bbox: 0.0417  loss_cls: 0.1911  acc: 92.4805  loss_bbox: 0.2442  loss_mask: 0.2295
2025/12/15 01:45:57 - mmengine - INFO - Epoch(train) [11][6800/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:12:47  time: 1.0410  data_time: 0.0038  memory: 9351  loss: 0.7423  loss_rpn_cls: 0.0296  loss_rpn_bbox: 0.0428  loss_cls: 0.1911  acc: 94.9707  loss_bbox: 0.2411  loss_mask: 0.2377
2025/12/15 01:46:50 - mmengine - INFO - Epoch(train) [11][6850/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:11:58  time: 1.0642  data_time: 0.0036  memory: 9255  loss: 0.7141  loss_rpn_cls: 0.0273  loss_rpn_bbox: 0.0358  loss_cls: 0.1836  acc: 94.4824  loss_bbox: 0.2283  loss_mask: 0.2390
2025/12/15 01:47:42 - mmengine - INFO - Epoch(train) [11][6900/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:11:07  time: 1.0368  data_time: 0.0036  memory: 9604  loss: 0.7612  loss_rpn_cls: 0.0297  loss_rpn_bbox: 0.0466  loss_cls: 0.1909  acc: 91.6992  loss_bbox: 0.2478  loss_mask: 0.2461
2025/12/15 01:48:33 - mmengine - INFO - Epoch(train) [11][6950/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:10:17  time: 1.0154  data_time: 0.0038  memory: 9402  loss: 0.6833  loss_rpn_cls: 0.0281  loss_rpn_bbox: 0.0368  loss_cls: 0.1692  acc: 95.2637  loss_bbox: 0.2200  loss_mask: 0.2293
2025/12/15 01:49:25 - mmengine - INFO - Epoch(train) [11][7000/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:09:27  time: 1.0401  data_time: 0.0039  memory: 9418  loss: 0.7183  loss_rpn_cls: 0.0259  loss_rpn_bbox: 0.0377  loss_cls: 0.1808  acc: 95.7520  loss_bbox: 0.2348  loss_mask: 0.2390
2025/12/15 01:50:17 - mmengine - INFO - Epoch(train) [11][7050/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:08:37  time: 1.0493  data_time: 0.0037  memory: 9553  loss: 0.7199  loss_rpn_cls: 0.0310  loss_rpn_bbox: 0.0400  loss_cls: 0.1870  acc: 89.8438  loss_bbox: 0.2339  loss_mask: 0.2280
2025/12/15 01:51:08 - mmengine - INFO - Epoch(train) [11][7100/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:07:46  time: 1.0140  data_time: 0.0038  memory: 9626  loss: 0.7218  loss_rpn_cls: 0.0313  loss_rpn_bbox: 0.0391  loss_cls: 0.1846  acc: 93.7012  loss_bbox: 0.2262  loss_mask: 0.2406
2025/12/15 01:51:59 - mmengine - INFO - Epoch(train) [11][7150/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:06:56  time: 1.0266  data_time: 0.0038  memory: 9385  loss: 0.7627  loss_rpn_cls: 0.0315  loss_rpn_bbox: 0.0464  loss_cls: 0.1889  acc: 93.5547  loss_bbox: 0.2491  loss_mask: 0.2469
2025/12/15 01:52:51 - mmengine - INFO - Epoch(train) [11][7200/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:06:06  time: 1.0392  data_time: 0.0040  memory: 9232  loss: 0.7239  loss_rpn_cls: 0.0272  loss_rpn_bbox: 0.0384  loss_cls: 0.1831  acc: 94.6777  loss_bbox: 0.2317  loss_mask: 0.2434
2025/12/15 01:53:43 - mmengine - INFO - Epoch(train) [11][7250/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:05:16  time: 1.0331  data_time: 0.0041  memory: 9348  loss: 0.6986  loss_rpn_cls: 0.0243  loss_rpn_bbox: 0.0359  loss_cls: 0.1814  acc: 90.8691  loss_bbox: 0.2296  loss_mask: 0.2274
2025/12/15 01:54:34 - mmengine - INFO - Epoch(train) [11][7300/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 2:04:25  time: 1.0246  data_time: 0.0039  memory: 9398  loss: 0.7120  loss_rpn_cls: 0.0292  loss_rpn_bbox: 0.0392  loss_cls: 0.1719  acc: 93.5059  loss_bbox: 0.2309  loss_mask: 0.2409
2025/12/15 01:55:05 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/15 01:55:05 - mmengine - INFO - Saving checkpoint at 11 epochs
2025/12/15 01:56:02 - mmengine - INFO - Epoch(val) [11][ 50/313]    eta: 0:04:39  time: 1.0620  data_time: 0.0091  memory: 9318  
2025/12/15 01:56:54 - mmengine - INFO - Epoch(val) [11][100/313]    eta: 0:03:42  time: 1.0289  data_time: 0.0009  memory: 2466  
2025/12/15 01:57:46 - mmengine - INFO - Epoch(val) [11][150/313]    eta: 0:02:50  time: 1.0413  data_time: 0.0009  memory: 2551  
2025/12/15 01:58:37 - mmengine - INFO - Epoch(val) [11][200/313]    eta: 0:01:57  time: 1.0280  data_time: 0.0009  memory: 2637  
2025/12/15 01:59:29 - mmengine - INFO - Epoch(val) [11][250/313]    eta: 0:01:05  time: 1.0323  data_time: 0.0010  memory: 2637  
2025/12/15 02:00:20 - mmengine - INFO - Epoch(val) [11][300/313]    eta: 0:00:13  time: 1.0332  data_time: 0.0010  memory: 2552  
2025/12/15 02:00:44 - mmengine - INFO - Evaluating bbox...
2025/12/15 02:01:21 - mmengine - INFO - bbox_mAP_copypaste: 0.449 0.666 0.493 0.293 0.483 0.580
2025/12/15 02:01:21 - mmengine - INFO - Evaluating segm...
2025/12/15 02:02:02 - mmengine - INFO - segm_mAP_copypaste: 0.400 0.630 0.429 0.212 0.431 0.579
2025/12/15 02:02:03 - mmengine - INFO - Epoch(val) [11][313/313]    coco/bbox_mAP: 0.4490  coco/bbox_mAP_50: 0.6660  coco/bbox_mAP_75: 0.4930  coco/bbox_mAP_s: 0.2930  coco/bbox_mAP_m: 0.4830  coco/bbox_mAP_l: 0.5800  coco/segm_mAP: 0.4000  coco/segm_mAP_50: 0.6300  coco/segm_mAP_75: 0.4290  coco/segm_mAP_s: 0.2120  coco/segm_mAP_m: 0.4310  coco/segm_mAP_l: 0.5790  data_time: 0.0022  time: 1.0337
2025/12/15 02:02:58 - mmengine - INFO - Epoch(train) [12][  50/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:03:06  time: 1.1016  data_time: 0.0081  memory: 9371  loss: 0.7877  loss_rpn_cls: 0.0330  loss_rpn_bbox: 0.0459  loss_cls: 0.1989  acc: 87.5000  loss_bbox: 0.2511  loss_mask: 0.2587
2025/12/15 02:03:53 - mmengine - INFO - Epoch(train) [12][ 100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:02:18  time: 1.0925  data_time: 0.0041  memory: 9559  loss: 0.7168  loss_rpn_cls: 0.0352  loss_rpn_bbox: 0.0415  loss_cls: 0.1851  acc: 92.7734  loss_bbox: 0.2299  loss_mask: 0.2251
2025/12/15 02:04:46 - mmengine - INFO - Epoch(train) [12][ 150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:01:28  time: 1.0658  data_time: 0.0040  memory: 9533  loss: 0.7580  loss_rpn_cls: 0.0325  loss_rpn_bbox: 0.0438  loss_cls: 0.1855  acc: 97.0703  loss_bbox: 0.2453  loss_mask: 0.2509
2025/12/15 02:05:39 - mmengine - INFO - Epoch(train) [12][ 200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 2:00:38  time: 1.0623  data_time: 0.0041  memory: 9916  loss: 0.6611  loss_rpn_cls: 0.0271  loss_rpn_bbox: 0.0338  loss_cls: 0.1689  acc: 92.0898  loss_bbox: 0.2139  loss_mask: 0.2175
2025/12/15 02:06:33 - mmengine - INFO - Epoch(train) [12][ 250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:59:49  time: 1.0788  data_time: 0.0036  memory: 9529  loss: 0.7505  loss_rpn_cls: 0.0295  loss_rpn_bbox: 0.0419  loss_cls: 0.1933  acc: 96.7773  loss_bbox: 0.2415  loss_mask: 0.2443
2025/12/15 02:07:26 - mmengine - INFO - Epoch(train) [12][ 300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:58:59  time: 1.0612  data_time: 0.0035  memory: 9416  loss: 0.6825  loss_rpn_cls: 0.0265  loss_rpn_bbox: 0.0407  loss_cls: 0.1638  acc: 88.4277  loss_bbox: 0.2168  loss_mask: 0.2348
2025/12/15 02:08:19 - mmengine - INFO - Epoch(train) [12][ 350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:58:10  time: 1.0636  data_time: 0.0034  memory: 9647  loss: 0.7710  loss_rpn_cls: 0.0367  loss_rpn_bbox: 0.0442  loss_cls: 0.2020  acc: 91.8945  loss_bbox: 0.2519  loss_mask: 0.2362
2025/12/15 02:08:40 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/15 02:09:12 - mmengine - INFO - Epoch(train) [12][ 400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:57:20  time: 1.0505  data_time: 0.0037  memory: 9491  loss: 0.6819  loss_rpn_cls: 0.0276  loss_rpn_bbox: 0.0358  loss_cls: 0.1709  acc: 95.3613  loss_bbox: 0.2146  loss_mask: 0.2331
2025/12/15 02:10:03 - mmengine - INFO - Epoch(train) [12][ 450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:56:29  time: 1.0293  data_time: 0.0039  memory: 9347  loss: 0.7502  loss_rpn_cls: 0.0336  loss_rpn_bbox: 0.0432  loss_cls: 0.1964  acc: 93.3105  loss_bbox: 0.2430  loss_mask: 0.2340
2025/12/15 02:10:56 - mmengine - INFO - Epoch(train) [12][ 500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:55:39  time: 1.0566  data_time: 0.0038  memory: 9394  loss: 0.6430  loss_rpn_cls: 0.0238  loss_rpn_bbox: 0.0345  loss_cls: 0.1517  acc: 94.9219  loss_bbox: 0.2061  loss_mask: 0.2270
2025/12/15 02:11:50 - mmengine - INFO - Epoch(train) [12][ 550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:54:50  time: 1.0781  data_time: 0.0038  memory: 9728  loss: 0.7115  loss_rpn_cls: 0.0262  loss_rpn_bbox: 0.0429  loss_cls: 0.1789  acc: 93.9453  loss_bbox: 0.2326  loss_mask: 0.2309
2025/12/15 02:12:44 - mmengine - INFO - Epoch(train) [12][ 600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:54:00  time: 1.0696  data_time: 0.0039  memory: 9218  loss: 0.7053  loss_rpn_cls: 0.0259  loss_rpn_bbox: 0.0398  loss_cls: 0.1760  acc: 96.0938  loss_bbox: 0.2295  loss_mask: 0.2341
2025/12/15 02:13:36 - mmengine - INFO - Epoch(train) [12][ 650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:53:10  time: 1.0474  data_time: 0.0036  memory: 9377  loss: 0.7322  loss_rpn_cls: 0.0276  loss_rpn_bbox: 0.0423  loss_cls: 0.1893  acc: 92.4316  loss_bbox: 0.2340  loss_mask: 0.2390
2025/12/15 02:14:27 - mmengine - INFO - Epoch(train) [12][ 700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:52:19  time: 1.0166  data_time: 0.0036  memory: 9545  loss: 0.6957  loss_rpn_cls: 0.0265  loss_rpn_bbox: 0.0381  loss_cls: 0.1747  acc: 94.4824  loss_bbox: 0.2212  loss_mask: 0.2353
2025/12/15 02:15:19 - mmengine - INFO - Epoch(train) [12][ 750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:51:29  time: 1.0479  data_time: 0.0036  memory: 9477  loss: 0.6967  loss_rpn_cls: 0.0270  loss_rpn_bbox: 0.0410  loss_cls: 0.1740  acc: 93.9453  loss_bbox: 0.2200  loss_mask: 0.2347
2025/12/15 02:16:10 - mmengine - INFO - Epoch(train) [12][ 800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:50:38  time: 1.0114  data_time: 0.0036  memory: 9322  loss: 0.6680  loss_rpn_cls: 0.0271  loss_rpn_bbox: 0.0366  loss_cls: 0.1712  acc: 92.7246  loss_bbox: 0.2085  loss_mask: 0.2246
2025/12/15 02:17:02 - mmengine - INFO - Epoch(train) [12][ 850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:49:48  time: 1.0477  data_time: 0.0035  memory: 9463  loss: 0.7423  loss_rpn_cls: 0.0306  loss_rpn_bbox: 0.0413  loss_cls: 0.1866  acc: 87.4512  loss_bbox: 0.2455  loss_mask: 0.2384
2025/12/15 02:17:54 - mmengine - INFO - Epoch(train) [12][ 900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:48:58  time: 1.0388  data_time: 0.0035  memory: 9867  loss: 0.7740  loss_rpn_cls: 0.0359  loss_rpn_bbox: 0.0435  loss_cls: 0.2058  acc: 89.1113  loss_bbox: 0.2557  loss_mask: 0.2330
2025/12/15 02:18:47 - mmengine - INFO - Epoch(train) [12][ 950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:48:08  time: 1.0544  data_time: 0.0034  memory: 9270  loss: 0.7308  loss_rpn_cls: 0.0309  loss_rpn_bbox: 0.0400  loss_cls: 0.1883  acc: 95.7031  loss_bbox: 0.2328  loss_mask: 0.2388
2025/12/15 02:19:40 - mmengine - INFO - Epoch(train) [12][1000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:47:18  time: 1.0547  data_time: 0.0038  memory: 9347  loss: 0.7593  loss_rpn_cls: 0.0371  loss_rpn_bbox: 0.0414  loss_cls: 0.1888  acc: 93.0176  loss_bbox: 0.2497  loss_mask: 0.2424
2025/12/15 02:20:31 - mmengine - INFO - Epoch(train) [12][1050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:46:27  time: 1.0295  data_time: 0.0039  memory: 9497  loss: 0.7240  loss_rpn_cls: 0.0324  loss_rpn_bbox: 0.0429  loss_cls: 0.1769  acc: 92.3340  loss_bbox: 0.2357  loss_mask: 0.2362
2025/12/15 02:21:25 - mmengine - INFO - Epoch(train) [12][1100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:45:37  time: 1.0704  data_time: 0.0039  memory: 9428  loss: 0.7248  loss_rpn_cls: 0.0318  loss_rpn_bbox: 0.0436  loss_cls: 0.1848  acc: 90.7227  loss_bbox: 0.2274  loss_mask: 0.2371
2025/12/15 02:22:19 - mmengine - INFO - Epoch(train) [12][1150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:44:47  time: 1.0786  data_time: 0.0036  memory: 9366  loss: 0.6821  loss_rpn_cls: 0.0287  loss_rpn_bbox: 0.0397  loss_cls: 0.1743  acc: 96.6797  loss_bbox: 0.2193  loss_mask: 0.2201
2025/12/15 02:23:13 - mmengine - INFO - Epoch(train) [12][1200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:43:58  time: 1.0818  data_time: 0.0038  memory: 9726  loss: 0.7095  loss_rpn_cls: 0.0303  loss_rpn_bbox: 0.0379  loss_cls: 0.1825  acc: 93.3594  loss_bbox: 0.2232  loss_mask: 0.2356
2025/12/15 02:24:06 - mmengine - INFO - Epoch(train) [12][1250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:43:08  time: 1.0539  data_time: 0.0036  memory: 9561  loss: 0.7398  loss_rpn_cls: 0.0330  loss_rpn_bbox: 0.0450  loss_cls: 0.1920  acc: 94.0918  loss_bbox: 0.2330  loss_mask: 0.2368
2025/12/15 02:24:58 - mmengine - INFO - Epoch(train) [12][1300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:42:17  time: 1.0412  data_time: 0.0036  memory: 9289  loss: 0.6588  loss_rpn_cls: 0.0264  loss_rpn_bbox: 0.0365  loss_cls: 0.1627  acc: 92.3828  loss_bbox: 0.2077  loss_mask: 0.2256
2025/12/15 02:25:49 - mmengine - INFO - Epoch(train) [12][1350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:41:27  time: 1.0369  data_time: 0.0035  memory: 9285  loss: 0.6591  loss_rpn_cls: 0.0262  loss_rpn_bbox: 0.0351  loss_cls: 0.1623  acc: 93.9453  loss_bbox: 0.2045  loss_mask: 0.2309
2025/12/15 02:26:10 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/15 02:26:42 - mmengine - INFO - Epoch(train) [12][1400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:40:36  time: 1.0531  data_time: 0.0036  memory: 9373  loss: 0.6424  loss_rpn_cls: 0.0260  loss_rpn_bbox: 0.0352  loss_cls: 0.1505  acc: 94.7754  loss_bbox: 0.2024  loss_mask: 0.2284
2025/12/15 02:27:35 - mmengine - INFO - Epoch(train) [12][1450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:39:46  time: 1.0618  data_time: 0.0037  memory: 9452  loss: 0.6830  loss_rpn_cls: 0.0271  loss_rpn_bbox: 0.0358  loss_cls: 0.1702  acc: 94.9219  loss_bbox: 0.2172  loss_mask: 0.2326
2025/12/15 02:28:29 - mmengine - INFO - Epoch(train) [12][1500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:38:56  time: 1.0654  data_time: 0.0036  memory: 9758  loss: 0.7559  loss_rpn_cls: 0.0323  loss_rpn_bbox: 0.0404  loss_cls: 0.1918  acc: 93.5059  loss_bbox: 0.2402  loss_mask: 0.2512
2025/12/15 02:29:22 - mmengine - INFO - Epoch(train) [12][1550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:38:06  time: 1.0641  data_time: 0.0035  memory: 9765  loss: 0.7167  loss_rpn_cls: 0.0260  loss_rpn_bbox: 0.0373  loss_cls: 0.1848  acc: 96.8750  loss_bbox: 0.2344  loss_mask: 0.2341
2025/12/15 02:30:14 - mmengine - INFO - Epoch(train) [12][1600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:37:16  time: 1.0369  data_time: 0.0034  memory: 9642  loss: 0.6942  loss_rpn_cls: 0.0297  loss_rpn_bbox: 0.0392  loss_cls: 0.1771  acc: 94.0918  loss_bbox: 0.2193  loss_mask: 0.2289
2025/12/15 02:31:06 - mmengine - INFO - Epoch(train) [12][1650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:36:25  time: 1.0485  data_time: 0.0035  memory: 9615  loss: 0.7955  loss_rpn_cls: 0.0330  loss_rpn_bbox: 0.0423  loss_cls: 0.2077  acc: 93.7500  loss_bbox: 0.2664  loss_mask: 0.2461
2025/12/15 02:31:58 - mmengine - INFO - Epoch(train) [12][1700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:35:35  time: 1.0397  data_time: 0.0036  memory: 9368  loss: 0.6565  loss_rpn_cls: 0.0248  loss_rpn_bbox: 0.0362  loss_cls: 0.1617  acc: 94.0918  loss_bbox: 0.2070  loss_mask: 0.2267
2025/12/15 02:32:49 - mmengine - INFO - Epoch(train) [12][1750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:34:44  time: 1.0216  data_time: 0.0038  memory: 9301  loss: 0.6766  loss_rpn_cls: 0.0265  loss_rpn_bbox: 0.0380  loss_cls: 0.1721  acc: 91.4062  loss_bbox: 0.2141  loss_mask: 0.2259
2025/12/15 02:33:42 - mmengine - INFO - Epoch(train) [12][1800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:33:53  time: 1.0560  data_time: 0.0038  memory: 9361  loss: 0.7067  loss_rpn_cls: 0.0345  loss_rpn_bbox: 0.0403  loss_cls: 0.1800  acc: 94.9707  loss_bbox: 0.2220  loss_mask: 0.2298
2025/12/15 02:34:34 - mmengine - INFO - Epoch(train) [12][1850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:33:03  time: 1.0482  data_time: 0.0035  memory: 9235  loss: 0.6806  loss_rpn_cls: 0.0261  loss_rpn_bbox: 0.0381  loss_cls: 0.1664  acc: 94.6777  loss_bbox: 0.2116  loss_mask: 0.2385
2025/12/15 02:35:27 - mmengine - INFO - Epoch(train) [12][1900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:32:12  time: 1.0446  data_time: 0.0036  memory: 9437  loss: 0.7106  loss_rpn_cls: 0.0272  loss_rpn_bbox: 0.0402  loss_cls: 0.1791  acc: 92.4805  loss_bbox: 0.2262  loss_mask: 0.2380
2025/12/15 02:36:19 - mmengine - INFO - Epoch(train) [12][1950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:31:22  time: 1.0497  data_time: 0.0034  memory: 9361  loss: 0.7292  loss_rpn_cls: 0.0301  loss_rpn_bbox: 0.0423  loss_cls: 0.1810  acc: 89.5996  loss_bbox: 0.2368  loss_mask: 0.2391
2025/12/15 02:37:11 - mmengine - INFO - Epoch(train) [12][2000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:30:31  time: 1.0309  data_time: 0.0034  memory: 9352  loss: 0.6777  loss_rpn_cls: 0.0250  loss_rpn_bbox: 0.0367  loss_cls: 0.1693  acc: 96.0449  loss_bbox: 0.2210  loss_mask: 0.2257
2025/12/15 02:38:04 - mmengine - INFO - Epoch(train) [12][2050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:29:41  time: 1.0620  data_time: 0.0035  memory: 9657  loss: 0.7154  loss_rpn_cls: 0.0314  loss_rpn_bbox: 0.0393  loss_cls: 0.1737  acc: 95.4590  loss_bbox: 0.2266  loss_mask: 0.2443
2025/12/15 02:38:57 - mmengine - INFO - Epoch(train) [12][2100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:28:51  time: 1.0672  data_time: 0.0034  memory: 9558  loss: 0.6992  loss_rpn_cls: 0.0267  loss_rpn_bbox: 0.0358  loss_cls: 0.1740  acc: 91.4062  loss_bbox: 0.2228  loss_mask: 0.2400
2025/12/15 02:39:51 - mmengine - INFO - Epoch(train) [12][2150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:28:00  time: 1.0658  data_time: 0.0035  memory: 9422  loss: 0.7448  loss_rpn_cls: 0.0302  loss_rpn_bbox: 0.0399  loss_cls: 0.1842  acc: 88.9648  loss_bbox: 0.2490  loss_mask: 0.2415
2025/12/15 02:40:42 - mmengine - INFO - Epoch(train) [12][2200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:27:10  time: 1.0356  data_time: 0.0036  memory: 9292  loss: 0.6883  loss_rpn_cls: 0.0277  loss_rpn_bbox: 0.0317  loss_cls: 0.1781  acc: 96.3379  loss_bbox: 0.2194  loss_mask: 0.2314
2025/12/15 02:41:35 - mmengine - INFO - Epoch(train) [12][2250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:26:19  time: 1.0584  data_time: 0.0037  memory: 9265  loss: 0.6975  loss_rpn_cls: 0.0279  loss_rpn_bbox: 0.0375  loss_cls: 0.1762  acc: 95.3125  loss_bbox: 0.2272  loss_mask: 0.2287
2025/12/15 02:42:27 - mmengine - INFO - Epoch(train) [12][2300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:25:29  time: 1.0423  data_time: 0.0035  memory: 9443  loss: 0.6637  loss_rpn_cls: 0.0256  loss_rpn_bbox: 0.0322  loss_cls: 0.1631  acc: 94.4336  loss_bbox: 0.2108  loss_mask: 0.2320
2025/12/15 02:43:20 - mmengine - INFO - Epoch(train) [12][2350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:24:38  time: 1.0432  data_time: 0.0036  memory: 9570  loss: 0.7133  loss_rpn_cls: 0.0286  loss_rpn_bbox: 0.0371  loss_cls: 0.1695  acc: 90.7715  loss_bbox: 0.2401  loss_mask: 0.2381
2025/12/15 02:43:40 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/15 02:44:11 - mmengine - INFO - Epoch(train) [12][2400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:23:47  time: 1.0271  data_time: 0.0036  memory: 9405  loss: 0.6825  loss_rpn_cls: 0.0285  loss_rpn_bbox: 0.0391  loss_cls: 0.1710  acc: 94.0918  loss_bbox: 0.2234  loss_mask: 0.2205
2025/12/15 02:45:03 - mmengine - INFO - Epoch(train) [12][2450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:22:56  time: 1.0358  data_time: 0.0036  memory: 9480  loss: 0.7023  loss_rpn_cls: 0.0284  loss_rpn_bbox: 0.0393  loss_cls: 0.1820  acc: 93.3594  loss_bbox: 0.2266  loss_mask: 0.2260
2025/12/15 02:45:55 - mmengine - INFO - Epoch(train) [12][2500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:22:06  time: 1.0417  data_time: 0.0034  memory: 9459  loss: 0.7305  loss_rpn_cls: 0.0277  loss_rpn_bbox: 0.0375  loss_cls: 0.1896  acc: 97.3145  loss_bbox: 0.2340  loss_mask: 0.2417
2025/12/15 02:46:47 - mmengine - INFO - Epoch(train) [12][2550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:21:15  time: 1.0512  data_time: 0.0036  memory: 9402  loss: 0.6949  loss_rpn_cls: 0.0306  loss_rpn_bbox: 0.0409  loss_cls: 0.1710  acc: 92.3828  loss_bbox: 0.2250  loss_mask: 0.2275
2025/12/15 02:47:41 - mmengine - INFO - Epoch(train) [12][2600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:20:25  time: 1.0676  data_time: 0.0038  memory: 9435  loss: 0.7382  loss_rpn_cls: 0.0317  loss_rpn_bbox: 0.0373  loss_cls: 0.1892  acc: 94.3848  loss_bbox: 0.2425  loss_mask: 0.2375
2025/12/15 02:48:33 - mmengine - INFO - Epoch(train) [12][2650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:19:34  time: 1.0414  data_time: 0.0037  memory: 9212  loss: 0.7239  loss_rpn_cls: 0.0270  loss_rpn_bbox: 0.0383  loss_cls: 0.1850  acc: 91.3086  loss_bbox: 0.2330  loss_mask: 0.2406
2025/12/15 02:49:26 - mmengine - INFO - Epoch(train) [12][2700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:18:44  time: 1.0558  data_time: 0.0037  memory: 9854  loss: 0.7223  loss_rpn_cls: 0.0291  loss_rpn_bbox: 0.0381  loss_cls: 0.1888  acc: 98.3887  loss_bbox: 0.2304  loss_mask: 0.2359
2025/12/15 02:50:19 - mmengine - INFO - Epoch(train) [12][2750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:17:53  time: 1.0571  data_time: 0.0036  memory: 9790  loss: 0.7338  loss_rpn_cls: 0.0328  loss_rpn_bbox: 0.0448  loss_cls: 0.1872  acc: 95.6055  loss_bbox: 0.2389  loss_mask: 0.2300
2025/12/15 02:51:10 - mmengine - INFO - Epoch(train) [12][2800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:17:02  time: 1.0295  data_time: 0.0036  memory: 9399  loss: 0.6735  loss_rpn_cls: 0.0291  loss_rpn_bbox: 0.0357  loss_cls: 0.1742  acc: 91.0156  loss_bbox: 0.2100  loss_mask: 0.2244
2025/12/15 02:52:02 - mmengine - INFO - Epoch(train) [12][2850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:16:11  time: 1.0352  data_time: 0.0035  memory: 9471  loss: 0.6952  loss_rpn_cls: 0.0253  loss_rpn_bbox: 0.0346  loss_cls: 0.1748  acc: 94.2383  loss_bbox: 0.2224  loss_mask: 0.2380
2025/12/15 02:52:54 - mmengine - INFO - Epoch(train) [12][2900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:15:21  time: 1.0425  data_time: 0.0035  memory: 9385  loss: 0.7066  loss_rpn_cls: 0.0249  loss_rpn_bbox: 0.0380  loss_cls: 0.1803  acc: 94.4336  loss_bbox: 0.2236  loss_mask: 0.2399
2025/12/15 02:53:46 - mmengine - INFO - Epoch(train) [12][2950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:14:30  time: 1.0351  data_time: 0.0036  memory: 9199  loss: 0.6640  loss_rpn_cls: 0.0298  loss_rpn_bbox: 0.0341  loss_cls: 0.1619  acc: 90.6738  loss_bbox: 0.2041  loss_mask: 0.2340
2025/12/15 02:54:39 - mmengine - INFO - Epoch(train) [12][3000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:13:39  time: 1.0651  data_time: 0.0038  memory: 9813  loss: 0.7111  loss_rpn_cls: 0.0267  loss_rpn_bbox: 0.0412  loss_cls: 0.1797  acc: 95.9961  loss_bbox: 0.2219  loss_mask: 0.2416
2025/12/15 02:55:32 - mmengine - INFO - Epoch(train) [12][3050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:12:49  time: 1.0627  data_time: 0.0042  memory: 9430  loss: 0.7531  loss_rpn_cls: 0.0317  loss_rpn_bbox: 0.0407  loss_cls: 0.1846  acc: 90.7227  loss_bbox: 0.2449  loss_mask: 0.2511
2025/12/15 02:56:24 - mmengine - INFO - Epoch(train) [12][3100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:11:58  time: 1.0323  data_time: 0.0040  memory: 9282  loss: 0.7347  loss_rpn_cls: 0.0326  loss_rpn_bbox: 0.0429  loss_cls: 0.1792  acc: 92.4316  loss_bbox: 0.2333  loss_mask: 0.2467
2025/12/15 02:57:17 - mmengine - INFO - Epoch(train) [12][3150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:11:07  time: 1.0642  data_time: 0.0039  memory: 9579  loss: 0.6818  loss_rpn_cls: 0.0288  loss_rpn_bbox: 0.0394  loss_cls: 0.1647  acc: 96.5332  loss_bbox: 0.2231  loss_mask: 0.2258
2025/12/15 02:58:11 - mmengine - INFO - Epoch(train) [12][3200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:10:17  time: 1.0732  data_time: 0.0061  memory: 9855  loss: 0.7024  loss_rpn_cls: 0.0346  loss_rpn_bbox: 0.0437  loss_cls: 0.1699  acc: 95.6055  loss_bbox: 0.2212  loss_mask: 0.2330
2025/12/15 02:59:03 - mmengine - INFO - Epoch(train) [12][3250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:09:26  time: 1.0556  data_time: 0.0038  memory: 9698  loss: 0.7182  loss_rpn_cls: 0.0282  loss_rpn_bbox: 0.0429  loss_cls: 0.1822  acc: 95.8496  loss_bbox: 0.2305  loss_mask: 0.2344
2025/12/15 02:59:56 - mmengine - INFO - Epoch(train) [12][3300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:08:35  time: 1.0521  data_time: 0.0037  memory: 9406  loss: 0.7443  loss_rpn_cls: 0.0302  loss_rpn_bbox: 0.0422  loss_cls: 0.1856  acc: 89.8438  loss_bbox: 0.2462  loss_mask: 0.2402
2025/12/15 03:00:48 - mmengine - INFO - Epoch(train) [12][3350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:07:45  time: 1.0421  data_time: 0.0038  memory: 9516  loss: 0.7260  loss_rpn_cls: 0.0333  loss_rpn_bbox: 0.0427  loss_cls: 0.1788  acc: 93.9941  loss_bbox: 0.2315  loss_mask: 0.2398
2025/12/15 03:01:10 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/15 03:01:42 - mmengine - INFO - Epoch(train) [12][3400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:06:54  time: 1.0800  data_time: 0.0037  memory: 9486  loss: 0.7332  loss_rpn_cls: 0.0289  loss_rpn_bbox: 0.0436  loss_cls: 0.1855  acc: 98.1445  loss_bbox: 0.2441  loss_mask: 0.2311
2025/12/15 03:02:35 - mmengine - INFO - Epoch(train) [12][3450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:06:03  time: 1.0594  data_time: 0.0036  memory: 9432  loss: 0.8151  loss_rpn_cls: 0.0336  loss_rpn_bbox: 0.0474  loss_cls: 0.2107  acc: 95.8984  loss_bbox: 0.2703  loss_mask: 0.2530
2025/12/15 03:03:28 - mmengine - INFO - Epoch(train) [12][3500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:05:13  time: 1.0560  data_time: 0.0038  memory: 9555  loss: 0.7252  loss_rpn_cls: 0.0302  loss_rpn_bbox: 0.0410  loss_cls: 0.1866  acc: 94.0918  loss_bbox: 0.2364  loss_mask: 0.2310
2025/12/15 03:04:22 - mmengine - INFO - Epoch(train) [12][3550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:04:22  time: 1.0738  data_time: 0.0039  memory: 9604  loss: 0.7303  loss_rpn_cls: 0.0254  loss_rpn_bbox: 0.0371  loss_cls: 0.1810  acc: 93.1152  loss_bbox: 0.2405  loss_mask: 0.2463
2025/12/15 03:05:13 - mmengine - INFO - Epoch(train) [12][3600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:03:31  time: 1.0333  data_time: 0.0038  memory: 9297  loss: 0.7182  loss_rpn_cls: 0.0276  loss_rpn_bbox: 0.0409  loss_cls: 0.1786  acc: 93.3105  loss_bbox: 0.2344  loss_mask: 0.2367
2025/12/15 03:06:04 - mmengine - INFO - Epoch(train) [12][3650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:02:40  time: 1.0140  data_time: 0.0036  memory: 9569  loss: 0.7635  loss_rpn_cls: 0.0326  loss_rpn_bbox: 0.0427  loss_cls: 0.2004  acc: 98.7793  loss_bbox: 0.2480  loss_mask: 0.2398
2025/12/15 03:06:56 - mmengine - INFO - Epoch(train) [12][3700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:01:49  time: 1.0293  data_time: 0.0037  memory: 9174  loss: 0.7091  loss_rpn_cls: 0.0288  loss_rpn_bbox: 0.0374  loss_cls: 0.1811  acc: 93.7012  loss_bbox: 0.2325  loss_mask: 0.2293
2025/12/15 03:07:47 - mmengine - INFO - Epoch(train) [12][3750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:00:58  time: 1.0354  data_time: 0.0035  memory: 9276  loss: 0.6662  loss_rpn_cls: 0.0252  loss_rpn_bbox: 0.0409  loss_cls: 0.1636  acc: 94.8242  loss_bbox: 0.2137  loss_mask: 0.2228
2025/12/15 03:08:40 - mmengine - INFO - Epoch(train) [12][3800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 1:00:07  time: 1.0483  data_time: 0.0035  memory: 10195  loss: 0.6930  loss_rpn_cls: 0.0295  loss_rpn_bbox: 0.0396  loss_cls: 0.1677  acc: 94.3359  loss_bbox: 0.2267  loss_mask: 0.2294
2025/12/15 03:09:32 - mmengine - INFO - Epoch(train) [12][3850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:59:16  time: 1.0449  data_time: 0.0034  memory: 9347  loss: 0.6618  loss_rpn_cls: 0.0230  loss_rpn_bbox: 0.0351  loss_cls: 0.1650  acc: 97.7539  loss_bbox: 0.2042  loss_mask: 0.2345
2025/12/15 03:10:24 - mmengine - INFO - Epoch(train) [12][3900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:58:25  time: 1.0282  data_time: 0.0035  memory: 9792  loss: 0.7161  loss_rpn_cls: 0.0286  loss_rpn_bbox: 0.0380  loss_cls: 0.1836  acc: 95.1660  loss_bbox: 0.2310  loss_mask: 0.2349
2025/12/15 03:11:16 - mmengine - INFO - Epoch(train) [12][3950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:57:34  time: 1.0432  data_time: 0.0035  memory: 9561  loss: 0.7038  loss_rpn_cls: 0.0289  loss_rpn_bbox: 0.0399  loss_cls: 0.1739  acc: 92.1875  loss_bbox: 0.2372  loss_mask: 0.2238
2025/12/15 03:12:08 - mmengine - INFO - Epoch(train) [12][4000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:56:43  time: 1.0417  data_time: 0.0034  memory: 9758  loss: 0.6973  loss_rpn_cls: 0.0274  loss_rpn_bbox: 0.0426  loss_cls: 0.1718  acc: 95.8008  loss_bbox: 0.2216  loss_mask: 0.2339
2025/12/15 03:13:00 - mmengine - INFO - Epoch(train) [12][4050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:55:53  time: 1.0471  data_time: 0.0035  memory: 9631  loss: 0.6670  loss_rpn_cls: 0.0290  loss_rpn_bbox: 0.0331  loss_cls: 0.1608  acc: 92.7246  loss_bbox: 0.2111  loss_mask: 0.2331
2025/12/15 03:13:52 - mmengine - INFO - Epoch(train) [12][4100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:55:02  time: 1.0357  data_time: 0.0035  memory: 9615  loss: 0.7266  loss_rpn_cls: 0.0302  loss_rpn_bbox: 0.0413  loss_cls: 0.1797  acc: 91.0156  loss_bbox: 0.2396  loss_mask: 0.2359
2025/12/15 03:14:43 - mmengine - INFO - Epoch(train) [12][4150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:54:10  time: 1.0271  data_time: 0.0035  memory: 9365  loss: 0.6609  loss_rpn_cls: 0.0249  loss_rpn_bbox: 0.0359  loss_cls: 0.1678  acc: 90.8203  loss_bbox: 0.2035  loss_mask: 0.2288
2025/12/15 03:15:35 - mmengine - INFO - Epoch(train) [12][4200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:53:19  time: 1.0326  data_time: 0.0034  memory: 9240  loss: 0.7035  loss_rpn_cls: 0.0284  loss_rpn_bbox: 0.0417  loss_cls: 0.1705  acc: 93.4082  loss_bbox: 0.2243  loss_mask: 0.2385
2025/12/15 03:16:27 - mmengine - INFO - Epoch(train) [12][4250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:52:28  time: 1.0376  data_time: 0.0035  memory: 9503  loss: 0.7282  loss_rpn_cls: 0.0319  loss_rpn_bbox: 0.0413  loss_cls: 0.1838  acc: 92.0410  loss_bbox: 0.2390  loss_mask: 0.2322
2025/12/15 03:17:18 - mmengine - INFO - Epoch(train) [12][4300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:51:37  time: 1.0237  data_time: 0.0034  memory: 9684  loss: 0.7034  loss_rpn_cls: 0.0301  loss_rpn_bbox: 0.0433  loss_cls: 0.1771  acc: 95.0195  loss_bbox: 0.2284  loss_mask: 0.2245
2025/12/15 03:18:11 - mmengine - INFO - Epoch(train) [12][4350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:50:46  time: 1.0537  data_time: 0.0035  memory: 9454  loss: 0.7711  loss_rpn_cls: 0.0393  loss_rpn_bbox: 0.0478  loss_cls: 0.1932  acc: 92.9688  loss_bbox: 0.2467  loss_mask: 0.2441
2025/12/15 03:18:31 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/15 03:19:02 - mmengine - INFO - Epoch(train) [12][4400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:49:55  time: 1.0316  data_time: 0.0035  memory: 9330  loss: 0.6691  loss_rpn_cls: 0.0249  loss_rpn_bbox: 0.0382  loss_cls: 0.1671  acc: 92.3340  loss_bbox: 0.2093  loss_mask: 0.2296
2025/12/15 03:19:53 - mmengine - INFO - Epoch(train) [12][4450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:49:04  time: 1.0216  data_time: 0.0035  memory: 9287  loss: 0.7134  loss_rpn_cls: 0.0266  loss_rpn_bbox: 0.0384  loss_cls: 0.1869  acc: 96.4355  loss_bbox: 0.2365  loss_mask: 0.2251
2025/12/15 03:20:46 - mmengine - INFO - Epoch(train) [12][4500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:48:13  time: 1.0596  data_time: 0.0035  memory: 9400  loss: 0.7208  loss_rpn_cls: 0.0337  loss_rpn_bbox: 0.0408  loss_cls: 0.1803  acc: 92.1875  loss_bbox: 0.2327  loss_mask: 0.2334
2025/12/15 03:21:38 - mmengine - INFO - Epoch(train) [12][4550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:47:22  time: 1.0269  data_time: 0.0035  memory: 9640  loss: 0.7346  loss_rpn_cls: 0.0291  loss_rpn_bbox: 0.0428  loss_cls: 0.1890  acc: 88.3301  loss_bbox: 0.2386  loss_mask: 0.2351
2025/12/15 03:22:28 - mmengine - INFO - Epoch(train) [12][4600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:46:31  time: 1.0125  data_time: 0.0034  memory: 9192  loss: 0.6737  loss_rpn_cls: 0.0255  loss_rpn_bbox: 0.0328  loss_cls: 0.1736  acc: 95.3613  loss_bbox: 0.2068  loss_mask: 0.2350
2025/12/15 03:23:21 - mmengine - INFO - Epoch(train) [12][4650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:45:40  time: 1.0409  data_time: 0.0035  memory: 9687  loss: 0.7197  loss_rpn_cls: 0.0332  loss_rpn_bbox: 0.0431  loss_cls: 0.1803  acc: 94.2871  loss_bbox: 0.2239  loss_mask: 0.2392
2025/12/15 03:24:11 - mmengine - INFO - Epoch(train) [12][4700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:44:49  time: 1.0172  data_time: 0.0034  memory: 9696  loss: 0.6792  loss_rpn_cls: 0.0297  loss_rpn_bbox: 0.0385  loss_cls: 0.1710  acc: 94.4336  loss_bbox: 0.2135  loss_mask: 0.2265
2025/12/15 03:25:03 - mmengine - INFO - Epoch(train) [12][4750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:43:58  time: 1.0257  data_time: 0.0034  memory: 9285  loss: 0.7062  loss_rpn_cls: 0.0289  loss_rpn_bbox: 0.0393  loss_cls: 0.1744  acc: 93.2129  loss_bbox: 0.2284  loss_mask: 0.2351
2025/12/15 03:25:55 - mmengine - INFO - Epoch(train) [12][4800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:43:07  time: 1.0469  data_time: 0.0035  memory: 9282  loss: 0.7117  loss_rpn_cls: 0.0270  loss_rpn_bbox: 0.0411  loss_cls: 0.1736  acc: 95.5078  loss_bbox: 0.2295  loss_mask: 0.2404
2025/12/15 03:26:48 - mmengine - INFO - Epoch(train) [12][4850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:42:16  time: 1.0502  data_time: 0.0035  memory: 9450  loss: 0.7141  loss_rpn_cls: 0.0308  loss_rpn_bbox: 0.0414  loss_cls: 0.1806  acc: 95.9473  loss_bbox: 0.2355  loss_mask: 0.2259
2025/12/15 03:27:39 - mmengine - INFO - Epoch(train) [12][4900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:41:25  time: 1.0257  data_time: 0.0035  memory: 9549  loss: 0.6998  loss_rpn_cls: 0.0290  loss_rpn_bbox: 0.0408  loss_cls: 0.1790  acc: 93.2129  loss_bbox: 0.2173  loss_mask: 0.2337
2025/12/15 03:28:31 - mmengine - INFO - Epoch(train) [12][4950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:40:34  time: 1.0427  data_time: 0.0035  memory: 9454  loss: 0.7622  loss_rpn_cls: 0.0328  loss_rpn_bbox: 0.0449  loss_cls: 0.1909  acc: 94.3359  loss_bbox: 0.2545  loss_mask: 0.2390
2025/12/15 03:29:23 - mmengine - INFO - Epoch(train) [12][5000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:39:43  time: 1.0360  data_time: 0.0035  memory: 9454  loss: 0.7247  loss_rpn_cls: 0.0307  loss_rpn_bbox: 0.0467  loss_cls: 0.1805  acc: 91.7969  loss_bbox: 0.2287  loss_mask: 0.2381
2025/12/15 03:30:15 - mmengine - INFO - Epoch(train) [12][5050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:38:52  time: 1.0443  data_time: 0.0036  memory: 9409  loss: 0.7503  loss_rpn_cls: 0.0298  loss_rpn_bbox: 0.0442  loss_cls: 0.1874  acc: 94.0918  loss_bbox: 0.2474  loss_mask: 0.2414
2025/12/15 03:31:07 - mmengine - INFO - Epoch(train) [12][5100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:38:01  time: 1.0347  data_time: 0.0035  memory: 9498  loss: 0.7755  loss_rpn_cls: 0.0379  loss_rpn_bbox: 0.0497  loss_cls: 0.1992  acc: 98.2910  loss_bbox: 0.2569  loss_mask: 0.2318
2025/12/15 03:31:58 - mmengine - INFO - Epoch(train) [12][5150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:37:10  time: 1.0285  data_time: 0.0035  memory: 9372  loss: 0.6922  loss_rpn_cls: 0.0249  loss_rpn_bbox: 0.0351  loss_cls: 0.1685  acc: 97.9980  loss_bbox: 0.2233  loss_mask: 0.2404
2025/12/15 03:32:51 - mmengine - INFO - Epoch(train) [12][5200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:36:19  time: 1.0460  data_time: 0.0035  memory: 9720  loss: 0.7503  loss_rpn_cls: 0.0315  loss_rpn_bbox: 0.0434  loss_cls: 0.1846  acc: 94.6777  loss_bbox: 0.2489  loss_mask: 0.2418
2025/12/15 03:33:43 - mmengine - INFO - Epoch(train) [12][5250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:35:27  time: 1.0451  data_time: 0.0034  memory: 9474  loss: 0.7298  loss_rpn_cls: 0.0328  loss_rpn_bbox: 0.0397  loss_cls: 0.1853  acc: 90.8691  loss_bbox: 0.2357  loss_mask: 0.2362
2025/12/15 03:34:35 - mmengine - INFO - Epoch(train) [12][5300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:34:36  time: 1.0344  data_time: 0.0035  memory: 9256  loss: 0.7322  loss_rpn_cls: 0.0322  loss_rpn_bbox: 0.0433  loss_cls: 0.1825  acc: 97.9004  loss_bbox: 0.2343  loss_mask: 0.2400
2025/12/15 03:35:26 - mmengine - INFO - Epoch(train) [12][5350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:33:45  time: 1.0179  data_time: 0.0035  memory: 9296  loss: 0.7094  loss_rpn_cls: 0.0284  loss_rpn_bbox: 0.0391  loss_cls: 0.1933  acc: 97.5586  loss_bbox: 0.2198  loss_mask: 0.2289
2025/12/15 03:35:46 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/15 03:36:16 - mmengine - INFO - Epoch(train) [12][5400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:32:54  time: 1.0160  data_time: 0.0035  memory: 9287  loss: 0.7327  loss_rpn_cls: 0.0307  loss_rpn_bbox: 0.0452  loss_cls: 0.1795  acc: 95.9473  loss_bbox: 0.2306  loss_mask: 0.2467
2025/12/15 03:37:07 - mmengine - INFO - Epoch(train) [12][5450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:32:03  time: 1.0173  data_time: 0.0036  memory: 9125  loss: 0.7114  loss_rpn_cls: 0.0271  loss_rpn_bbox: 0.0360  loss_cls: 0.1833  acc: 97.9980  loss_bbox: 0.2242  loss_mask: 0.2407
2025/12/15 03:37:58 - mmengine - INFO - Epoch(train) [12][5500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:31:12  time: 1.0196  data_time: 0.0041  memory: 9360  loss: 0.6791  loss_rpn_cls: 0.0301  loss_rpn_bbox: 0.0338  loss_cls: 0.1599  acc: 90.1855  loss_bbox: 0.2162  loss_mask: 0.2391
2025/12/15 03:38:50 - mmengine - INFO - Epoch(train) [12][5550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:30:21  time: 1.0428  data_time: 0.0038  memory: 9394  loss: 0.7436  loss_rpn_cls: 0.0335  loss_rpn_bbox: 0.0393  loss_cls: 0.1929  acc: 91.9434  loss_bbox: 0.2424  loss_mask: 0.2354
2025/12/15 03:39:42 - mmengine - INFO - Epoch(train) [12][5600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:29:29  time: 1.0365  data_time: 0.0038  memory: 9537  loss: 0.7131  loss_rpn_cls: 0.0291  loss_rpn_bbox: 0.0395  loss_cls: 0.1823  acc: 89.7461  loss_bbox: 0.2344  loss_mask: 0.2278
2025/12/15 03:40:34 - mmengine - INFO - Epoch(train) [12][5650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:28:38  time: 1.0300  data_time: 0.0037  memory: 9793  loss: 0.7336  loss_rpn_cls: 0.0290  loss_rpn_bbox: 0.0413  loss_cls: 0.1800  acc: 90.1367  loss_bbox: 0.2426  loss_mask: 0.2407
2025/12/15 03:41:25 - mmengine - INFO - Epoch(train) [12][5700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:27:47  time: 1.0336  data_time: 0.0035  memory: 9545  loss: 0.7381  loss_rpn_cls: 0.0325  loss_rpn_bbox: 0.0430  loss_cls: 0.1872  acc: 95.6055  loss_bbox: 0.2395  loss_mask: 0.2359
2025/12/15 03:42:17 - mmengine - INFO - Epoch(train) [12][5750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:26:56  time: 1.0352  data_time: 0.0036  memory: 9492  loss: 0.7076  loss_rpn_cls: 0.0276  loss_rpn_bbox: 0.0393  loss_cls: 0.1769  acc: 93.4570  loss_bbox: 0.2352  loss_mask: 0.2287
2025/12/15 03:43:09 - mmengine - INFO - Epoch(train) [12][5800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:26:05  time: 1.0451  data_time: 0.0041  memory: 9463  loss: 0.7599  loss_rpn_cls: 0.0355  loss_rpn_bbox: 0.0441  loss_cls: 0.1917  acc: 95.1172  loss_bbox: 0.2468  loss_mask: 0.2417
2025/12/15 03:44:00 - mmengine - INFO - Epoch(train) [12][5850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:25:14  time: 1.0188  data_time: 0.0038  memory: 9363  loss: 0.7395  loss_rpn_cls: 0.0263  loss_rpn_bbox: 0.0388  loss_cls: 0.1856  acc: 95.9473  loss_bbox: 0.2430  loss_mask: 0.2459
2025/12/15 03:44:53 - mmengine - INFO - Epoch(train) [12][5900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:24:23  time: 1.0506  data_time: 0.0036  memory: 9351  loss: 0.6577  loss_rpn_cls: 0.0237  loss_rpn_bbox: 0.0352  loss_cls: 0.1619  acc: 96.6309  loss_bbox: 0.2036  loss_mask: 0.2332
2025/12/15 03:45:44 - mmengine - INFO - Epoch(train) [12][5950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:23:32  time: 1.0171  data_time: 0.0037  memory: 9451  loss: 0.7493  loss_rpn_cls: 0.0318  loss_rpn_bbox: 0.0418  loss_cls: 0.1856  acc: 92.3828  loss_bbox: 0.2478  loss_mask: 0.2422
2025/12/15 03:46:36 - mmengine - INFO - Epoch(train) [12][6000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:22:41  time: 1.0474  data_time: 0.0036  memory: 9709  loss: 0.7482  loss_rpn_cls: 0.0326  loss_rpn_bbox: 0.0451  loss_cls: 0.1902  acc: 95.3613  loss_bbox: 0.2465  loss_mask: 0.2338
2025/12/15 03:47:28 - mmengine - INFO - Epoch(train) [12][6050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:21:49  time: 1.0329  data_time: 0.0037  memory: 9421  loss: 0.7112  loss_rpn_cls: 0.0299  loss_rpn_bbox: 0.0417  loss_cls: 0.1737  acc: 92.3340  loss_bbox: 0.2321  loss_mask: 0.2338
2025/12/15 03:48:19 - mmengine - INFO - Epoch(train) [12][6100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:20:58  time: 1.0214  data_time: 0.0039  memory: 9385  loss: 0.6646  loss_rpn_cls: 0.0259  loss_rpn_bbox: 0.0372  loss_cls: 0.1669  acc: 97.3633  loss_bbox: 0.2086  loss_mask: 0.2259
2025/12/15 03:49:11 - mmengine - INFO - Epoch(train) [12][6150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:20:07  time: 1.0495  data_time: 0.0038  memory: 9810  loss: 0.7543  loss_rpn_cls: 0.0288  loss_rpn_bbox: 0.0445  loss_cls: 0.1913  acc: 90.5762  loss_bbox: 0.2451  loss_mask: 0.2445
2025/12/15 03:50:02 - mmengine - INFO - Epoch(train) [12][6200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:19:16  time: 1.0024  data_time: 0.0036  memory: 9489  loss: 0.7094  loss_rpn_cls: 0.0301  loss_rpn_bbox: 0.0422  loss_cls: 0.1757  acc: 90.8203  loss_bbox: 0.2274  loss_mask: 0.2339
2025/12/15 03:50:54 - mmengine - INFO - Epoch(train) [12][6250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:18:25  time: 1.0452  data_time: 0.0036  memory: 9309  loss: 0.7478  loss_rpn_cls: 0.0300  loss_rpn_bbox: 0.0398  loss_cls: 0.1909  acc: 90.6250  loss_bbox: 0.2435  loss_mask: 0.2436
2025/12/15 03:51:46 - mmengine - INFO - Epoch(train) [12][6300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:17:34  time: 1.0420  data_time: 0.0036  memory: 9307  loss: 0.7598  loss_rpn_cls: 0.0345  loss_rpn_bbox: 0.0435  loss_cls: 0.1886  acc: 95.4102  loss_bbox: 0.2439  loss_mask: 0.2493
2025/12/15 03:52:38 - mmengine - INFO - Epoch(train) [12][6350/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:16:43  time: 1.0361  data_time: 0.0039  memory: 9969  loss: 0.6762  loss_rpn_cls: 0.0254  loss_rpn_bbox: 0.0374  loss_cls: 0.1671  acc: 99.0723  loss_bbox: 0.2187  loss_mask: 0.2275
2025/12/15 03:52:59 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/15 03:53:29 - mmengine - INFO - Epoch(train) [12][6400/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:15:51  time: 1.0269  data_time: 0.0044  memory: 9659  loss: 0.7724  loss_rpn_cls: 0.0320  loss_rpn_bbox: 0.0443  loss_cls: 0.1974  acc: 93.9941  loss_bbox: 0.2573  loss_mask: 0.2414
2025/12/15 03:54:20 - mmengine - INFO - Epoch(train) [12][6450/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:15:00  time: 1.0157  data_time: 0.0042  memory: 9284  loss: 0.7229  loss_rpn_cls: 0.0319  loss_rpn_bbox: 0.0380  loss_cls: 0.1779  acc: 92.2363  loss_bbox: 0.2347  loss_mask: 0.2404
2025/12/15 03:55:11 - mmengine - INFO - Epoch(train) [12][6500/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:14:09  time: 1.0203  data_time: 0.0042  memory: 9453  loss: 0.7199  loss_rpn_cls: 0.0302  loss_rpn_bbox: 0.0419  loss_cls: 0.1923  acc: 94.4824  loss_bbox: 0.2243  loss_mask: 0.2312
2025/12/15 03:56:03 - mmengine - INFO - Epoch(train) [12][6550/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:13:18  time: 1.0354  data_time: 0.0039  memory: 9410  loss: 0.7249  loss_rpn_cls: 0.0330  loss_rpn_bbox: 0.0393  loss_cls: 0.1760  acc: 88.4277  loss_bbox: 0.2284  loss_mask: 0.2482
2025/12/15 03:56:55 - mmengine - INFO - Epoch(train) [12][6600/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:12:27  time: 1.0354  data_time: 0.0041  memory: 9540  loss: 0.7500  loss_rpn_cls: 0.0316  loss_rpn_bbox: 0.0452  loss_cls: 0.1887  acc: 92.9688  loss_bbox: 0.2449  loss_mask: 0.2395
2025/12/15 03:57:45 - mmengine - INFO - Epoch(train) [12][6650/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:11:35  time: 1.0144  data_time: 0.0037  memory: 9869  loss: 0.6755  loss_rpn_cls: 0.0267  loss_rpn_bbox: 0.0368  loss_cls: 0.1703  acc: 91.4062  loss_bbox: 0.2148  loss_mask: 0.2269
2025/12/15 03:58:38 - mmengine - INFO - Epoch(train) [12][6700/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:10:44  time: 1.0491  data_time: 0.0037  memory: 9632  loss: 0.7347  loss_rpn_cls: 0.0295  loss_rpn_bbox: 0.0397  loss_cls: 0.1793  acc: 90.9180  loss_bbox: 0.2406  loss_mask: 0.2456
2025/12/15 03:59:29 - mmengine - INFO - Epoch(train) [12][6750/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:09:53  time: 1.0285  data_time: 0.0041  memory: 9378  loss: 0.6962  loss_rpn_cls: 0.0284  loss_rpn_bbox: 0.0360  loss_cls: 0.1776  acc: 93.8477  loss_bbox: 0.2268  loss_mask: 0.2274
2025/12/15 04:00:22 - mmengine - INFO - Epoch(train) [12][6800/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:09:02  time: 1.0495  data_time: 0.0043  memory: 9542  loss: 0.7249  loss_rpn_cls: 0.0275  loss_rpn_bbox: 0.0400  loss_cls: 0.1884  acc: 94.4336  loss_bbox: 0.2382  loss_mask: 0.2308
2025/12/15 04:01:14 - mmengine - INFO - Epoch(train) [12][6850/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:08:11  time: 1.0524  data_time: 0.0044  memory: 9216  loss: 0.7900  loss_rpn_cls: 0.0356  loss_rpn_bbox: 0.0493  loss_cls: 0.2002  acc: 93.8965  loss_bbox: 0.2595  loss_mask: 0.2454
2025/12/15 04:02:05 - mmengine - INFO - Epoch(train) [12][6900/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:07:20  time: 1.0197  data_time: 0.0041  memory: 9334  loss: 0.7281  loss_rpn_cls: 0.0250  loss_rpn_bbox: 0.0391  loss_cls: 0.1883  acc: 92.8223  loss_bbox: 0.2371  loss_mask: 0.2386
2025/12/15 04:02:56 - mmengine - INFO - Epoch(train) [12][6950/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:06:29  time: 1.0174  data_time: 0.0039  memory: 9371  loss: 0.7406  loss_rpn_cls: 0.0316  loss_rpn_bbox: 0.0400  loss_cls: 0.1865  acc: 92.7246  loss_bbox: 0.2389  loss_mask: 0.2436
2025/12/15 04:03:48 - mmengine - INFO - Epoch(train) [12][7000/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:05:37  time: 1.0250  data_time: 0.0042  memory: 9371  loss: 0.7180  loss_rpn_cls: 0.0308  loss_rpn_bbox: 0.0393  loss_cls: 0.1802  acc: 95.0684  loss_bbox: 0.2382  loss_mask: 0.2295
2025/12/15 04:04:39 - mmengine - INFO - Epoch(train) [12][7050/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:04:46  time: 1.0257  data_time: 0.0039  memory: 9784  loss: 0.7467  loss_rpn_cls: 0.0354  loss_rpn_bbox: 0.0435  loss_cls: 0.1857  acc: 94.4824  loss_bbox: 0.2430  loss_mask: 0.2391
2025/12/15 04:05:31 - mmengine - INFO - Epoch(train) [12][7100/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:03:55  time: 1.0427  data_time: 0.0037  memory: 9791  loss: 0.7616  loss_rpn_cls: 0.0328  loss_rpn_bbox: 0.0425  loss_cls: 0.2007  acc: 93.3105  loss_bbox: 0.2468  loss_mask: 0.2388
2025/12/15 04:06:22 - mmengine - INFO - Epoch(train) [12][7150/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:03:04  time: 1.0151  data_time: 0.0038  memory: 9366  loss: 0.7039  loss_rpn_cls: 0.0309  loss_rpn_bbox: 0.0410  loss_cls: 0.1730  acc: 91.9434  loss_bbox: 0.2257  loss_mask: 0.2333
2025/12/15 04:07:13 - mmengine - INFO - Epoch(train) [12][7200/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:02:13  time: 1.0257  data_time: 0.0041  memory: 9390  loss: 0.6883  loss_rpn_cls: 0.0258  loss_rpn_bbox: 0.0386  loss_cls: 0.1765  acc: 93.8477  loss_bbox: 0.2213  loss_mask: 0.2261
2025/12/15 04:08:04 - mmengine - INFO - Epoch(train) [12][7250/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:01:21  time: 1.0284  data_time: 0.0039  memory: 9415  loss: 0.7340  loss_rpn_cls: 0.0283  loss_rpn_bbox: 0.0406  loss_cls: 0.1827  acc: 95.8984  loss_bbox: 0.2360  loss_mask: 0.2465
2025/12/15 04:08:56 - mmengine - INFO - Epoch(train) [12][7300/7330]  base_lr: 1.0000e-06 lr: 1.0000e-06  eta: 0:00:30  time: 1.0341  data_time: 0.0038  memory: 9564  loss: 0.7306  loss_rpn_cls: 0.0332  loss_rpn_bbox: 0.0408  loss_cls: 0.1804  acc: 92.2363  loss_bbox: 0.2335  loss_mask: 0.2428
2025/12/15 04:09:27 - mmengine - INFO - Exp name: mask_rcnn_mamba_out_vision_t_1x_coco_20251214_213921
2025/12/15 04:09:27 - mmengine - INFO - Saving checkpoint at 12 epochs
2025/12/15 04:10:23 - mmengine - INFO - Epoch(val) [12][ 50/313]    eta: 0:04:38  time: 1.0595  data_time: 0.0066  memory: 9139  
2025/12/15 04:11:14 - mmengine - INFO - Epoch(val) [12][100/313]    eta: 0:03:41  time: 1.0191  data_time: 0.0008  memory: 2466  
2025/12/15 04:12:05 - mmengine - INFO - Epoch(val) [12][150/313]    eta: 0:02:48  time: 1.0194  data_time: 0.0008  memory: 2551  
2025/12/15 04:12:56 - mmengine - INFO - Epoch(val) [12][200/313]    eta: 0:01:56  time: 1.0172  data_time: 0.0008  memory: 2637  
2025/12/15 04:13:47 - mmengine - INFO - Epoch(val) [12][250/313]    eta: 0:01:04  time: 1.0213  data_time: 0.0008  memory: 2637  
2025/12/15 04:14:38 - mmengine - INFO - Epoch(val) [12][300/313]    eta: 0:00:13  time: 1.0191  data_time: 0.0008  memory: 2552  
2025/12/15 04:15:01 - mmengine - INFO - Evaluating bbox...
2025/12/15 04:15:35 - mmengine - INFO - bbox_mAP_copypaste: 0.450 0.667 0.492 0.296 0.483 0.586
2025/12/15 04:15:35 - mmengine - INFO - Evaluating segm...
2025/12/15 04:16:14 - mmengine - INFO - segm_mAP_copypaste: 0.399 0.631 0.428 0.212 0.431 0.584
2025/12/15 04:16:14 - mmengine - INFO - Epoch(val) [12][313/313]    coco/bbox_mAP: 0.4500  coco/bbox_mAP_50: 0.6670  coco/bbox_mAP_75: 0.4920  coco/bbox_mAP_s: 0.2960  coco/bbox_mAP_m: 0.4830  coco/bbox_mAP_l: 0.5860  coco/segm_mAP: 0.3990  coco/segm_mAP_50: 0.6310  coco/segm_mAP_75: 0.4280  coco/segm_mAP_s: 0.2120  coco/segm_mAP_m: 0.4310  coco/segm_mAP_l: 0.5840  data_time: 0.0017  time: 1.0219
