2025/12/11 08:38:36 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.25 (main, Nov  3 2025, 22:33:05) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1746547140
    GPU 0,1: NVIDIA GeForce RTX 3090
    CUDA_HOME: /usr/local/cuda
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
    PyTorch: 2.1.2+cu118
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.2+cu118
    OpenCV: 4.11.0
    MMEngine: 0.10.3

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1746547140
    Distributed launcher: pytorch
    Distributed training: True
    GPU number: 2
------------------------------------------------------------

2025/12/11 08:38:38 - mmengine - INFO - Config:
accum_steps = 1
auto_scale_lr = dict(base_batch_size=16, enable=False)
backend_args = None
batch_size_per_gpu = 8
data_root = './coco/'
dataset_type = 'CocoDataset'
default_hooks = dict(
    checkpoint=dict(interval=1, type='CheckpointHook'),
    logger=dict(interval=50, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='DetVisualizationHook'))
default_scope = 'mmdet'
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
launcher = 'pytorch'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=True, type='LogProcessor', window_size=50)
log_root = './log_dirs/mamba_vision_t_object_detection'
max_epochs = 12
model = dict(
    backbone=dict(
        depth=50,
        depths=(
            1,
            3,
            8,
            4,
        ),
        dim=80,
        drop_path_rate=0.2,
        frozen_stages=1,
        in_dim=32,
        init_cfg=dict(checkpoint='torchvision://resnet50', type='Pretrained'),
        layer_scale=None,
        mlp_ratio=4,
        norm_cfg=dict(requires_grad=True, type='BN'),
        norm_eval=True,
        norm_layer='ln2d',
        num_heads=(
            2,
            4,
            8,
            16,
        ),
        num_stages=4,
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        pretrained='../models/mamba_vision_T-224/model_best.pth.tar',
        style='pytorch',
        type='MM_mamba_vision',
        window_size=(
            8,
            8,
            112,
            56,
        )),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_mask=True,
        pad_size_divisor=32,
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='DetDataPreprocessor'),
    neck=dict(
        in_channels=[
            80,
            160,
            320,
            640,
        ],
        num_outs=5,
        out_channels=256,
        type='FPN'),
    roi_head=dict(
        bbox_head=dict(
            bbox_coder=dict(
                target_means=[
                    0.0,
                    0.0,
                    0.0,
                    0.0,
                ],
                target_stds=[
                    0.1,
                    0.1,
                    0.2,
                    0.2,
                ],
                type='DeltaXYWHBBoxCoder'),
            conv_out_channels=256,
            fc_out_channels=1024,
            in_channels=256,
            loss_bbox=dict(loss_weight=10.0, type='GIoULoss'),
            loss_cls=dict(
                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
            norm_cfg=dict(requires_grad=True, type='SyncBN'),
            num_classes=80,
            num_shared_convs=4,
            num_shared_fcs=1,
            reg_class_agnostic=False,
            reg_decoded_bbox=True,
            roi_feat_size=7,
            type='ConvFCBBoxHead'),
        bbox_roi_extractor=dict(
            featmap_strides=[
                4,
                8,
                16,
                32,
            ],
            out_channels=256,
            roi_layer=dict(output_size=7, sampling_ratio=0, type='RoIAlign'),
            type='SingleRoIExtractor'),
        mask_head=dict(
            conv_out_channels=256,
            in_channels=256,
            loss_mask=dict(
                loss_weight=1.0, type='CrossEntropyLoss', use_mask=True),
            num_classes=80,
            num_convs=4,
            type='FCNMaskHead'),
        mask_roi_extractor=dict(
            featmap_strides=[
                4,
                8,
                16,
                32,
            ],
            out_channels=256,
            roi_layer=dict(output_size=14, sampling_ratio=0, type='RoIAlign'),
            type='SingleRoIExtractor'),
        type='StandardRoIHead'),
    rpn_head=dict(
        anchor_generator=dict(
            ratios=[
                0.5,
                1.0,
                2.0,
            ],
            scales=[
                8,
            ],
            strides=[
                4,
                8,
                16,
                32,
                64,
            ],
            type='AnchorGenerator'),
        bbox_coder=dict(
            target_means=[
                0.0,
                0.0,
                0.0,
                0.0,
            ],
            target_stds=[
                1.0,
                1.0,
                1.0,
                1.0,
            ],
            type='DeltaXYWHBBoxCoder'),
        feat_channels=256,
        in_channels=256,
        loss_bbox=dict(loss_weight=1.0, type='L1Loss'),
        loss_cls=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=True),
        type='RPNHead'),
    test_cfg=dict(
        rcnn=dict(
            mask_thr_binary=0.5,
            max_per_img=100,
            nms=dict(iou_threshold=0.5, type='nms'),
            score_thr=0.05),
        rpn=dict(
            max_per_img=1000,
            min_bbox_size=0,
            nms=dict(iou_threshold=0.7, type='nms'),
            nms_pre=1000)),
    train_cfg=dict(
        rcnn=dict(
            assigner=dict(
                ignore_iof_thr=-1,
                match_low_quality=True,
                min_pos_iou=0.5,
                neg_iou_thr=0.5,
                pos_iou_thr=0.5,
                type='MaxIoUAssigner'),
            debug=False,
            mask_size=28,
            pos_weight=-1,
            sampler=dict(
                add_gt_as_proposals=True,
                neg_pos_ub=-1,
                num=512,
                pos_fraction=0.25,
                type='RandomSampler')),
        rpn=dict(
            allowed_border=-1,
            assigner=dict(
                ignore_iof_thr=-1,
                match_low_quality=True,
                min_pos_iou=0.3,
                neg_iou_thr=0.3,
                pos_iou_thr=0.7,
                type='MaxIoUAssigner'),
            debug=False,
            pos_weight=-1,
            sampler=dict(
                add_gt_as_proposals=False,
                neg_pos_ub=-1,
                num=256,
                pos_fraction=0.5,
                type='RandomSampler')),
        rpn_proposal=dict(
            max_per_img=1000,
            min_bbox_size=0,
            nms=dict(iou_threshold=0.7, type='nms'),
            nms_pre=2000)),
    type='MaskRCNN')
num_gpus = 2
optim_wrapper = dict(
    accumulative_counts=1,
    loss_scale='dynamic',
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ), lr=0.0001, type='AdamW', weight_decay=0.05),
    paramwise_cfg=dict(custom_keys=dict(norm=dict(decay_mult=0.0))),
    type='AmpOptimWrapper')
param_scheduler = [
    dict(
        begin=0, by_epoch=False, end=1000, start_factor=0.001,
        type='LinearLR'),
    dict(
        begin=0,
        by_epoch=True,
        end=12,
        gamma=0.1,
        milestones=[
            8,
            11,
        ],
        type='MultiStepLR'),
]
resume = False
run_name = 'mamba_vision_t_object_detection'
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=8,
    dataset=dict(
        ann_file='annotations/instances_val2017.json',
        backend_args=None,
        data_prefix=dict(img='val2017/'),
        data_root='./coco/',
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                1333,
                800,
            ), type='Resize'),
            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackDetInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=4,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    ann_file='./coco/annotations/instances_val2017.json',
    backend_args=None,
    format_only=False,
    metric=[
        'bbox',
        'segm',
    ],
    type='CocoMetric')
test_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        1333,
        800,
    ), type='Resize'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(
        meta_keys=(
            'img_id',
            'img_path',
            'ori_shape',
            'img_shape',
            'scale_factor',
        ),
        type='PackDetInputs'),
]
total_batch_size = 16
train_cfg = dict(max_epochs=12, type='EpochBasedTrainLoop', val_interval=1)
train_dataloader = dict(
    batch_sampler=dict(type='AspectRatioBatchSampler'),
    batch_size=8,
    dataset=dict(
        ann_file='annotations/instances_train2017.json',
        backend_args=None,
        data_prefix=dict(img='train2017/'),
        data_root='./coco/',
        filter_cfg=dict(filter_empty_gt=True, min_size=32),
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
            dict(prob=0.5, type='RandomFlip'),
            dict(
                transforms=[
                    [
                        dict(
                            keep_ratio=True,
                            scales=[
                                (
                                    480,
                                    1333,
                                ),
                                (
                                    512,
                                    1333,
                                ),
                                (
                                    544,
                                    1333,
                                ),
                                (
                                    576,
                                    1333,
                                ),
                                (
                                    608,
                                    1333,
                                ),
                                (
                                    640,
                                    1333,
                                ),
                                (
                                    672,
                                    1333,
                                ),
                                (
                                    704,
                                    1333,
                                ),
                                (
                                    736,
                                    1333,
                                ),
                                (
                                    768,
                                    1333,
                                ),
                                (
                                    800,
                                    1333,
                                ),
                            ],
                            type='RandomChoiceResize'),
                    ],
                    [
                        dict(
                            keep_ratio=True,
                            scales=[
                                (
                                    400,
                                    1333,
                                ),
                                (
                                    500,
                                    1333,
                                ),
                                (
                                    600,
                                    1333,
                                ),
                            ],
                            type='RandomChoiceResize'),
                        dict(
                            allow_negative_crop=True,
                            crop_size=(
                                384,
                                600,
                            ),
                            crop_type='absolute_range',
                            type='RandomCrop'),
                        dict(
                            keep_ratio=True,
                            scales=[
                                (
                                    480,
                                    1333,
                                ),
                                (
                                    512,
                                    1333,
                                ),
                                (
                                    544,
                                    1333,
                                ),
                                (
                                    576,
                                    1333,
                                ),
                                (
                                    608,
                                    1333,
                                ),
                                (
                                    640,
                                    1333,
                                ),
                                (
                                    672,
                                    1333,
                                ),
                                (
                                    704,
                                    1333,
                                ),
                                (
                                    736,
                                    1333,
                                ),
                                (
                                    768,
                                    1333,
                                ),
                                (
                                    800,
                                    1333,
                                ),
                            ],
                            type='RandomChoiceResize'),
                    ],
                ],
                type='RandomChoice'),
            dict(type='PackDetInputs'),
        ],
        type='CocoDataset'),
    num_workers=4,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=True, type='DefaultSampler'))
train_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(prob=0.5, type='RandomFlip'),
    dict(
        transforms=[
            [
                dict(
                    keep_ratio=True,
                    scales=[
                        (
                            480,
                            1333,
                        ),
                        (
                            512,
                            1333,
                        ),
                        (
                            544,
                            1333,
                        ),
                        (
                            576,
                            1333,
                        ),
                        (
                            608,
                            1333,
                        ),
                        (
                            640,
                            1333,
                        ),
                        (
                            672,
                            1333,
                        ),
                        (
                            704,
                            1333,
                        ),
                        (
                            736,
                            1333,
                        ),
                        (
                            768,
                            1333,
                        ),
                        (
                            800,
                            1333,
                        ),
                    ],
                    type='RandomChoiceResize'),
            ],
            [
                dict(
                    keep_ratio=True,
                    scales=[
                        (
                            400,
                            1333,
                        ),
                        (
                            500,
                            1333,
                        ),
                        (
                            600,
                            1333,
                        ),
                    ],
                    type='RandomChoiceResize'),
                dict(
                    allow_negative_crop=True,
                    crop_size=(
                        384,
                        600,
                    ),
                    crop_type='absolute_range',
                    type='RandomCrop'),
                dict(
                    keep_ratio=True,
                    scales=[
                        (
                            480,
                            1333,
                        ),
                        (
                            512,
                            1333,
                        ),
                        (
                            544,
                            1333,
                        ),
                        (
                            576,
                            1333,
                        ),
                        (
                            608,
                            1333,
                        ),
                        (
                            640,
                            1333,
                        ),
                        (
                            672,
                            1333,
                        ),
                        (
                            704,
                            1333,
                        ),
                        (
                            736,
                            1333,
                        ),
                        (
                            768,
                            1333,
                        ),
                        (
                            800,
                            1333,
                        ),
                    ],
                    type='RandomChoiceResize'),
            ],
        ],
        type='RandomChoice'),
    dict(type='PackDetInputs'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=8,
    dataset=dict(
        ann_file='annotations/instances_val2017.json',
        backend_args=None,
        data_prefix=dict(img='val2017/'),
        data_root='./coco/',
        pipeline=[
            dict(backend_args=None, type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                1333,
                800,
            ), type='Resize'),
            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
            dict(
                meta_keys=(
                    'img_id',
                    'img_path',
                    'ori_shape',
                    'img_shape',
                    'scale_factor',
                ),
                type='PackDetInputs'),
        ],
        test_mode=True,
        type='CocoDataset'),
    drop_last=False,
    num_workers=4,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    ann_file='./coco/annotations/instances_val2017.json',
    backend_args=None,
    format_only=False,
    metric=[
        'bbox',
        'segm',
    ],
    type='CocoMetric')
vis_backends = [
    dict(
        save_dir='./log_dirs/mamba_vision_t_object_detection',
        type='TensorboardVisBackend'),
    dict(
        save_dir='./log_dirs/mamba_vision_t_object_detection',
        type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='DetLocalVisualizer',
    vis_backends=[
        dict(
            save_dir='./log_dirs/mamba_vision_t_object_detection',
            type='TensorboardVisBackend'),
        dict(
            save_dir='./log_dirs/mamba_vision_t_object_detection',
            type='LocalVisBackend'),
    ])
work_dir = '../work_dirs/mamba_vision_t_object_detection'

2025/12/11 08:38:42 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DetVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm1.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm1.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm1.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm1.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm1.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm1.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm2.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm2.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm2.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm2.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm2.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.0.blocks.0.norm2.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm1.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm1.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm1.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm1.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm1.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm1.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm2.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm2.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm2.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm2.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm2.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.0.norm2.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm1.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm1.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm1.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm1.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm1.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm1.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm2.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm2.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm2.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm2.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm2.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.1.norm2.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm1.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm1.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm1.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm1.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm1.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm1.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm2.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm2.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm2.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm2.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm2.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.1.blocks.2.norm2.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm1.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm1.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm1.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm1.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm1.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm1.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm2.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm2.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm2.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm2.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm2.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.0.norm2.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm1.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm1.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm1.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm1.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm1.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm1.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm2.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm2.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm2.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm2.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm2.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.1.norm2.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm1.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm1.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm1.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm1.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm1.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm1.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm2.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm2.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm2.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm2.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm2.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.2.norm2.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm1.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm1.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm1.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm1.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm1.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm1.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm2.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm2.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm2.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm2.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm2.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.3.norm2.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm1.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm1.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm1.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm1.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm1.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm1.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm2.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm2.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm2.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm2.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm2.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.4.norm2.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm1.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm1.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm1.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm1.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm1.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm1.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm2.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm2.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm2.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm2.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm2.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.5.norm2.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm1.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm1.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm1.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm1.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm1.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm1.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm2.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm2.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm2.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm2.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm2.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.6.norm2.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm1.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm1.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm1.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm1.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm1.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm1.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm2.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm2.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm2.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm2.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm2.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.2.blocks.7.norm2.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm1.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm1.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm1.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm1.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm1.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm1.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm2.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm2.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm2.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm2.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm2.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.0.norm2.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm1.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm1.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm1.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm1.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm1.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm1.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm2.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm2.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm2.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm2.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm2.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.1.norm2.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm1.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm1.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm1.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm1.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm1.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm1.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm2.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm2.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm2.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm2.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm2.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.2.norm2.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm1.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm1.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm1.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm1.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm1.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm1.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm2.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm2.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm2.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm2.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm2.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.levels.3.blocks.3.norm2.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm0.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm0.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm0.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm0.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm0.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm0.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm1.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm1.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm1.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm1.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm1.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm1.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm2.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm2.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm2.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm2.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm2.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm2.bias:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm3.weight:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm3.weight:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm3.weight:decay_mult=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm3.bias:lr=0.0001
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm3.bias:weight_decay=0.0
2025/12/11 08:39:18 - mmengine - INFO - paramwise_options -- backbone.outnorm3.bias:decay_mult=0.0
Name of parameter - Initialization information

backbone.patch_embed.conv_down.0.weight - torch.Size([32, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.patch_embed.conv_down.1.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.patch_embed.conv_down.1.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.patch_embed.conv_down.3.weight - torch.Size([80, 32, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.patch_embed.conv_down.4.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.patch_embed.conv_down.4.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.conv1.weight - torch.Size([80, 80, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.conv1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.norm1.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.norm1.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.conv2.weight - torch.Size([80, 80, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.conv2.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.norm2.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.blocks.0.norm2.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.0.downsample.reduction.0.weight - torch.Size([160, 80, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.conv1.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.conv1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.norm1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.norm1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.conv2.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.conv2.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.norm2.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.0.norm2.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.conv1.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.conv1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.norm1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.norm1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.conv2.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.conv2.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.norm2.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.1.norm2.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.conv1.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.conv1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.norm1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.norm1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.conv2.weight - torch.Size([160, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.conv2.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.norm2.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.blocks.2.norm2.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.1.downsample.reduction.0.weight - torch.Size([320, 160, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mixer.A_log - torch.Size([160, 8]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mixer.D - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mixer.in_proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mixer.x_proj.weight - torch.Size([36, 160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mixer.dt_proj.weight - torch.Size([160, 20]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mixer.dt_proj.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mixer.out_proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mixer.conv1d_x.weight - torch.Size([160, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mixer.conv1d_z.weight - torch.Size([160, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mlp.fc1.weight - torch.Size([1280, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mlp.fc2.weight - torch.Size([320, 1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.0.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mixer.A_log - torch.Size([160, 8]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mixer.D - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mixer.in_proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mixer.x_proj.weight - torch.Size([36, 160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mixer.dt_proj.weight - torch.Size([160, 20]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mixer.dt_proj.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mixer.out_proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mixer.conv1d_x.weight - torch.Size([160, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mixer.conv1d_z.weight - torch.Size([160, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mlp.fc1.weight - torch.Size([1280, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mlp.fc2.weight - torch.Size([320, 1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.1.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mixer.A_log - torch.Size([160, 8]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mixer.D - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mixer.in_proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mixer.x_proj.weight - torch.Size([36, 160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mixer.dt_proj.weight - torch.Size([160, 20]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mixer.dt_proj.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mixer.out_proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mixer.conv1d_x.weight - torch.Size([160, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mixer.conv1d_z.weight - torch.Size([160, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mlp.fc1.weight - torch.Size([1280, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mlp.fc2.weight - torch.Size([320, 1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.2.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mixer.A_log - torch.Size([160, 8]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mixer.D - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mixer.in_proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mixer.x_proj.weight - torch.Size([36, 160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mixer.dt_proj.weight - torch.Size([160, 20]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mixer.dt_proj.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mixer.out_proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mixer.conv1d_x.weight - torch.Size([160, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mixer.conv1d_z.weight - torch.Size([160, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mlp.fc1.weight - torch.Size([1280, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mlp.fc2.weight - torch.Size([320, 1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.3.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mixer.qkv.weight - torch.Size([960, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mixer.qkv.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mixer.proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mixer.proj.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mlp.fc1.weight - torch.Size([1280, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mlp.fc2.weight - torch.Size([320, 1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.4.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mixer.qkv.weight - torch.Size([960, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mixer.qkv.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mixer.proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mixer.proj.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mlp.fc1.weight - torch.Size([1280, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mlp.fc2.weight - torch.Size([320, 1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.5.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mixer.qkv.weight - torch.Size([960, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mixer.qkv.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mixer.proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mixer.proj.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mlp.fc1.weight - torch.Size([1280, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mlp.fc2.weight - torch.Size([320, 1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.6.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.norm1.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.norm1.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.mixer.qkv.weight - torch.Size([960, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.mixer.qkv.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.mixer.proj.weight - torch.Size([320, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.mixer.proj.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.norm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.norm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.mlp.fc1.weight - torch.Size([1280, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.mlp.fc1.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.mlp.fc2.weight - torch.Size([320, 1280]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.blocks.7.mlp.fc2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.2.downsample.reduction.0.weight - torch.Size([640, 320, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.norm1.weight - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.norm1.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mixer.A_log - torch.Size([320, 8]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mixer.D - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mixer.in_proj.weight - torch.Size([640, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mixer.x_proj.weight - torch.Size([56, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mixer.dt_proj.weight - torch.Size([320, 40]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mixer.dt_proj.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mixer.out_proj.weight - torch.Size([640, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mixer.conv1d_x.weight - torch.Size([320, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mixer.conv1d_z.weight - torch.Size([320, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.norm2.weight - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.norm2.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mlp.fc1.weight - torch.Size([2560, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mlp.fc1.bias - torch.Size([2560]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mlp.fc2.weight - torch.Size([640, 2560]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.0.mlp.fc2.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.norm1.weight - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.norm1.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mixer.A_log - torch.Size([320, 8]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mixer.D - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mixer.in_proj.weight - torch.Size([640, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mixer.x_proj.weight - torch.Size([56, 320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mixer.dt_proj.weight - torch.Size([320, 40]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mixer.dt_proj.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mixer.out_proj.weight - torch.Size([640, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mixer.conv1d_x.weight - torch.Size([320, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mixer.conv1d_z.weight - torch.Size([320, 1, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.norm2.weight - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.norm2.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mlp.fc1.weight - torch.Size([2560, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mlp.fc1.bias - torch.Size([2560]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mlp.fc2.weight - torch.Size([640, 2560]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.1.mlp.fc2.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.norm1.weight - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.norm1.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mixer.qkv.weight - torch.Size([1920, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mixer.qkv.bias - torch.Size([1920]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mixer.proj.weight - torch.Size([640, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mixer.proj.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.norm2.weight - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.norm2.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mlp.fc1.weight - torch.Size([2560, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mlp.fc1.bias - torch.Size([2560]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mlp.fc2.weight - torch.Size([640, 2560]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.2.mlp.fc2.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.norm1.weight - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.norm1.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mixer.qkv.weight - torch.Size([1920, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mixer.qkv.bias - torch.Size([1920]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mixer.proj.weight - torch.Size([640, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mixer.proj.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.norm2.weight - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.norm2.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mlp.fc1.weight - torch.Size([2560, 640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mlp.fc1.bias - torch.Size([2560]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mlp.fc2.weight - torch.Size([640, 2560]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.levels.3.blocks.3.mlp.fc2.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm0.weight - torch.Size([80]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm0.bias - torch.Size([80]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm1.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm1.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm2.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm2.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm3.weight - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.outnorm3.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.lateral_convs.0.conv.weight - torch.Size([256, 80, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.lateral_convs.1.conv.weight - torch.Size([256, 160, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.lateral_convs.2.conv.weight - torch.Size([256, 320, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.lateral_convs.3.conv.weight - torch.Size([256, 640, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_conv.bias - torch.Size([256]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.bias - torch.Size([3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.weight - torch.Size([12, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.bias - torch.Size([12]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.fc_cls.weight - torch.Size([81, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.fc_cls.bias - torch.Size([81]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.fc_reg.weight - torch.Size([320, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.fc_reg.bias - torch.Size([320]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.shared_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_convs.3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.mask_head.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.mask_head.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.mask_head.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.mask_head.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.mask_head.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.mask_head.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.mask_head.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

roi_head.mask_head.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

roi_head.mask_head.upsample.weight - torch.Size([256, 256, 2, 2]): 
Initialized by user-defined `init_weights` in FCNMaskHead  

roi_head.mask_head.upsample.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in FCNMaskHead  

roi_head.mask_head.conv_logits.weight - torch.Size([80, 256, 1, 1]): 
Initialized by user-defined `init_weights` in FCNMaskHead  

roi_head.mask_head.conv_logits.bias - torch.Size([80]): 
Initialized by user-defined `init_weights` in FCNMaskHead  
2025/12/11 08:39:22 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2025/12/11 08:39:22 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2025/12/11 08:39:22 - mmengine - INFO - Checkpoints will be saved to /home/chenhao/MambaVision/work_dirs/mamba_vision_t_object_detection.
2025/12/11 08:40:55 - mmengine - INFO - Epoch(train)  [1][  50/7330]  base_lr: 5.0000e-06 lr: 5.0000e-06  eta: 1 day, 21:30:15  time: 1.8634  data_time: 0.0366  memory: 17563  loss: 5.2898  loss_rpn_cls: 0.6455  loss_rpn_bbox: 0.0924  loss_cls: 3.6213  acc: 96.1182  loss_bbox: 0.0401  loss_mask: 0.8904
2025/12/11 08:42:16 - mmengine - INFO - Epoch(train)  [1][ 100/7330]  base_lr: 1.0000e-05 lr: 1.0000e-05  eta: 1 day, 18:34:34  time: 1.6256  data_time: 0.0039  memory: 17563  loss: 2.0920  loss_rpn_cls: 0.4735  loss_rpn_bbox: 0.0780  loss_cls: 0.6431  acc: 94.9463  loss_bbox: 0.1494  loss_mask: 0.7479
2025/12/11 08:43:38 - mmengine - INFO - Epoch(train)  [1][ 150/7330]  base_lr: 1.5000e-05 lr: 1.5000e-05  eta: 1 day, 17:39:46  time: 1.6352  data_time: 0.0034  memory: 18079  loss: 1.6250  loss_rpn_cls: 0.2561  loss_rpn_bbox: 0.0745  loss_cls: 0.3997  acc: 93.7744  loss_bbox: 0.1893  loss_mask: 0.7055
2025/12/11 08:45:00 - mmengine - INFO - Epoch(train)  [1][ 200/7330]  base_lr: 2.0000e-05 lr: 2.0000e-05  eta: 1 day, 17:11:39  time: 1.6351  data_time: 0.0035  memory: 17344  loss: 1.5971  loss_rpn_cls: 0.2299  loss_rpn_bbox: 0.0771  loss_cls: 0.4014  acc: 96.9238  loss_bbox: 0.1978  loss_mask: 0.6909
2025/12/11 08:46:22 - mmengine - INFO - Epoch(train)  [1][ 250/7330]  base_lr: 2.5000e-05 lr: 2.5000e-05  eta: 1 day, 16:56:54  time: 1.6442  data_time: 0.0036  memory: 17211  loss: 1.6048  loss_rpn_cls: 0.1845  loss_rpn_bbox: 0.0729  loss_cls: 0.4356  acc: 92.7002  loss_bbox: 0.2270  loss_mask: 0.6848
2025/12/11 08:47:44 - mmengine - INFO - Epoch(train)  [1][ 300/7330]  base_lr: 3.0000e-05 lr: 3.0000e-05  eta: 1 day, 16:46:13  time: 1.6426  data_time: 0.0034  memory: 17973  loss: 1.5902  loss_rpn_cls: 0.1787  loss_rpn_bbox: 0.0792  loss_cls: 0.4342  acc: 91.4307  loss_bbox: 0.2285  loss_mask: 0.6696
2025/12/11 08:49:05 - mmengine - INFO - Epoch(train)  [1][ 350/7330]  base_lr: 3.5000e-05 lr: 3.5000e-05  eta: 1 day, 16:35:19  time: 1.6288  data_time: 0.0034  memory: 18195  loss: 1.5359  loss_rpn_cls: 0.1586  loss_rpn_bbox: 0.0793  loss_cls: 0.4250  acc: 92.4316  loss_bbox: 0.2341  loss_mask: 0.6388
2025/12/11 08:50:28 - mmengine - INFO - Epoch(train)  [1][ 400/7330]  base_lr: 4.0000e-05 lr: 4.0000e-05  eta: 1 day, 16:29:32  time: 1.6437  data_time: 0.0033  memory: 18374  loss: 1.5415  loss_rpn_cls: 0.1393  loss_rpn_bbox: 0.0793  loss_cls: 0.4427  acc: 91.8457  loss_bbox: 0.2610  loss_mask: 0.6193
2025/12/11 08:51:49 - mmengine - INFO - Epoch(train)  [1][ 450/7330]  base_lr: 4.5000e-05 lr: 4.5000e-05  eta: 1 day, 16:22:44  time: 1.6314  data_time: 0.0033  memory: 17872  loss: 1.5445  loss_rpn_cls: 0.1256  loss_rpn_bbox: 0.0760  loss_cls: 0.4624  acc: 92.8955  loss_bbox: 0.2840  loss_mask: 0.5965
2025/12/11 08:53:11 - mmengine - INFO - Epoch(train)  [1][ 500/7330]  base_lr: 5.0000e-05 lr: 5.0000e-05  eta: 1 day, 16:18:52  time: 1.6442  data_time: 0.0033  memory: 17853  loss: 1.5582  loss_rpn_cls: 0.1146  loss_rpn_bbox: 0.0739  loss_cls: 0.4856  acc: 90.1123  loss_bbox: 0.3123  loss_mask: 0.5718
2025/12/11 08:54:33 - mmengine - INFO - Epoch(train)  [1][ 550/7330]  base_lr: 5.5000e-05 lr: 5.5000e-05  eta: 1 day, 16:13:56  time: 1.6326  data_time: 0.0033  memory: 17763  loss: 1.6048  loss_rpn_cls: 0.1092  loss_rpn_bbox: 0.0719  loss_cls: 0.5203  acc: 89.9414  loss_bbox: 0.3438  loss_mask: 0.5597
2025/12/11 08:55:54 - mmengine - INFO - Epoch(train)  [1][ 600/7330]  base_lr: 6.0000e-05 lr: 6.0000e-05  eta: 1 day, 16:07:51  time: 1.6182  data_time: 0.0035  memory: 18801  loss: 1.5792  loss_rpn_cls: 0.1087  loss_rpn_bbox: 0.0697  loss_cls: 0.5159  acc: 86.7188  loss_bbox: 0.3505  loss_mask: 0.5344
2025/12/11 08:57:15 - mmengine - INFO - Epoch(train)  [1][ 650/7330]  base_lr: 6.5000e-05 lr: 6.5000e-05  eta: 1 day, 16:03:04  time: 1.6232  data_time: 0.0037  memory: 18214  loss: 1.5466  loss_rpn_cls: 0.0979  loss_rpn_bbox: 0.0704  loss_cls: 0.5014  acc: 91.4551  loss_bbox: 0.3526  loss_mask: 0.5244
2025/12/11 08:58:37 - mmengine - INFO - Epoch(train)  [1][ 700/7330]  base_lr: 7.0000e-05 lr: 7.0000e-05  eta: 1 day, 15:59:48  time: 1.6332  data_time: 0.0038  memory: 18554  loss: 1.4854  loss_rpn_cls: 0.0935  loss_rpn_bbox: 0.0655  loss_cls: 0.4806  acc: 90.0391  loss_bbox: 0.3601  loss_mask: 0.4857
2025/12/11 08:59:59 - mmengine - INFO - Epoch(train)  [1][ 750/7330]  base_lr: 7.5000e-05 lr: 7.5000e-05  eta: 1 day, 15:58:22  time: 1.6495  data_time: 0.0038  memory: 17931  loss: 1.5399  loss_rpn_cls: 0.0956  loss_rpn_bbox: 0.0756  loss_cls: 0.4941  acc: 90.9668  loss_bbox: 0.3768  loss_mask: 0.4977
2025/12/11 09:01:21 - mmengine - INFO - Epoch(train)  [1][ 800/7330]  base_lr: 8.0000e-05 lr: 8.0000e-05  eta: 1 day, 15:55:38  time: 1.6352  data_time: 0.0037  memory: 18075  loss: 1.4580  loss_rpn_cls: 0.0867  loss_rpn_bbox: 0.0691  loss_cls: 0.4597  acc: 92.5537  loss_bbox: 0.3750  loss_mask: 0.4675
2025/12/11 09:02:43 - mmengine - INFO - Epoch(train)  [1][ 850/7330]  base_lr: 8.5000e-05 lr: 8.5000e-05  eta: 1 day, 15:53:11  time: 1.6366  data_time: 0.0037  memory: 18387  loss: 1.4240  loss_rpn_cls: 0.0819  loss_rpn_bbox: 0.0637  loss_cls: 0.4490  acc: 92.2363  loss_bbox: 0.3679  loss_mask: 0.4615
2025/12/11 09:04:04 - mmengine - INFO - Epoch(train)  [1][ 900/7330]  base_lr: 9.0000e-05 lr: 9.0000e-05  eta: 1 day, 15:50:03  time: 1.6264  data_time: 0.0036  memory: 18012  loss: 1.3997  loss_rpn_cls: 0.0871  loss_rpn_bbox: 0.0633  loss_cls: 0.4368  acc: 92.1631  loss_bbox: 0.3697  loss_mask: 0.4428
2025/12/11 09:05:25 - mmengine - INFO - Epoch(train)  [1][ 950/7330]  base_lr: 9.5000e-05 lr: 9.5000e-05  eta: 1 day, 15:47:09  time: 1.6273  data_time: 0.0036  memory: 18107  loss: 1.4000  loss_rpn_cls: 0.0849  loss_rpn_bbox: 0.0662  loss_cls: 0.4315  acc: 89.9170  loss_bbox: 0.3778  loss_mask: 0.4396
2025/12/11 09:06:47 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_t_1x_coco_20251211_083835
2025/12/11 09:06:47 - mmengine - INFO - Epoch(train)  [1][1000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:44:14  time: 1.6247  data_time: 0.0037  memory: 18533  loss: 1.3571  loss_rpn_cls: 0.0819  loss_rpn_bbox: 0.0656  loss_cls: 0.4109  acc: 88.0127  loss_bbox: 0.3577  loss_mask: 0.4411
2025/12/11 09:08:09 - mmengine - INFO - Epoch(train)  [1][1050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:42:49  time: 1.6446  data_time: 0.0029  memory: 18631  loss: 1.4317  loss_rpn_cls: 0.0830  loss_rpn_bbox: 0.0672  loss_cls: 0.4476  acc: 90.1855  loss_bbox: 0.4028  loss_mask: 0.4311
2025/12/11 09:09:32 - mmengine - INFO - Epoch(train)  [1][1100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:42:11  time: 1.6563  data_time: 0.0028  memory: 18561  loss: 1.3098  loss_rpn_cls: 0.0808  loss_rpn_bbox: 0.0651  loss_cls: 0.3897  acc: 89.4531  loss_bbox: 0.3656  loss_mask: 0.4087
2025/12/11 09:10:54 - mmengine - INFO - Epoch(train)  [1][1150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:40:57  time: 1.6477  data_time: 0.0028  memory: 18716  loss: 1.3517  loss_rpn_cls: 0.0804  loss_rpn_bbox: 0.0653  loss_cls: 0.4121  acc: 89.9658  loss_bbox: 0.3781  loss_mask: 0.4158
2025/12/11 09:12:15 - mmengine - INFO - Epoch(train)  [1][1200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:38:21  time: 1.6252  data_time: 0.0029  memory: 18626  loss: 1.2683  loss_rpn_cls: 0.0769  loss_rpn_bbox: 0.0606  loss_cls: 0.3679  acc: 92.3340  loss_bbox: 0.3481  loss_mask: 0.4147
2025/12/11 09:13:38 - mmengine - INFO - Epoch(train)  [1][1250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:37:11  time: 1.6484  data_time: 0.0030  memory: 17954  loss: 1.2940  loss_rpn_cls: 0.0739  loss_rpn_bbox: 0.0643  loss_cls: 0.3829  acc: 92.5049  loss_bbox: 0.3621  loss_mask: 0.4108
2025/12/11 09:15:01 - mmengine - INFO - Epoch(train)  [1][1300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:36:29  time: 1.6569  data_time: 0.0029  memory: 17914  loss: 1.2861  loss_rpn_cls: 0.0764  loss_rpn_bbox: 0.0662  loss_cls: 0.3797  acc: 91.1621  loss_bbox: 0.3645  loss_mask: 0.3993
2025/12/11 09:16:25 - mmengine - INFO - Epoch(train)  [1][1350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:36:58  time: 1.6802  data_time: 0.0030  memory: 18142  loss: 1.2626  loss_rpn_cls: 0.0719  loss_rpn_bbox: 0.0608  loss_cls: 0.3711  acc: 88.3545  loss_bbox: 0.3620  loss_mask: 0.3969
2025/12/11 09:17:49 - mmengine - INFO - Epoch(train)  [1][1400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:37:51  time: 1.6905  data_time: 0.0029  memory: 19416  loss: 1.2100  loss_rpn_cls: 0.0690  loss_rpn_bbox: 0.0554  loss_cls: 0.3572  acc: 88.1348  loss_bbox: 0.3455  loss_mask: 0.3829
2025/12/11 09:19:13 - mmengine - INFO - Epoch(train)  [1][1450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:37:23  time: 1.6666  data_time: 0.0029  memory: 17619  loss: 1.1711  loss_rpn_cls: 0.0675  loss_rpn_bbox: 0.0550  loss_cls: 0.3432  acc: 90.5029  loss_bbox: 0.3273  loss_mask: 0.3781
2025/12/11 09:20:36 - mmengine - INFO - Epoch(train)  [1][1500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:36:49  time: 1.6654  data_time: 0.0029  memory: 18380  loss: 1.2488  loss_rpn_cls: 0.0736  loss_rpn_bbox: 0.0602  loss_cls: 0.3603  acc: 90.1367  loss_bbox: 0.3586  loss_mask: 0.3961
2025/12/11 09:21:59 - mmengine - INFO - Epoch(train)  [1][1550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:36:08  time: 1.6645  data_time: 0.0029  memory: 17652  loss: 1.2020  loss_rpn_cls: 0.0715  loss_rpn_bbox: 0.0619  loss_cls: 0.3435  acc: 90.6494  loss_bbox: 0.3408  loss_mask: 0.3843
2025/12/11 09:23:24 - mmengine - INFO - Epoch(train)  [1][1600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:37:10  time: 1.7033  data_time: 0.0030  memory: 18238  loss: 1.2563  loss_rpn_cls: 0.0729  loss_rpn_bbox: 0.0675  loss_cls: 0.3687  acc: 86.3281  loss_bbox: 0.3672  loss_mask: 0.3800
2025/12/11 09:24:48 - mmengine - INFO - Epoch(train)  [1][1650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:36:54  time: 1.6771  data_time: 0.0029  memory: 17572  loss: 1.1923  loss_rpn_cls: 0.0632  loss_rpn_bbox: 0.0559  loss_cls: 0.3482  acc: 89.8438  loss_bbox: 0.3521  loss_mask: 0.3729
2025/12/11 09:26:10 - mmengine - INFO - Epoch(train)  [1][1700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:34:56  time: 1.6384  data_time: 0.0029  memory: 17896  loss: 1.2053  loss_rpn_cls: 0.0656  loss_rpn_bbox: 0.0577  loss_cls: 0.3538  acc: 87.9395  loss_bbox: 0.3535  loss_mask: 0.3747
2025/12/11 09:27:32 - mmengine - INFO - Epoch(train)  [1][1750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:33:22  time: 1.6472  data_time: 0.0028  memory: 17878  loss: 1.2268  loss_rpn_cls: 0.0709  loss_rpn_bbox: 0.0651  loss_cls: 0.3638  acc: 90.2344  loss_bbox: 0.3575  loss_mask: 0.3696
2025/12/11 09:28:54 - mmengine - INFO - Epoch(train)  [1][1800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:31:28  time: 1.6386  data_time: 0.0029  memory: 17775  loss: 1.1875  loss_rpn_cls: 0.0745  loss_rpn_bbox: 0.0579  loss_cls: 0.3489  acc: 89.5264  loss_bbox: 0.3427  loss_mask: 0.3635
2025/12/11 09:30:17 - mmengine - INFO - Epoch(train)  [1][1850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:30:33  time: 1.6635  data_time: 0.0031  memory: 17901  loss: 1.1551  loss_rpn_cls: 0.0699  loss_rpn_bbox: 0.0589  loss_cls: 0.3387  acc: 90.7715  loss_bbox: 0.3287  loss_mask: 0.3589
2025/12/11 09:31:40 - mmengine - INFO - Epoch(train)  [1][1900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:29:15  time: 1.6539  data_time: 0.0030  memory: 17959  loss: 1.1639  loss_rpn_cls: 0.0633  loss_rpn_bbox: 0.0613  loss_cls: 0.3356  acc: 92.6514  loss_bbox: 0.3363  loss_mask: 0.3675
2025/12/11 09:33:03 - mmengine - INFO - Epoch(train)  [1][1950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:27:54  time: 1.6522  data_time: 0.0029  memory: 18423  loss: 1.1308  loss_rpn_cls: 0.0642  loss_rpn_bbox: 0.0607  loss_cls: 0.3294  acc: 88.0371  loss_bbox: 0.3188  loss_mask: 0.3577
2025/12/11 09:34:24 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_t_1x_coco_20251211_083835
2025/12/11 09:34:24 - mmengine - INFO - Epoch(train)  [1][2000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:25:49  time: 1.6325  data_time: 0.0028  memory: 18340  loss: 1.1812  loss_rpn_cls: 0.0668  loss_rpn_bbox: 0.0596  loss_cls: 0.3390  acc: 91.7236  loss_bbox: 0.3443  loss_mask: 0.3715
2025/12/11 09:35:46 - mmengine - INFO - Epoch(train)  [1][2050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:24:02  time: 1.6398  data_time: 0.0029  memory: 18551  loss: 1.1403  loss_rpn_cls: 0.0633  loss_rpn_bbox: 0.0559  loss_cls: 0.3338  acc: 86.4258  loss_bbox: 0.3411  loss_mask: 0.3462
2025/12/11 09:37:09 - mmengine - INFO - Epoch(train)  [1][2100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:23:02  time: 1.6621  data_time: 0.0031  memory: 17660  loss: 1.1847  loss_rpn_cls: 0.0711  loss_rpn_bbox: 0.0636  loss_cls: 0.3415  acc: 85.8154  loss_bbox: 0.3478  loss_mask: 0.3607
2025/12/11 09:38:31 - mmengine - INFO - Epoch(train)  [1][2150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:21:09  time: 1.6358  data_time: 0.0029  memory: 17926  loss: 1.0785  loss_rpn_cls: 0.0619  loss_rpn_bbox: 0.0540  loss_cls: 0.3099  acc: 92.4561  loss_bbox: 0.3153  loss_mask: 0.3375
2025/12/11 09:39:54 - mmengine - INFO - Epoch(train)  [1][2200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:19:54  time: 1.6551  data_time: 0.0029  memory: 18739  loss: 1.1551  loss_rpn_cls: 0.0664  loss_rpn_bbox: 0.0577  loss_cls: 0.3309  acc: 89.0381  loss_bbox: 0.3428  loss_mask: 0.3574
2025/12/11 09:41:16 - mmengine - INFO - Epoch(train)  [1][2250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:18:18  time: 1.6439  data_time: 0.0029  memory: 17750  loss: 1.1804  loss_rpn_cls: 0.0664  loss_rpn_bbox: 0.0606  loss_cls: 0.3391  acc: 86.5967  loss_bbox: 0.3473  loss_mask: 0.3669
2025/12/11 09:42:39 - mmengine - INFO - Epoch(train)  [1][2300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:16:56  time: 1.6512  data_time: 0.0029  memory: 17549  loss: 1.1816  loss_rpn_cls: 0.0674  loss_rpn_bbox: 0.0612  loss_cls: 0.3442  acc: 90.4297  loss_bbox: 0.3532  loss_mask: 0.3557
2025/12/11 09:44:00 - mmengine - INFO - Epoch(train)  [1][2350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:14:37  time: 1.6201  data_time: 0.0029  memory: 18684  loss: 1.1580  loss_rpn_cls: 0.0638  loss_rpn_bbox: 0.0600  loss_cls: 0.3363  acc: 92.1631  loss_bbox: 0.3418  loss_mask: 0.3561
2025/12/11 09:45:23 - mmengine - INFO - Epoch(train)  [1][2400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:13:57  time: 1.6736  data_time: 0.0029  memory: 18848  loss: 1.1915  loss_rpn_cls: 0.0737  loss_rpn_bbox: 0.0639  loss_cls: 0.3446  acc: 89.8438  loss_bbox: 0.3519  loss_mask: 0.3575
2025/12/11 09:46:45 - mmengine - INFO - Epoch(train)  [1][2450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:11:53  time: 1.6272  data_time: 0.0028  memory: 18072  loss: 1.1318  loss_rpn_cls: 0.0628  loss_rpn_bbox: 0.0560  loss_cls: 0.3240  acc: 88.7695  loss_bbox: 0.3317  loss_mask: 0.3573
2025/12/11 09:48:07 - mmengine - INFO - Epoch(train)  [1][2500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:10:20  time: 1.6439  data_time: 0.0028  memory: 18425  loss: 1.1252  loss_rpn_cls: 0.0664  loss_rpn_bbox: 0.0577  loss_cls: 0.3228  acc: 89.6484  loss_bbox: 0.3309  loss_mask: 0.3473
2025/12/11 09:49:29 - mmengine - INFO - Epoch(train)  [1][2550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:08:57  time: 1.6503  data_time: 0.0029  memory: 18576  loss: 1.1439  loss_rpn_cls: 0.0685  loss_rpn_bbox: 0.0595  loss_cls: 0.3199  acc: 90.4785  loss_bbox: 0.3408  loss_mask: 0.3553
2025/12/11 09:50:51 - mmengine - INFO - Epoch(train)  [1][2600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:07:16  time: 1.6388  data_time: 0.0028  memory: 18177  loss: 1.1417  loss_rpn_cls: 0.0660  loss_rpn_bbox: 0.0616  loss_cls: 0.3212  acc: 90.5029  loss_bbox: 0.3374  loss_mask: 0.3554
2025/12/11 09:52:13 - mmengine - INFO - Epoch(train)  [1][2650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:05:38  time: 1.6399  data_time: 0.0029  memory: 17885  loss: 1.1466  loss_rpn_cls: 0.0696  loss_rpn_bbox: 0.0650  loss_cls: 0.3252  acc: 91.2598  loss_bbox: 0.3389  loss_mask: 0.3478
2025/12/11 09:53:35 - mmengine - INFO - Epoch(train)  [1][2700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:03:38  time: 1.6264  data_time: 0.0029  memory: 18001  loss: 1.0888  loss_rpn_cls: 0.0588  loss_rpn_bbox: 0.0571  loss_cls: 0.3107  acc: 92.0166  loss_bbox: 0.3142  loss_mask: 0.3480
2025/12/11 09:54:57 - mmengine - INFO - Epoch(train)  [1][2750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:01:56  time: 1.6366  data_time: 0.0028  memory: 18392  loss: 1.1178  loss_rpn_cls: 0.0634  loss_rpn_bbox: 0.0556  loss_cls: 0.3193  acc: 88.9648  loss_bbox: 0.3305  loss_mask: 0.3490
2025/12/11 09:56:18 - mmengine - INFO - Epoch(train)  [1][2800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 15:00:11  time: 1.6344  data_time: 0.0029  memory: 17945  loss: 1.1138  loss_rpn_cls: 0.0623  loss_rpn_bbox: 0.0566  loss_cls: 0.3206  acc: 90.6250  loss_bbox: 0.3277  loss_mask: 0.3466
2025/12/11 09:57:41 - mmengine - INFO - Epoch(train)  [1][2850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:58:56  time: 1.6535  data_time: 0.0030  memory: 18349  loss: 1.1001  loss_rpn_cls: 0.0640  loss_rpn_bbox: 0.0568  loss_cls: 0.3092  acc: 87.8662  loss_bbox: 0.3272  loss_mask: 0.3428
2025/12/11 09:59:04 - mmengine - INFO - Epoch(train)  [1][2900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:57:50  time: 1.6603  data_time: 0.0028  memory: 18058  loss: 1.1085  loss_rpn_cls: 0.0652  loss_rpn_bbox: 0.0580  loss_cls: 0.3204  acc: 87.0117  loss_bbox: 0.3295  loss_mask: 0.3355
2025/12/11 10:00:26 - mmengine - INFO - Epoch(train)  [1][2950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:56:21  time: 1.6441  data_time: 0.0030  memory: 18388  loss: 1.1170  loss_rpn_cls: 0.0659  loss_rpn_bbox: 0.0617  loss_cls: 0.3150  acc: 92.0166  loss_bbox: 0.3231  loss_mask: 0.3514
2025/12/11 10:01:48 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_t_1x_coco_20251211_083835
2025/12/11 10:01:48 - mmengine - INFO - Epoch(train)  [1][3000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:54:34  time: 1.6317  data_time: 0.0029  memory: 18448  loss: 1.0599  loss_rpn_cls: 0.0586  loss_rpn_bbox: 0.0510  loss_cls: 0.3004  acc: 90.4785  loss_bbox: 0.3108  loss_mask: 0.3391
2025/12/11 10:03:10 - mmengine - INFO - Epoch(train)  [1][3050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:52:52  time: 1.6348  data_time: 0.0029  memory: 18091  loss: 1.0357  loss_rpn_cls: 0.0590  loss_rpn_bbox: 0.0527  loss_cls: 0.2903  acc: 89.6240  loss_bbox: 0.2961  loss_mask: 0.3376
2025/12/11 10:04:32 - mmengine - INFO - Epoch(train)  [1][3100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:51:38  time: 1.6548  data_time: 0.0030  memory: 17864  loss: 1.0943  loss_rpn_cls: 0.0573  loss_rpn_bbox: 0.0566  loss_cls: 0.3114  acc: 90.9180  loss_bbox: 0.3277  loss_mask: 0.3412
2025/12/11 10:05:54 - mmengine - INFO - Epoch(train)  [1][3150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:50:10  time: 1.6442  data_time: 0.0030  memory: 17935  loss: 1.0889  loss_rpn_cls: 0.0565  loss_rpn_bbox: 0.0549  loss_cls: 0.3083  acc: 91.0889  loss_bbox: 0.3249  loss_mask: 0.3444
2025/12/11 10:07:17 - mmengine - INFO - Epoch(train)  [1][3200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:48:37  time: 1.6406  data_time: 0.0030  memory: 18552  loss: 1.0594  loss_rpn_cls: 0.0574  loss_rpn_bbox: 0.0546  loss_cls: 0.2958  acc: 90.7471  loss_bbox: 0.3136  loss_mask: 0.3380
2025/12/11 10:08:40 - mmengine - INFO - Epoch(train)  [1][3250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:47:32  time: 1.6617  data_time: 0.0031  memory: 18397  loss: 1.0666  loss_rpn_cls: 0.0611  loss_rpn_bbox: 0.0569  loss_cls: 0.2974  acc: 93.3838  loss_bbox: 0.3146  loss_mask: 0.3366
2025/12/11 10:10:03 - mmengine - INFO - Epoch(train)  [1][3300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:46:31  time: 1.6652  data_time: 0.0032  memory: 18304  loss: 1.0773  loss_rpn_cls: 0.0617  loss_rpn_bbox: 0.0560  loss_cls: 0.3076  acc: 93.3105  loss_bbox: 0.3170  loss_mask: 0.3350
2025/12/11 10:11:25 - mmengine - INFO - Epoch(train)  [1][3350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:45:10  time: 1.6500  data_time: 0.0032  memory: 17855  loss: 1.0338  loss_rpn_cls: 0.0548  loss_rpn_bbox: 0.0517  loss_cls: 0.2890  acc: 94.2871  loss_bbox: 0.3100  loss_mask: 0.3283
2025/12/11 10:12:49 - mmengine - INFO - Epoch(train)  [1][3400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:44:06  time: 1.6641  data_time: 0.0032  memory: 18534  loss: 1.0432  loss_rpn_cls: 0.0563  loss_rpn_bbox: 0.0558  loss_cls: 0.2915  acc: 90.4297  loss_bbox: 0.3066  loss_mask: 0.3330
2025/12/11 10:14:11 - mmengine - INFO - Epoch(train)  [1][3450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:42:51  time: 1.6548  data_time: 0.0032  memory: 18526  loss: 1.0580  loss_rpn_cls: 0.0545  loss_rpn_bbox: 0.0550  loss_cls: 0.2969  acc: 91.0400  loss_bbox: 0.3148  loss_mask: 0.3369
2025/12/11 10:15:35 - mmengine - INFO - Epoch(train)  [1][3500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:41:47  time: 1.6646  data_time: 0.0033  memory: 19260  loss: 1.1225  loss_rpn_cls: 0.0653  loss_rpn_bbox: 0.0606  loss_cls: 0.3220  acc: 93.6279  loss_bbox: 0.3367  loss_mask: 0.3380
2025/12/11 10:16:59 - mmengine - INFO - Epoch(train)  [1][3550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:41:02  time: 1.6811  data_time: 0.0031  memory: 18621  loss: 1.0959  loss_rpn_cls: 0.0597  loss_rpn_bbox: 0.0533  loss_cls: 0.3133  acc: 89.0381  loss_bbox: 0.3383  loss_mask: 0.3313
2025/12/11 10:18:23 - mmengine - INFO - Epoch(train)  [1][3600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:40:23  time: 1.6866  data_time: 0.0033  memory: 19288  loss: 1.1341  loss_rpn_cls: 0.0626  loss_rpn_bbox: 0.0620  loss_cls: 0.3205  acc: 93.0176  loss_bbox: 0.3447  loss_mask: 0.3442
2025/12/11 10:19:48 - mmengine - INFO - Epoch(train)  [1][3650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:39:59  time: 1.7017  data_time: 0.0033  memory: 18769  loss: 1.1077  loss_rpn_cls: 0.0639  loss_rpn_bbox: 0.0595  loss_cls: 0.3240  acc: 89.7705  loss_bbox: 0.3304  loss_mask: 0.3301
2025/12/11 10:21:12 - mmengine - INFO - Epoch(train)  [1][3700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:39:08  time: 1.6787  data_time: 0.0033  memory: 18180  loss: 1.0047  loss_rpn_cls: 0.0486  loss_rpn_bbox: 0.0471  loss_cls: 0.2799  acc: 87.6953  loss_bbox: 0.3091  loss_mask: 0.3200
2025/12/11 10:22:36 - mmengine - INFO - Epoch(train)  [1][3750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:38:26  time: 1.6873  data_time: 0.0034  memory: 18462  loss: 1.0751  loss_rpn_cls: 0.0586  loss_rpn_bbox: 0.0550  loss_cls: 0.3058  acc: 93.3838  loss_bbox: 0.3255  loss_mask: 0.3300
2025/12/11 10:24:01 - mmengine - INFO - Epoch(train)  [1][3800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:37:47  time: 1.6909  data_time: 0.0035  memory: 18143  loss: 1.0848  loss_rpn_cls: 0.0623  loss_rpn_bbox: 0.0578  loss_cls: 0.3007  acc: 89.2822  loss_bbox: 0.3260  loss_mask: 0.3381
2025/12/11 10:25:25 - mmengine - INFO - Epoch(train)  [1][3850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:36:49  time: 1.6751  data_time: 0.0034  memory: 18838  loss: 1.0838  loss_rpn_cls: 0.0589  loss_rpn_bbox: 0.0549  loss_cls: 0.3032  acc: 93.8232  loss_bbox: 0.3301  loss_mask: 0.3368
2025/12/11 10:26:48 - mmengine - INFO - Epoch(train)  [1][3900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:35:41  time: 1.6663  data_time: 0.0034  memory: 18014  loss: 1.0890  loss_rpn_cls: 0.0578  loss_rpn_bbox: 0.0565  loss_cls: 0.3067  acc: 89.5264  loss_bbox: 0.3338  loss_mask: 0.3342
2025/12/11 10:28:11 - mmengine - INFO - Epoch(train)  [1][3950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:34:17  time: 1.6519  data_time: 0.0033  memory: 17947  loss: 1.0708  loss_rpn_cls: 0.0627  loss_rpn_bbox: 0.0550  loss_cls: 0.2984  acc: 88.8184  loss_bbox: 0.3249  loss_mask: 0.3298
2025/12/11 10:29:33 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_t_1x_coco_20251211_083835
2025/12/11 10:29:33 - mmengine - INFO - Epoch(train)  [1][4000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:32:50  time: 1.6487  data_time: 0.0033  memory: 17655  loss: 1.0336  loss_rpn_cls: 0.0582  loss_rpn_bbox: 0.0548  loss_cls: 0.2878  acc: 92.0166  loss_bbox: 0.3011  loss_mask: 0.3317
2025/12/11 10:30:57 - mmengine - INFO - Epoch(train)  [1][4050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:31:47  time: 1.6713  data_time: 0.0033  memory: 18360  loss: 1.0371  loss_rpn_cls: 0.0599  loss_rpn_bbox: 0.0571  loss_cls: 0.2847  acc: 91.8213  loss_bbox: 0.3094  loss_mask: 0.3261
2025/12/11 10:32:19 - mmengine - INFO - Epoch(train)  [1][4100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:30:12  time: 1.6415  data_time: 0.0032  memory: 17666  loss: 0.9741  loss_rpn_cls: 0.0481  loss_rpn_bbox: 0.0456  loss_cls: 0.2756  acc: 95.0195  loss_bbox: 0.2935  loss_mask: 0.3113
2025/12/11 10:33:42 - mmengine - INFO - Epoch(train)  [1][4150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:29:05  time: 1.6684  data_time: 0.0032  memory: 19298  loss: 1.0298  loss_rpn_cls: 0.0609  loss_rpn_bbox: 0.0571  loss_cls: 0.2835  acc: 91.1865  loss_bbox: 0.3042  loss_mask: 0.3241
2025/12/11 10:35:05 - mmengine - INFO - Epoch(train)  [1][4200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:27:54  time: 1.6645  data_time: 0.0033  memory: 18448  loss: 1.0746  loss_rpn_cls: 0.0570  loss_rpn_bbox: 0.0562  loss_cls: 0.3026  acc: 90.7959  loss_bbox: 0.3268  loss_mask: 0.3320
2025/12/11 10:36:29 - mmengine - INFO - Epoch(train)  [1][4250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:26:49  time: 1.6716  data_time: 0.0033  memory: 18389  loss: 1.0385  loss_rpn_cls: 0.0564  loss_rpn_bbox: 0.0554  loss_cls: 0.2886  acc: 93.2129  loss_bbox: 0.3120  loss_mask: 0.3261
2025/12/11 10:37:52 - mmengine - INFO - Epoch(train)  [1][4300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:25:39  time: 1.6662  data_time: 0.0035  memory: 18264  loss: 1.0716  loss_rpn_cls: 0.0625  loss_rpn_bbox: 0.0575  loss_cls: 0.3047  acc: 89.3066  loss_bbox: 0.3207  loss_mask: 0.3262
2025/12/11 10:39:16 - mmengine - INFO - Epoch(train)  [1][4350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:24:45  time: 1.6837  data_time: 0.0036  memory: 18179  loss: 1.0134  loss_rpn_cls: 0.0553  loss_rpn_bbox: 0.0495  loss_cls: 0.2783  acc: 95.1904  loss_bbox: 0.3121  loss_mask: 0.3181
2025/12/11 10:40:40 - mmengine - INFO - Epoch(train)  [1][4400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:23:35  time: 1.6674  data_time: 0.0032  memory: 18374  loss: 1.0871  loss_rpn_cls: 0.0587  loss_rpn_bbox: 0.0588  loss_cls: 0.3063  acc: 88.5742  loss_bbox: 0.3329  loss_mask: 0.3305
2025/12/11 10:42:02 - mmengine - INFO - Epoch(train)  [1][4450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:22:12  time: 1.6533  data_time: 0.0035  memory: 17685  loss: 1.0527  loss_rpn_cls: 0.0636  loss_rpn_bbox: 0.0555  loss_cls: 0.2949  acc: 93.8477  loss_bbox: 0.3142  loss_mask: 0.3245
2025/12/11 10:43:26 - mmengine - INFO - Epoch(train)  [1][4500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:21:02  time: 1.6681  data_time: 0.0033  memory: 18640  loss: 1.0538  loss_rpn_cls: 0.0582  loss_rpn_bbox: 0.0591  loss_cls: 0.2920  acc: 94.7510  loss_bbox: 0.3146  loss_mask: 0.3299
2025/12/11 10:44:50 - mmengine - INFO - Epoch(train)  [1][4550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:20:01  time: 1.6772  data_time: 0.0032  memory: 17805  loss: 1.0858  loss_rpn_cls: 0.0623  loss_rpn_bbox: 0.0552  loss_cls: 0.3065  acc: 89.6484  loss_bbox: 0.3297  loss_mask: 0.3321
2025/12/11 10:46:13 - mmengine - INFO - Epoch(train)  [1][4600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:18:49  time: 1.6665  data_time: 0.0031  memory: 18562  loss: 0.9968  loss_rpn_cls: 0.0557  loss_rpn_bbox: 0.0523  loss_cls: 0.2729  acc: 92.3096  loss_bbox: 0.3012  loss_mask: 0.3147
2025/12/11 10:47:36 - mmengine - INFO - Epoch(train)  [1][4650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:17:39  time: 1.6688  data_time: 0.0032  memory: 18085  loss: 1.0684  loss_rpn_cls: 0.0559  loss_rpn_bbox: 0.0567  loss_cls: 0.2968  acc: 85.9375  loss_bbox: 0.3279  loss_mask: 0.3311
2025/12/11 10:49:00 - mmengine - INFO - Epoch(train)  [1][4700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:16:38  time: 1.6797  data_time: 0.0031  memory: 18114  loss: 1.0929  loss_rpn_cls: 0.0585  loss_rpn_bbox: 0.0589  loss_cls: 0.3169  acc: 88.9404  loss_bbox: 0.3307  loss_mask: 0.3278
2025/12/11 10:50:23 - mmengine - INFO - Epoch(train)  [1][4750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:15:07  time: 1.6457  data_time: 0.0031  memory: 17756  loss: 1.0443  loss_rpn_cls: 0.0619  loss_rpn_bbox: 0.0577  loss_cls: 0.2853  acc: 86.7432  loss_bbox: 0.3079  loss_mask: 0.3314
2025/12/11 10:51:45 - mmengine - INFO - Epoch(train)  [1][4800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:13:34  time: 1.6427  data_time: 0.0031  memory: 18038  loss: 0.9927  loss_rpn_cls: 0.0533  loss_rpn_bbox: 0.0494  loss_cls: 0.2792  acc: 89.0869  loss_bbox: 0.3004  loss_mask: 0.3103
2025/12/11 10:53:08 - mmengine - INFO - Epoch(train)  [1][4850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:12:16  time: 1.6609  data_time: 0.0032  memory: 18307  loss: 1.0740  loss_rpn_cls: 0.0600  loss_rpn_bbox: 0.0593  loss_cls: 0.2978  acc: 90.0879  loss_bbox: 0.3348  loss_mask: 0.3221
2025/12/11 10:54:30 - mmengine - INFO - Epoch(train)  [1][4900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:10:41  time: 1.6398  data_time: 0.0031  memory: 18100  loss: 1.0281  loss_rpn_cls: 0.0546  loss_rpn_bbox: 0.0544  loss_cls: 0.2862  acc: 90.7715  loss_bbox: 0.3111  loss_mask: 0.3218
2025/12/11 10:55:53 - mmengine - INFO - Epoch(train)  [1][4950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:09:23  time: 1.6607  data_time: 0.0032  memory: 18906  loss: 1.0207  loss_rpn_cls: 0.0637  loss_rpn_bbox: 0.0529  loss_cls: 0.2837  acc: 87.7441  loss_bbox: 0.3078  loss_mask: 0.3126
2025/12/11 10:57:15 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_t_1x_coco_20251211_083835
2025/12/11 10:57:15 - mmengine - INFO - Epoch(train)  [1][5000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:07:46  time: 1.6383  data_time: 0.0032  memory: 17636  loss: 0.9642  loss_rpn_cls: 0.0511  loss_rpn_bbox: 0.0482  loss_cls: 0.2712  acc: 91.8457  loss_bbox: 0.2916  loss_mask: 0.3022
2025/12/11 10:58:38 - mmengine - INFO - Epoch(train)  [1][5050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:06:27  time: 1.6586  data_time: 0.0032  memory: 18036  loss: 1.0313  loss_rpn_cls: 0.0552  loss_rpn_bbox: 0.0529  loss_cls: 0.2980  acc: 88.5010  loss_bbox: 0.3083  loss_mask: 0.3168
2025/12/11 11:00:02 - mmengine - INFO - Epoch(train)  [1][5100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:05:24  time: 1.6791  data_time: 0.0032  memory: 17762  loss: 1.0314  loss_rpn_cls: 0.0521  loss_rpn_bbox: 0.0509  loss_cls: 0.2901  acc: 92.4561  loss_bbox: 0.3122  loss_mask: 0.3262
2025/12/11 11:01:26 - mmengine - INFO - Epoch(train)  [1][5150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:04:20  time: 1.6782  data_time: 0.0031  memory: 17876  loss: 1.0080  loss_rpn_cls: 0.0551  loss_rpn_bbox: 0.0490  loss_cls: 0.2852  acc: 94.2871  loss_bbox: 0.3024  loss_mask: 0.3163
2025/12/11 11:02:50 - mmengine - INFO - Epoch(train)  [1][5200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:03:24  time: 1.6889  data_time: 0.0032  memory: 18796  loss: 1.0451  loss_rpn_cls: 0.0537  loss_rpn_bbox: 0.0554  loss_cls: 0.2976  acc: 90.2344  loss_bbox: 0.3205  loss_mask: 0.3180
2025/12/11 11:04:14 - mmengine - INFO - Epoch(train)  [1][5250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:02:17  time: 1.6755  data_time: 0.0031  memory: 18602  loss: 1.0354  loss_rpn_cls: 0.0561  loss_rpn_bbox: 0.0553  loss_cls: 0.2895  acc: 94.4824  loss_bbox: 0.3204  loss_mask: 0.3142
2025/12/11 11:05:36 - mmengine - INFO - Epoch(train)  [1][5300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 14:00:38  time: 1.6351  data_time: 0.0031  memory: 17563  loss: 1.0214  loss_rpn_cls: 0.0579  loss_rpn_bbox: 0.0491  loss_cls: 0.2913  acc: 90.6982  loss_bbox: 0.3030  loss_mask: 0.3200
2025/12/11 11:06:57 - mmengine - INFO - Epoch(train)  [1][5350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:59:00  time: 1.6349  data_time: 0.0031  memory: 18560  loss: 1.0227  loss_rpn_cls: 0.0517  loss_rpn_bbox: 0.0515  loss_cls: 0.2846  acc: 92.8955  loss_bbox: 0.3116  loss_mask: 0.3233
2025/12/11 11:08:20 - mmengine - INFO - Epoch(train)  [1][5400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:57:36  time: 1.6535  data_time: 0.0031  memory: 17912  loss: 1.0458  loss_rpn_cls: 0.0602  loss_rpn_bbox: 0.0546  loss_cls: 0.2913  acc: 93.2129  loss_bbox: 0.3208  loss_mask: 0.3190
2025/12/11 11:09:44 - mmengine - INFO - Epoch(train)  [1][5450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:56:36  time: 1.6855  data_time: 0.0031  memory: 18531  loss: 0.9989  loss_rpn_cls: 0.0536  loss_rpn_bbox: 0.0541  loss_cls: 0.2773  acc: 90.4541  loss_bbox: 0.3067  loss_mask: 0.3072
2025/12/11 11:11:14 - mmengine - INFO - Epoch(train)  [1][5500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:56:53  time: 1.7892  data_time: 0.0036  memory: 18636  loss: 1.0293  loss_rpn_cls: 0.0553  loss_rpn_bbox: 0.0519  loss_cls: 0.2922  acc: 90.7471  loss_bbox: 0.3177  loss_mask: 0.3123
2025/12/11 11:12:42 - mmengine - INFO - Epoch(train)  [1][5550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:56:54  time: 1.7698  data_time: 0.0035  memory: 18613  loss: 0.9856  loss_rpn_cls: 0.0486  loss_rpn_bbox: 0.0473  loss_cls: 0.2686  acc: 96.5576  loss_bbox: 0.2994  loss_mask: 0.3218
2025/12/11 11:14:09 - mmengine - INFO - Epoch(train)  [1][5600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:56:30  time: 1.7375  data_time: 0.0037  memory: 17857  loss: 0.9642  loss_rpn_cls: 0.0521  loss_rpn_bbox: 0.0479  loss_cls: 0.2653  acc: 93.9453  loss_bbox: 0.2913  loss_mask: 0.3076
2025/12/11 11:15:36 - mmengine - INFO - Epoch(train)  [1][5650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:56:12  time: 1.7480  data_time: 0.0036  memory: 18017  loss: 1.0383  loss_rpn_cls: 0.0525  loss_rpn_bbox: 0.0514  loss_cls: 0.2941  acc: 91.0645  loss_bbox: 0.3206  loss_mask: 0.3198
2025/12/11 11:17:02 - mmengine - INFO - Epoch(train)  [1][5700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:55:29  time: 1.7141  data_time: 0.0036  memory: 18325  loss: 1.0035  loss_rpn_cls: 0.0517  loss_rpn_bbox: 0.0530  loss_cls: 0.2821  acc: 91.2354  loss_bbox: 0.3090  loss_mask: 0.3077
2025/12/11 11:18:28 - mmengine - INFO - Epoch(train)  [1][5750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:54:53  time: 1.7252  data_time: 0.0034  memory: 17995  loss: 1.0235  loss_rpn_cls: 0.0542  loss_rpn_bbox: 0.0528  loss_cls: 0.2897  acc: 94.0186  loss_bbox: 0.3095  loss_mask: 0.3172
2025/12/11 11:19:56 - mmengine - INFO - Epoch(train)  [1][5800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:54:34  time: 1.7514  data_time: 0.0037  memory: 18232  loss: 1.0541  loss_rpn_cls: 0.0570  loss_rpn_bbox: 0.0547  loss_cls: 0.2975  acc: 89.3311  loss_bbox: 0.3200  loss_mask: 0.3250
2025/12/11 11:21:24 - mmengine - INFO - Epoch(train)  [1][5850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:54:15  time: 1.7514  data_time: 0.0034  memory: 18372  loss: 0.9839  loss_rpn_cls: 0.0523  loss_rpn_bbox: 0.0505  loss_cls: 0.2660  acc: 91.7969  loss_bbox: 0.3014  loss_mask: 0.3137
2025/12/11 11:22:51 - mmengine - INFO - Epoch(train)  [1][5900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:53:46  time: 1.7400  data_time: 0.0037  memory: 18022  loss: 0.9613  loss_rpn_cls: 0.0508  loss_rpn_bbox: 0.0468  loss_cls: 0.2677  acc: 93.4570  loss_bbox: 0.2866  loss_mask: 0.3094
2025/12/11 11:24:19 - mmengine - INFO - Epoch(train)  [1][5950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:53:37  time: 1.7698  data_time: 0.0037  memory: 18178  loss: 1.0282  loss_rpn_cls: 0.0582  loss_rpn_bbox: 0.0545  loss_cls: 0.2843  acc: 87.0117  loss_bbox: 0.3124  loss_mask: 0.3189
2025/12/11 11:25:46 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_t_1x_coco_20251211_083835
2025/12/11 11:25:46 - mmengine - INFO - Epoch(train)  [1][6000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:53:06  time: 1.7407  data_time: 0.0036  memory: 17776  loss: 1.0058  loss_rpn_cls: 0.0557  loss_rpn_bbox: 0.0542  loss_cls: 0.2826  acc: 88.7695  loss_bbox: 0.3044  loss_mask: 0.3088
2025/12/11 11:27:15 - mmengine - INFO - Epoch(train)  [1][6050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:53:01  time: 1.7793  data_time: 0.0036  memory: 18571  loss: 1.0036  loss_rpn_cls: 0.0541  loss_rpn_bbox: 0.0528  loss_cls: 0.2807  acc: 93.9209  loss_bbox: 0.3030  loss_mask: 0.3130
2025/12/11 11:28:45 - mmengine - INFO - Epoch(train)  [1][6100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:53:06  time: 1.7959  data_time: 0.0036  memory: 18719  loss: 0.9713  loss_rpn_cls: 0.0478  loss_rpn_bbox: 0.0519  loss_cls: 0.2701  acc: 95.3613  loss_bbox: 0.2907  loss_mask: 0.3108
2025/12/11 11:30:13 - mmengine - INFO - Epoch(train)  [1][6150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:52:47  time: 1.7634  data_time: 0.0035  memory: 19335  loss: 0.9682  loss_rpn_cls: 0.0492  loss_rpn_bbox: 0.0468  loss_cls: 0.2799  acc: 94.2383  loss_bbox: 0.2889  loss_mask: 0.3034
2025/12/11 11:31:38 - mmengine - INFO - Epoch(train)  [1][6200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:51:43  time: 1.6965  data_time: 0.0035  memory: 18100  loss: 0.9515  loss_rpn_cls: 0.0508  loss_rpn_bbox: 0.0490  loss_cls: 0.2577  acc: 93.2129  loss_bbox: 0.2837  loss_mask: 0.3102
2025/12/11 11:33:08 - mmengine - INFO - Epoch(train)  [1][6250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:51:45  time: 1.7973  data_time: 0.0034  memory: 18452  loss: 0.9684  loss_rpn_cls: 0.0539  loss_rpn_bbox: 0.0481  loss_cls: 0.2743  acc: 92.6514  loss_bbox: 0.2878  loss_mask: 0.3043
2025/12/11 11:34:35 - mmengine - INFO - Epoch(train)  [1][6300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:51:11  time: 1.7449  data_time: 0.0035  memory: 18041  loss: 1.0135  loss_rpn_cls: 0.0532  loss_rpn_bbox: 0.0516  loss_cls: 0.2867  acc: 90.3564  loss_bbox: 0.3084  loss_mask: 0.3137
2025/12/11 11:36:02 - mmengine - INFO - Epoch(train)  [1][6350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:50:36  time: 1.7437  data_time: 0.0036  memory: 17788  loss: 1.0342  loss_rpn_cls: 0.0524  loss_rpn_bbox: 0.0538  loss_cls: 0.2884  acc: 91.5527  loss_bbox: 0.3180  loss_mask: 0.3216
2025/12/11 11:37:29 - mmengine - INFO - Epoch(train)  [1][6400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:49:58  time: 1.7401  data_time: 0.0036  memory: 18105  loss: 0.9990  loss_rpn_cls: 0.0510  loss_rpn_bbox: 0.0489  loss_cls: 0.2878  acc: 93.5059  loss_bbox: 0.3053  loss_mask: 0.3060
2025/12/11 11:38:56 - mmengine - INFO - Epoch(train)  [1][6450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:49:21  time: 1.7442  data_time: 0.0035  memory: 18040  loss: 0.9802  loss_rpn_cls: 0.0528  loss_rpn_bbox: 0.0503  loss_cls: 0.2715  acc: 92.9932  loss_bbox: 0.3005  loss_mask: 0.3052
2025/12/11 11:40:25 - mmengine - INFO - Epoch(train)  [1][6500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:48:58  time: 1.7672  data_time: 0.0035  memory: 18371  loss: 1.0020  loss_rpn_cls: 0.0527  loss_rpn_bbox: 0.0538  loss_cls: 0.2737  acc: 86.2549  loss_bbox: 0.3085  loss_mask: 0.3133
2025/12/11 11:41:52 - mmengine - INFO - Epoch(train)  [1][6550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:48:24  time: 1.7503  data_time: 0.0034  memory: 18375  loss: 1.0066  loss_rpn_cls: 0.0567  loss_rpn_bbox: 0.0524  loss_cls: 0.2809  acc: 91.6748  loss_bbox: 0.3062  loss_mask: 0.3105
2025/12/11 11:43:20 - mmengine - INFO - Epoch(train)  [1][6600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:47:53  time: 1.7569  data_time: 0.0032  memory: 18499  loss: 1.0008  loss_rpn_cls: 0.0516  loss_rpn_bbox: 0.0482  loss_cls: 0.2819  acc: 91.9922  loss_bbox: 0.3045  loss_mask: 0.3147
2025/12/11 11:44:46 - mmengine - INFO - Epoch(train)  [1][6650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:47:01  time: 1.7250  data_time: 0.0033  memory: 17781  loss: 0.9668  loss_rpn_cls: 0.0545  loss_rpn_bbox: 0.0491  loss_cls: 0.2634  acc: 92.6758  loss_bbox: 0.2957  loss_mask: 0.3041
2025/12/11 11:46:14 - mmengine - INFO - Epoch(train)  [1][6700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:46:20  time: 1.7424  data_time: 0.0033  memory: 19482  loss: 0.9551  loss_rpn_cls: 0.0510  loss_rpn_bbox: 0.0486  loss_cls: 0.2627  acc: 91.1133  loss_bbox: 0.2858  loss_mask: 0.3070
2025/12/11 11:47:42 - mmengine - INFO - Epoch(train)  [1][6750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:45:53  time: 1.7680  data_time: 0.0036  memory: 18183  loss: 1.0009  loss_rpn_cls: 0.0509  loss_rpn_bbox: 0.0535  loss_cls: 0.2795  acc: 89.4043  loss_bbox: 0.3088  loss_mask: 0.3082
2025/12/11 11:49:10 - mmengine - INFO - Epoch(train)  [1][6800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:45:23  time: 1.7648  data_time: 0.0039  memory: 18177  loss: 1.0350  loss_rpn_cls: 0.0552  loss_rpn_bbox: 0.0552  loss_cls: 0.2903  acc: 91.1621  loss_bbox: 0.3133  loss_mask: 0.3210
2025/12/11 11:50:38 - mmengine - INFO - Epoch(train)  [1][6850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:44:52  time: 1.7629  data_time: 0.0037  memory: 18254  loss: 1.0156  loss_rpn_cls: 0.0590  loss_rpn_bbox: 0.0537  loss_cls: 0.2803  acc: 93.2129  loss_bbox: 0.3102  loss_mask: 0.3123
2025/12/11 11:52:06 - mmengine - INFO - Epoch(train)  [1][6900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:44:10  time: 1.7477  data_time: 0.0035  memory: 18010  loss: 0.9879  loss_rpn_cls: 0.0504  loss_rpn_bbox: 0.0500  loss_cls: 0.2765  acc: 91.9434  loss_bbox: 0.2982  loss_mask: 0.3128
2025/12/11 11:53:33 - mmengine - INFO - Epoch(train)  [1][6950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:43:23  time: 1.7388  data_time: 0.0035  memory: 17852  loss: 1.0258  loss_rpn_cls: 0.0576  loss_rpn_bbox: 0.0540  loss_cls: 0.2841  acc: 91.8701  loss_bbox: 0.3154  loss_mask: 0.3147
2025/12/11 11:55:01 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_t_1x_coco_20251211_083835
2025/12/11 11:55:01 - mmengine - INFO - Epoch(train)  [1][7000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:42:50  time: 1.7643  data_time: 0.0034  memory: 17655  loss: 1.0075  loss_rpn_cls: 0.0527  loss_rpn_bbox: 0.0520  loss_cls: 0.2853  acc: 87.7441  loss_bbox: 0.3092  loss_mask: 0.3083
2025/12/11 11:56:29 - mmengine - INFO - Epoch(train)  [1][7050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:42:19  time: 1.7683  data_time: 0.0036  memory: 17714  loss: 1.0168  loss_rpn_cls: 0.0551  loss_rpn_bbox: 0.0551  loss_cls: 0.2883  acc: 92.0654  loss_bbox: 0.3123  loss_mask: 0.3061
2025/12/11 11:57:58 - mmengine - INFO - Epoch(train)  [1][7100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:41:46  time: 1.7678  data_time: 0.0035  memory: 18392  loss: 0.9817  loss_rpn_cls: 0.0510  loss_rpn_bbox: 0.0510  loss_cls: 0.2723  acc: 91.8701  loss_bbox: 0.3028  loss_mask: 0.3045
2025/12/11 11:59:24 - mmengine - INFO - Epoch(train)  [1][7150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:40:53  time: 1.7321  data_time: 0.0034  memory: 17587  loss: 0.9693  loss_rpn_cls: 0.0501  loss_rpn_bbox: 0.0460  loss_cls: 0.2671  acc: 88.1348  loss_bbox: 0.3031  loss_mask: 0.3029
2025/12/11 12:00:54 - mmengine - INFO - Epoch(train)  [1][7200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:40:29  time: 1.7862  data_time: 0.0035  memory: 18725  loss: 0.9875  loss_rpn_cls: 0.0538  loss_rpn_bbox: 0.0535  loss_cls: 0.2765  acc: 93.6035  loss_bbox: 0.2978  loss_mask: 0.3060
2025/12/11 12:02:22 - mmengine - INFO - Epoch(train)  [1][7250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:39:54  time: 1.7675  data_time: 0.0036  memory: 17668  loss: 1.0231  loss_rpn_cls: 0.0570  loss_rpn_bbox: 0.0551  loss_cls: 0.2850  acc: 93.1396  loss_bbox: 0.3132  loss_mask: 0.3129
2025/12/11 12:03:49 - mmengine - INFO - Epoch(train)  [1][7300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:38:59  time: 1.7316  data_time: 0.0036  memory: 17833  loss: 0.9949  loss_rpn_cls: 0.0550  loss_rpn_bbox: 0.0513  loss_cls: 0.2779  acc: 90.1855  loss_bbox: 0.2993  loss_mask: 0.3113
2025/12/11 12:04:40 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_t_1x_coco_20251211_083835
2025/12/11 12:04:40 - mmengine - INFO - Saving checkpoint at 1 epochs
2025/12/11 12:06:37 - mmengine - INFO - Epoch(val)  [1][ 50/313]    eta: 0:09:55  time: 2.2639  data_time: 0.0294  memory: 17862  
2025/12/11 12:08:26 - mmengine - INFO - Epoch(val)  [1][100/313]    eta: 0:07:53  time: 2.1787  data_time: 0.0011  memory: 4449  
2025/12/11 12:10:16 - mmengine - INFO - Epoch(val)  [1][150/313]    eta: 0:06:00  time: 2.1933  data_time: 0.0010  memory: 4277  
2025/12/11 12:12:05 - mmengine - INFO - Epoch(val)  [1][200/313]    eta: 0:04:08  time: 2.1777  data_time: 0.0011  memory: 4449  
2025/12/11 12:13:55 - mmengine - INFO - Epoch(val)  [1][250/313]    eta: 0:02:18  time: 2.1974  data_time: 0.0010  memory: 4449  
2025/12/11 12:15:45 - mmengine - INFO - Epoch(val)  [1][300/313]    eta: 0:00:28  time: 2.2157  data_time: 0.0011  memory: 4449  
2025/12/11 12:16:32 - mmengine - INFO - Evaluating bbox...
2025/12/11 12:17:40 - mmengine - INFO - bbox_mAP_copypaste: 0.288 0.502 0.293 0.172 0.312 0.380
2025/12/11 12:17:40 - mmengine - INFO - Evaluating segm...
2025/12/11 12:19:01 - mmengine - INFO - segm_mAP_copypaste: 0.275 0.476 0.284 0.121 0.300 0.414
2025/12/11 12:19:02 - mmengine - INFO - Epoch(val) [1][313/313]    coco/bbox_mAP: 0.2880  coco/bbox_mAP_50: 0.5020  coco/bbox_mAP_75: 0.2930  coco/bbox_mAP_s: 0.1720  coco/bbox_mAP_m: 0.3120  coco/bbox_mAP_l: 0.3800  coco/segm_mAP: 0.2750  coco/segm_mAP_50: 0.4760  coco/segm_mAP_75: 0.2840  coco/segm_mAP_s: 0.1210  coco/segm_mAP_m: 0.3000  coco/segm_mAP_l: 0.4140  data_time: 0.0056  time: 2.2005
2025/12/11 12:20:33 - mmengine - INFO - Epoch(train)  [2][  50/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:38:00  time: 1.8055  data_time: 0.0168  memory: 18901  loss: 0.9848  loss_rpn_cls: 0.0473  loss_rpn_bbox: 0.0524  loss_cls: 0.2792  acc: 93.4326  loss_bbox: 0.3010  loss_mask: 0.3049
2025/12/11 12:22:02 - mmengine - INFO - Epoch(train)  [2][ 100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:37:27  time: 1.7761  data_time: 0.0038  memory: 18341  loss: 1.0192  loss_rpn_cls: 0.0485  loss_rpn_bbox: 0.0585  loss_cls: 0.2820  acc: 91.8945  loss_bbox: 0.3233  loss_mask: 0.3070
2025/12/11 12:23:29 - mmengine - INFO - Epoch(train)  [2][ 150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:36:42  time: 1.7542  data_time: 0.0037  memory: 18369  loss: 0.9307  loss_rpn_cls: 0.0450  loss_rpn_bbox: 0.0457  loss_cls: 0.2532  acc: 92.4316  loss_bbox: 0.2849  loss_mask: 0.3019
2025/12/11 12:24:57 - mmengine - INFO - Epoch(train)  [2][ 200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:35:55  time: 1.7515  data_time: 0.0038  memory: 18063  loss: 0.9805  loss_rpn_cls: 0.0494  loss_rpn_bbox: 0.0507  loss_cls: 0.2694  acc: 91.3086  loss_bbox: 0.3054  loss_mask: 0.3055
2025/12/11 12:26:24 - mmengine - INFO - Epoch(train)  [2][ 250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:35:03  time: 1.7445  data_time: 0.0037  memory: 18113  loss: 0.9838  loss_rpn_cls: 0.0533  loss_rpn_bbox: 0.0549  loss_cls: 0.2652  acc: 93.0908  loss_bbox: 0.3003  loss_mask: 0.3101
2025/12/11 12:27:52 - mmengine - INFO - Epoch(train)  [2][ 300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:34:17  time: 1.7558  data_time: 0.0037  memory: 17996  loss: 0.9784  loss_rpn_cls: 0.0480  loss_rpn_bbox: 0.0521  loss_cls: 0.2762  acc: 88.0371  loss_bbox: 0.3006  loss_mask: 0.3015
2025/12/11 12:29:20 - mmengine - INFO - Epoch(train)  [2][ 350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:33:35  time: 1.7644  data_time: 0.0040  memory: 17980  loss: 0.9567  loss_rpn_cls: 0.0488  loss_rpn_bbox: 0.0485  loss_cls: 0.2596  acc: 93.2861  loss_bbox: 0.2934  loss_mask: 0.3064
2025/12/11 12:30:50 - mmengine - INFO - Epoch(train)  [2][ 400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:33:06  time: 1.7912  data_time: 0.0037  memory: 18090  loss: 0.9636  loss_rpn_cls: 0.0521  loss_rpn_bbox: 0.0521  loss_cls: 0.2616  acc: 89.8193  loss_bbox: 0.2962  loss_mask: 0.3016
2025/12/11 12:32:18 - mmengine - INFO - Epoch(train)  [2][ 450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:32:20  time: 1.7584  data_time: 0.0038  memory: 18905  loss: 0.9554  loss_rpn_cls: 0.0452  loss_rpn_bbox: 0.0485  loss_cls: 0.2622  acc: 91.5283  loss_bbox: 0.2936  loss_mask: 0.3060
2025/12/11 12:33:43 - mmengine - INFO - Epoch(train)  [2][ 500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:31:11  time: 1.7153  data_time: 0.0035  memory: 18381  loss: 0.9206  loss_rpn_cls: 0.0436  loss_rpn_bbox: 0.0486  loss_cls: 0.2487  acc: 88.1348  loss_bbox: 0.2876  loss_mask: 0.2921
2025/12/11 12:35:11 - mmengine - INFO - Epoch(train)  [2][ 550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:30:21  time: 1.7537  data_time: 0.0036  memory: 18178  loss: 1.0149  loss_rpn_cls: 0.0518  loss_rpn_bbox: 0.0543  loss_cls: 0.2784  acc: 90.7959  loss_bbox: 0.3203  loss_mask: 0.3101
2025/12/11 12:36:36 - mmengine - INFO - Epoch(train)  [2][ 600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:29:06  time: 1.7048  data_time: 0.0036  memory: 18228  loss: 0.9645  loss_rpn_cls: 0.0512  loss_rpn_bbox: 0.0484  loss_cls: 0.2695  acc: 94.0674  loss_bbox: 0.2945  loss_mask: 0.3009
2025/12/11 12:38:03 - mmengine - INFO - Epoch(train)  [2][ 650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:28:10  time: 1.7418  data_time: 0.0035  memory: 18778  loss: 0.9271  loss_rpn_cls: 0.0492  loss_rpn_bbox: 0.0470  loss_cls: 0.2485  acc: 93.2861  loss_bbox: 0.2811  loss_mask: 0.3013
2025/12/11 12:38:38 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_t_1x_coco_20251211_083835
2025/12/11 12:39:31 - mmengine - INFO - Epoch(train)  [2][ 700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:27:18  time: 1.7510  data_time: 0.0036  memory: 18088  loss: 0.9836  loss_rpn_cls: 0.0496  loss_rpn_bbox: 0.0521  loss_cls: 0.2770  acc: 89.6484  loss_bbox: 0.3006  loss_mask: 0.3043
2025/12/11 12:41:00 - mmengine - INFO - Epoch(train)  [2][ 750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:26:38  time: 1.7767  data_time: 0.0036  memory: 18803  loss: 0.9893  loss_rpn_cls: 0.0500  loss_rpn_bbox: 0.0541  loss_cls: 0.2802  acc: 94.7754  loss_bbox: 0.3064  loss_mask: 0.2987
2025/12/11 12:42:27 - mmengine - INFO - Epoch(train)  [2][ 800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:25:39  time: 1.7399  data_time: 0.0035  memory: 19513  loss: 0.9457  loss_rpn_cls: 0.0497  loss_rpn_bbox: 0.0506  loss_cls: 0.2572  acc: 93.8232  loss_bbox: 0.2899  loss_mask: 0.2983
2025/12/11 12:43:53 - mmengine - INFO - Epoch(train)  [2][ 850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:24:36  time: 1.7323  data_time: 0.0035  memory: 17635  loss: 0.9551  loss_rpn_cls: 0.0461  loss_rpn_bbox: 0.0503  loss_cls: 0.2640  acc: 89.4287  loss_bbox: 0.2931  loss_mask: 0.3016
2025/12/11 12:45:21 - mmengine - INFO - Epoch(train)  [2][ 900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:23:45  time: 1.7558  data_time: 0.0036  memory: 17898  loss: 0.9564  loss_rpn_cls: 0.0477  loss_rpn_bbox: 0.0512  loss_cls: 0.2655  acc: 93.5791  loss_bbox: 0.2947  loss_mask: 0.2973
2025/12/11 12:46:48 - mmengine - INFO - Epoch(train)  [2][ 950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:22:43  time: 1.7362  data_time: 0.0036  memory: 18205  loss: 0.9817  loss_rpn_cls: 0.0461  loss_rpn_bbox: 0.0521  loss_cls: 0.2743  acc: 86.5479  loss_bbox: 0.3061  loss_mask: 0.3031
2025/12/11 12:48:14 - mmengine - INFO - Epoch(train)  [2][1000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:21:35  time: 1.7232  data_time: 0.0035  memory: 17980  loss: 0.9112  loss_rpn_cls: 0.0423  loss_rpn_bbox: 0.0501  loss_cls: 0.2457  acc: 90.8447  loss_bbox: 0.2811  loss_mask: 0.2920
2025/12/11 12:49:42 - mmengine - INFO - Epoch(train)  [2][1050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:20:43  time: 1.7573  data_time: 0.0037  memory: 18903  loss: 0.9378  loss_rpn_cls: 0.0489  loss_rpn_bbox: 0.0491  loss_cls: 0.2548  acc: 91.5283  loss_bbox: 0.2891  loss_mask: 0.2958
2025/12/11 12:51:11 - mmengine - INFO - Epoch(train)  [2][1100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:20:01  time: 1.7783  data_time: 0.0036  memory: 18651  loss: 0.9277  loss_rpn_cls: 0.0454  loss_rpn_bbox: 0.0481  loss_cls: 0.2538  acc: 90.6738  loss_bbox: 0.2885  loss_mask: 0.2919
2025/12/11 12:52:39 - mmengine - INFO - Epoch(train)  [2][1150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:19:10  time: 1.7611  data_time: 0.0036  memory: 18360  loss: 0.9761  loss_rpn_cls: 0.0518  loss_rpn_bbox: 0.0539  loss_cls: 0.2621  acc: 90.0391  loss_bbox: 0.3060  loss_mask: 0.3023
2025/12/11 12:54:07 - mmengine - INFO - Epoch(train)  [2][1200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:18:16  time: 1.7565  data_time: 0.0036  memory: 18131  loss: 1.0099  loss_rpn_cls: 0.0534  loss_rpn_bbox: 0.0510  loss_cls: 0.2817  acc: 93.6523  loss_bbox: 0.3074  loss_mask: 0.3165
2025/12/11 12:55:35 - mmengine - INFO - Epoch(train)  [2][1250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:17:26  time: 1.7667  data_time: 0.0038  memory: 18714  loss: 0.9202  loss_rpn_cls: 0.0456  loss_rpn_bbox: 0.0464  loss_cls: 0.2506  acc: 91.2598  loss_bbox: 0.2823  loss_mask: 0.2952
2025/12/11 12:57:04 - mmengine - INFO - Epoch(train)  [2][1300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:16:40  time: 1.7735  data_time: 0.0035  memory: 18489  loss: 0.9510  loss_rpn_cls: 0.0490  loss_rpn_bbox: 0.0498  loss_cls: 0.2633  acc: 89.9658  loss_bbox: 0.3017  loss_mask: 0.2872
2025/12/11 12:58:31 - mmengine - INFO - Epoch(train)  [2][1350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:15:35  time: 1.7344  data_time: 0.0036  memory: 18680  loss: 0.8779  loss_rpn_cls: 0.0431  loss_rpn_bbox: 0.0441  loss_cls: 0.2371  acc: 91.4795  loss_bbox: 0.2695  loss_mask: 0.2840
2025/12/11 13:00:00 - mmengine - INFO - Epoch(train)  [2][1400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:14:52  time: 1.7834  data_time: 0.0036  memory: 17793  loss: 0.9584  loss_rpn_cls: 0.0470  loss_rpn_bbox: 0.0468  loss_cls: 0.2606  acc: 93.3350  loss_bbox: 0.2961  loss_mask: 0.3079
2025/12/11 13:01:28 - mmengine - INFO - Epoch(train)  [2][1450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:14:03  time: 1.7728  data_time: 0.0036  memory: 18337  loss: 0.9614  loss_rpn_cls: 0.0498  loss_rpn_bbox: 0.0527  loss_cls: 0.2594  acc: 94.5312  loss_bbox: 0.2994  loss_mask: 0.3000
2025/12/11 13:02:56 - mmengine - INFO - Epoch(train)  [2][1500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:13:04  time: 1.7504  data_time: 0.0036  memory: 18157  loss: 0.9965  loss_rpn_cls: 0.0531  loss_rpn_bbox: 0.0519  loss_cls: 0.2812  acc: 91.7236  loss_bbox: 0.3004  loss_mask: 0.3099
2025/12/11 13:04:25 - mmengine - INFO - Epoch(train)  [2][1550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:12:19  time: 1.7817  data_time: 0.0037  memory: 18178  loss: 0.9387  loss_rpn_cls: 0.0450  loss_rpn_bbox: 0.0513  loss_cls: 0.2598  acc: 90.9180  loss_bbox: 0.2930  loss_mask: 0.2896
2025/12/11 13:05:55 - mmengine - INFO - Epoch(train)  [2][1600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:11:45  time: 1.8084  data_time: 0.0037  memory: 18924  loss: 0.9452  loss_rpn_cls: 0.0497  loss_rpn_bbox: 0.0507  loss_cls: 0.2591  acc: 90.9912  loss_bbox: 0.2944  loss_mask: 0.2912
2025/12/11 13:07:27 - mmengine - INFO - Epoch(train)  [2][1650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:11:18  time: 1.8253  data_time: 0.0102  memory: 19030  loss: 0.9380  loss_rpn_cls: 0.0480  loss_rpn_bbox: 0.0512  loss_cls: 0.2553  acc: 94.2383  loss_bbox: 0.2932  loss_mask: 0.2903
2025/12/11 13:08:03 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_t_1x_coco_20251211_083835
2025/12/11 13:08:56 - mmengine - INFO - Epoch(train)  [2][1700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:10:33  time: 1.7853  data_time: 0.0043  memory: 17968  loss: 0.9377  loss_rpn_cls: 0.0456  loss_rpn_bbox: 0.0493  loss_cls: 0.2566  acc: 87.1094  loss_bbox: 0.2911  loss_mask: 0.2952
2025/12/11 13:10:27 - mmengine - INFO - Epoch(train)  [2][1750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:10:01  time: 1.8175  data_time: 0.0044  memory: 18860  loss: 0.9212  loss_rpn_cls: 0.0479  loss_rpn_bbox: 0.0491  loss_cls: 0.2560  acc: 89.8682  loss_bbox: 0.2760  loss_mask: 0.2922
2025/12/11 13:11:58 - mmengine - INFO - Epoch(train)  [2][1800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:09:35  time: 1.8338  data_time: 0.0050  memory: 18229  loss: 0.9706  loss_rpn_cls: 0.0484  loss_rpn_bbox: 0.0486  loss_cls: 0.2720  acc: 88.8184  loss_bbox: 0.2982  loss_mask: 0.3035
2025/12/11 13:13:30 - mmengine - INFO - Epoch(train)  [2][1850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:09:07  time: 1.8294  data_time: 0.0045  memory: 18694  loss: 0.9463  loss_rpn_cls: 0.0488  loss_rpn_bbox: 0.0525  loss_cls: 0.2632  acc: 92.4072  loss_bbox: 0.2904  loss_mask: 0.2915
2025/12/11 13:14:58 - mmengine - INFO - Epoch(train)  [2][1900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:08:08  time: 1.7574  data_time: 0.0043  memory: 17600  loss: 0.9322  loss_rpn_cls: 0.0494  loss_rpn_bbox: 0.0483  loss_cls: 0.2520  acc: 89.8682  loss_bbox: 0.2871  loss_mask: 0.2954
2025/12/11 13:16:26 - mmengine - INFO - Epoch(train)  [2][1950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:07:14  time: 1.7722  data_time: 0.0044  memory: 18753  loss: 0.9827  loss_rpn_cls: 0.0523  loss_rpn_bbox: 0.0520  loss_cls: 0.2664  acc: 90.6738  loss_bbox: 0.3062  loss_mask: 0.3058
2025/12/11 13:17:56 - mmengine - INFO - Epoch(train)  [2][2000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:06:30  time: 1.7936  data_time: 0.0043  memory: 18711  loss: 0.9238  loss_rpn_cls: 0.0458  loss_rpn_bbox: 0.0477  loss_cls: 0.2536  acc: 92.4561  loss_bbox: 0.2810  loss_mask: 0.2958
2025/12/11 13:19:23 - mmengine - INFO - Epoch(train)  [2][2050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:05:25  time: 1.7475  data_time: 0.0043  memory: 17969  loss: 0.9360  loss_rpn_cls: 0.0468  loss_rpn_bbox: 0.0496  loss_cls: 0.2542  acc: 92.0898  loss_bbox: 0.2897  loss_mask: 0.2957
2025/12/11 13:20:50 - mmengine - INFO - Epoch(train)  [2][2100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:04:10  time: 1.7240  data_time: 0.0041  memory: 17965  loss: 0.9217  loss_rpn_cls: 0.0460  loss_rpn_bbox: 0.0495  loss_cls: 0.2462  acc: 92.6270  loss_bbox: 0.2814  loss_mask: 0.2984
2025/12/11 13:22:17 - mmengine - INFO - Epoch(train)  [2][2150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:03:09  time: 1.7553  data_time: 0.0042  memory: 17754  loss: 0.9708  loss_rpn_cls: 0.0532  loss_rpn_bbox: 0.0501  loss_cls: 0.2746  acc: 89.7705  loss_bbox: 0.3006  loss_mask: 0.2924
2025/12/11 13:23:46 - mmengine - INFO - Epoch(train)  [2][2200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:02:13  time: 1.7716  data_time: 0.0043  memory: 17981  loss: 0.9421  loss_rpn_cls: 0.0520  loss_rpn_bbox: 0.0498  loss_cls: 0.2584  acc: 92.7490  loss_bbox: 0.2887  loss_mask: 0.2933
2025/12/11 13:25:15 - mmengine - INFO - Epoch(train)  [2][2250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:01:18  time: 1.7736  data_time: 0.0042  memory: 17957  loss: 0.9842  loss_rpn_cls: 0.0530  loss_rpn_bbox: 0.0550  loss_cls: 0.2749  acc: 90.9912  loss_bbox: 0.3016  loss_mask: 0.2997
2025/12/11 13:26:43 - mmengine - INFO - Epoch(train)  [2][2300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 13:00:21  time: 1.7700  data_time: 0.0040  memory: 18413  loss: 0.9186  loss_rpn_cls: 0.0451  loss_rpn_bbox: 0.0459  loss_cls: 0.2492  acc: 87.3779  loss_bbox: 0.2858  loss_mask: 0.2925
2025/12/11 13:28:14 - mmengine - INFO - Epoch(train)  [2][2350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:59:39  time: 1.8065  data_time: 0.0045  memory: 18292  loss: 0.9719  loss_rpn_cls: 0.0525  loss_rpn_bbox: 0.0515  loss_cls: 0.2712  acc: 88.1592  loss_bbox: 0.2921  loss_mask: 0.3046
2025/12/11 13:29:42 - mmengine - INFO - Epoch(train)  [2][2400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:58:43  time: 1.7729  data_time: 0.0043  memory: 17850  loss: 0.9311  loss_rpn_cls: 0.0519  loss_rpn_bbox: 0.0511  loss_cls: 0.2588  acc: 92.0898  loss_bbox: 0.2802  loss_mask: 0.2891
2025/12/11 13:31:10 - mmengine - INFO - Epoch(train)  [2][2450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:57:40  time: 1.7562  data_time: 0.0042  memory: 18875  loss: 0.9451  loss_rpn_cls: 0.0484  loss_rpn_bbox: 0.0522  loss_cls: 0.2636  acc: 91.8457  loss_bbox: 0.2881  loss_mask: 0.2928
2025/12/11 13:32:39 - mmengine - INFO - Epoch(train)  [2][2500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:56:44  time: 1.7761  data_time: 0.0041  memory: 17953  loss: 0.9493  loss_rpn_cls: 0.0479  loss_rpn_bbox: 0.0494  loss_cls: 0.2613  acc: 93.1885  loss_bbox: 0.2893  loss_mask: 0.3013
2025/12/11 13:34:08 - mmengine - INFO - Epoch(train)  [2][2550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:55:49  time: 1.7792  data_time: 0.0042  memory: 18625  loss: 0.9460  loss_rpn_cls: 0.0492  loss_rpn_bbox: 0.0514  loss_cls: 0.2534  acc: 90.6250  loss_bbox: 0.2961  loss_mask: 0.2960
2025/12/11 13:35:35 - mmengine - INFO - Epoch(train)  [2][2600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:54:44  time: 1.7526  data_time: 0.0041  memory: 18123  loss: 0.9321  loss_rpn_cls: 0.0491  loss_rpn_bbox: 0.0501  loss_cls: 0.2561  acc: 93.1152  loss_bbox: 0.2859  loss_mask: 0.2909
2025/12/11 13:37:04 - mmengine - INFO - Epoch(train)  [2][2650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:53:46  time: 1.7737  data_time: 0.0041  memory: 18709  loss: 0.9465  loss_rpn_cls: 0.0532  loss_rpn_bbox: 0.0524  loss_cls: 0.2567  acc: 93.8232  loss_bbox: 0.2905  loss_mask: 0.2936
2025/12/11 13:37:39 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_t_1x_coco_20251211_083835
2025/12/11 13:38:34 - mmengine - INFO - Epoch(train)  [2][2700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:53:01  time: 1.8055  data_time: 0.0044  memory: 18785  loss: 0.9464  loss_rpn_cls: 0.0525  loss_rpn_bbox: 0.0536  loss_cls: 0.2541  acc: 95.2148  loss_bbox: 0.2860  loss_mask: 0.3002
2025/12/11 13:40:05 - mmengine - INFO - Epoch(train)  [2][2750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:52:14  time: 1.8042  data_time: 0.0046  memory: 18805  loss: 0.9251  loss_rpn_cls: 0.0498  loss_rpn_bbox: 0.0487  loss_cls: 0.2493  acc: 90.9424  loss_bbox: 0.2791  loss_mask: 0.2982
2025/12/11 13:41:33 - mmengine - INFO - Epoch(train)  [2][2800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:51:10  time: 1.7602  data_time: 0.0043  memory: 18628  loss: 0.9303  loss_rpn_cls: 0.0485  loss_rpn_bbox: 0.0485  loss_cls: 0.2577  acc: 88.1836  loss_bbox: 0.2793  loss_mask: 0.2964
2025/12/11 13:43:01 - mmengine - INFO - Epoch(train)  [2][2850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:50:10  time: 1.7683  data_time: 0.0044  memory: 17839  loss: 0.8810  loss_rpn_cls: 0.0424  loss_rpn_bbox: 0.0473  loss_cls: 0.2350  acc: 91.1865  loss_bbox: 0.2679  loss_mask: 0.2884
2025/12/11 13:44:30 - mmengine - INFO - Epoch(train)  [2][2900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:49:14  time: 1.7826  data_time: 0.0043  memory: 18141  loss: 0.9520  loss_rpn_cls: 0.0481  loss_rpn_bbox: 0.0478  loss_cls: 0.2614  acc: 93.0176  loss_bbox: 0.2947  loss_mask: 0.3000
2025/12/11 13:45:59 - mmengine - INFO - Epoch(train)  [2][2950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:48:15  time: 1.7746  data_time: 0.0041  memory: 18643  loss: 0.9272  loss_rpn_cls: 0.0464  loss_rpn_bbox: 0.0478  loss_cls: 0.2525  acc: 85.6445  loss_bbox: 0.2888  loss_mask: 0.2916
2025/12/11 13:47:29 - mmengine - INFO - Epoch(train)  [2][3000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:47:24  time: 1.7991  data_time: 0.0043  memory: 18212  loss: 0.9878  loss_rpn_cls: 0.0510  loss_rpn_bbox: 0.0504  loss_cls: 0.2803  acc: 91.2598  loss_bbox: 0.3108  loss_mask: 0.2952
2025/12/11 13:48:59 - mmengine - INFO - Epoch(train)  [2][3050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:46:34  time: 1.7985  data_time: 0.0042  memory: 18344  loss: 0.9648  loss_rpn_cls: 0.0519  loss_rpn_bbox: 0.0510  loss_cls: 0.2664  acc: 90.3076  loss_bbox: 0.2994  loss_mask: 0.2961
2025/12/11 13:50:29 - mmengine - INFO - Epoch(train)  [2][3100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:45:45  time: 1.8044  data_time: 0.0045  memory: 17881  loss: 0.9076  loss_rpn_cls: 0.0446  loss_rpn_bbox: 0.0460  loss_cls: 0.2431  acc: 88.7451  loss_bbox: 0.2827  loss_mask: 0.2912
2025/12/11 13:51:59 - mmengine - INFO - Epoch(train)  [2][3150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:44:53  time: 1.7991  data_time: 0.0042  memory: 18401  loss: 0.9755  loss_rpn_cls: 0.0506  loss_rpn_bbox: 0.0493  loss_cls: 0.2721  acc: 94.8486  loss_bbox: 0.3005  loss_mask: 0.3030
2025/12/11 13:53:26 - mmengine - INFO - Epoch(train)  [2][3200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:43:43  time: 1.7489  data_time: 0.0041  memory: 18535  loss: 0.9295  loss_rpn_cls: 0.0471  loss_rpn_bbox: 0.0493  loss_cls: 0.2527  acc: 94.6045  loss_bbox: 0.2824  loss_mask: 0.2980
2025/12/11 13:54:56 - mmengine - INFO - Epoch(train)  [2][3250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:42:50  time: 1.7956  data_time: 0.0043  memory: 18294  loss: 0.9067  loss_rpn_cls: 0.0435  loss_rpn_bbox: 0.0432  loss_cls: 0.2527  acc: 90.2100  loss_bbox: 0.2794  loss_mask: 0.2879
2025/12/11 13:56:25 - mmengine - INFO - Epoch(train)  [2][3300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:41:52  time: 1.7824  data_time: 0.0044  memory: 18061  loss: 0.9276  loss_rpn_cls: 0.0469  loss_rpn_bbox: 0.0516  loss_cls: 0.2527  acc: 94.2871  loss_bbox: 0.2853  loss_mask: 0.2911
2025/12/11 13:57:57 - mmengine - INFO - Epoch(train)  [2][3350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:41:10  time: 1.8280  data_time: 0.0045  memory: 17978  loss: 0.9299  loss_rpn_cls: 0.0495  loss_rpn_bbox: 0.0473  loss_cls: 0.2534  acc: 90.6982  loss_bbox: 0.2874  loss_mask: 0.2923
2025/12/11 13:59:25 - mmengine - INFO - Epoch(train)  [2][3400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:40:07  time: 1.7738  data_time: 0.0046  memory: 18242  loss: 0.9518  loss_rpn_cls: 0.0543  loss_rpn_bbox: 0.0504  loss_cls: 0.2564  acc: 92.6025  loss_bbox: 0.2950  loss_mask: 0.2958
2025/12/11 14:00:56 - mmengine - INFO - Epoch(train)  [2][3450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:39:16  time: 1.8038  data_time: 0.0043  memory: 18506  loss: 0.9549  loss_rpn_cls: 0.0508  loss_rpn_bbox: 0.0497  loss_cls: 0.2724  acc: 93.5303  loss_bbox: 0.2928  loss_mask: 0.2892
2025/12/11 14:02:24 - mmengine - INFO - Epoch(train)  [2][3500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:38:11  time: 1.7690  data_time: 0.0042  memory: 17850  loss: 0.9134  loss_rpn_cls: 0.0470  loss_rpn_bbox: 0.0489  loss_cls: 0.2487  acc: 90.2832  loss_bbox: 0.2826  loss_mask: 0.2863
2025/12/11 14:03:53 - mmengine - INFO - Epoch(train)  [2][3550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:37:09  time: 1.7763  data_time: 0.0044  memory: 17771  loss: 0.9067  loss_rpn_cls: 0.0397  loss_rpn_bbox: 0.0458  loss_cls: 0.2516  acc: 89.6973  loss_bbox: 0.2800  loss_mask: 0.2896
2025/12/11 14:05:21 - mmengine - INFO - Epoch(train)  [2][3600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:36:05  time: 1.7703  data_time: 0.0044  memory: 18747  loss: 0.9182  loss_rpn_cls: 0.0467  loss_rpn_bbox: 0.0467  loss_cls: 0.2593  acc: 92.5537  loss_bbox: 0.2884  loss_mask: 0.2771
2025/12/11 14:06:48 - mmengine - INFO - Epoch(train)  [2][3650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:34:49  time: 1.7374  data_time: 0.0042  memory: 17777  loss: 0.9044  loss_rpn_cls: 0.0395  loss_rpn_bbox: 0.0425  loss_cls: 0.2594  acc: 90.7471  loss_bbox: 0.2793  loss_mask: 0.2837
2025/12/11 14:07:24 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_t_1x_coco_20251211_083835
2025/12/11 14:08:17 - mmengine - INFO - Epoch(train)  [2][3700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:33:48  time: 1.7825  data_time: 0.0043  memory: 18729  loss: 0.9224  loss_rpn_cls: 0.0486  loss_rpn_bbox: 0.0479  loss_cls: 0.2561  acc: 92.0166  loss_bbox: 0.2808  loss_mask: 0.2889
2025/12/11 14:09:46 - mmengine - INFO - Epoch(train)  [2][3750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:32:45  time: 1.7760  data_time: 0.0044  memory: 17942  loss: 0.9438  loss_rpn_cls: 0.0438  loss_rpn_bbox: 0.0489  loss_cls: 0.2600  acc: 93.5791  loss_bbox: 0.2967  loss_mask: 0.2944
2025/12/11 14:11:15 - mmengine - INFO - Epoch(train)  [2][3800/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:31:44  time: 1.7816  data_time: 0.0046  memory: 18159  loss: 0.9439  loss_rpn_cls: 0.0472  loss_rpn_bbox: 0.0505  loss_cls: 0.2576  acc: 92.2607  loss_bbox: 0.2938  loss_mask: 0.2947
2025/12/11 14:12:44 - mmengine - INFO - Epoch(train)  [2][3850/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:30:39  time: 1.7702  data_time: 0.0045  memory: 19100  loss: 0.9183  loss_rpn_cls: 0.0457  loss_rpn_bbox: 0.0473  loss_cls: 0.2528  acc: 93.7988  loss_bbox: 0.2856  loss_mask: 0.2869
2025/12/11 14:14:12 - mmengine - INFO - Epoch(train)  [2][3900/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:29:29  time: 1.7586  data_time: 0.0043  memory: 18169  loss: 0.9229  loss_rpn_cls: 0.0442  loss_rpn_bbox: 0.0511  loss_cls: 0.2528  acc: 94.5068  loss_bbox: 0.2868  loss_mask: 0.2880
2025/12/11 14:15:40 - mmengine - INFO - Epoch(train)  [2][3950/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:28:24  time: 1.7718  data_time: 0.0043  memory: 18419  loss: 0.9157  loss_rpn_cls: 0.0457  loss_rpn_bbox: 0.0478  loss_cls: 0.2495  acc: 87.0361  loss_bbox: 0.2762  loss_mask: 0.2966
2025/12/11 14:17:11 - mmengine - INFO - Epoch(train)  [2][4000/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:27:35  time: 1.8199  data_time: 0.0049  memory: 18065  loss: 0.9664  loss_rpn_cls: 0.0524  loss_rpn_bbox: 0.0531  loss_cls: 0.2643  acc: 91.1865  loss_bbox: 0.3005  loss_mask: 0.2961
2025/12/11 14:18:39 - mmengine - INFO - Epoch(train)  [2][4050/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:26:24  time: 1.7568  data_time: 0.0046  memory: 17760  loss: 0.9753  loss_rpn_cls: 0.0552  loss_rpn_bbox: 0.0553  loss_cls: 0.2651  acc: 92.7246  loss_bbox: 0.2949  loss_mask: 0.3048
2025/12/11 14:20:07 - mmengine - INFO - Epoch(train)  [2][4100/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:25:12  time: 1.7549  data_time: 0.0043  memory: 18229  loss: 0.9697  loss_rpn_cls: 0.0501  loss_rpn_bbox: 0.0550  loss_cls: 0.2650  acc: 91.5039  loss_bbox: 0.2955  loss_mask: 0.3041
2025/12/11 14:21:36 - mmengine - INFO - Epoch(train)  [2][4150/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:24:10  time: 1.7835  data_time: 0.0042  memory: 18108  loss: 0.9185  loss_rpn_cls: 0.0444  loss_rpn_bbox: 0.0462  loss_cls: 0.2497  acc: 93.9453  loss_bbox: 0.2858  loss_mask: 0.2923
2025/12/11 14:23:03 - mmengine - INFO - Epoch(train)  [2][4200/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:22:52  time: 1.7384  data_time: 0.0045  memory: 19519  loss: 0.9155  loss_rpn_cls: 0.0460  loss_rpn_bbox: 0.0486  loss_cls: 0.2514  acc: 92.3584  loss_bbox: 0.2842  loss_mask: 0.2853
2025/12/11 14:24:33 - mmengine - INFO - Epoch(train)  [2][4250/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:21:52  time: 1.7913  data_time: 0.0043  memory: 19531  loss: 0.9418  loss_rpn_cls: 0.0521  loss_rpn_bbox: 0.0518  loss_cls: 0.2574  acc: 94.1406  loss_bbox: 0.2864  loss_mask: 0.2941
2025/12/11 14:25:59 - mmengine - INFO - Epoch(train)  [2][4300/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:20:29  time: 1.7205  data_time: 0.0041  memory: 17906  loss: 0.9139  loss_rpn_cls: 0.0492  loss_rpn_bbox: 0.0513  loss_cls: 0.2401  acc: 91.6016  loss_bbox: 0.2788  loss_mask: 0.2944
2025/12/11 14:27:26 - mmengine - INFO - Epoch(train)  [2][4350/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:19:12  time: 1.7420  data_time: 0.0044  memory: 18534  loss: 0.9096  loss_rpn_cls: 0.0423  loss_rpn_bbox: 0.0471  loss_cls: 0.2481  acc: 93.1641  loss_bbox: 0.2808  loss_mask: 0.2914
2025/12/11 14:28:58 - mmengine - INFO - Epoch(train)  [2][4400/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:18:30  time: 1.8469  data_time: 0.0046  memory: 18417  loss: 0.9372  loss_rpn_cls: 0.0481  loss_rpn_bbox: 0.0477  loss_cls: 0.2587  acc: 87.3535  loss_bbox: 0.2874  loss_mask: 0.2953
2025/12/11 14:30:27 - mmengine - INFO - Epoch(train)  [2][4450/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:17:27  time: 1.7848  data_time: 0.0045  memory: 18170  loss: 0.9196  loss_rpn_cls: 0.0465  loss_rpn_bbox: 0.0466  loss_cls: 0.2544  acc: 92.4316  loss_bbox: 0.2835  loss_mask: 0.2886
2025/12/11 14:31:57 - mmengine - INFO - Epoch(train)  [2][4500/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:16:26  time: 1.7939  data_time: 0.0047  memory: 19197  loss: 0.9491  loss_rpn_cls: 0.0518  loss_rpn_bbox: 0.0506  loss_cls: 0.2577  acc: 90.3809  loss_bbox: 0.2937  loss_mask: 0.2953
2025/12/11 14:33:27 - mmengine - INFO - Epoch(train)  [2][4550/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:15:29  time: 1.8034  data_time: 0.0049  memory: 18117  loss: 0.9592  loss_rpn_cls: 0.0451  loss_rpn_bbox: 0.0533  loss_cls: 0.2617  acc: 92.0898  loss_bbox: 0.2970  loss_mask: 0.3022
2025/12/11 14:34:57 - mmengine - INFO - Epoch(train)  [2][4600/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:14:28  time: 1.7950  data_time: 0.0046  memory: 18197  loss: 0.9205  loss_rpn_cls: 0.0439  loss_rpn_bbox: 0.0481  loss_cls: 0.2571  acc: 93.3105  loss_bbox: 0.2818  loss_mask: 0.2896
2025/12/11 14:36:25 - mmengine - INFO - Epoch(train)  [2][4650/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:13:18  time: 1.7642  data_time: 0.0043  memory: 18459  loss: 0.9380  loss_rpn_cls: 0.0483  loss_rpn_bbox: 0.0488  loss_cls: 0.2566  acc: 90.3809  loss_bbox: 0.2916  loss_mask: 0.2927
2025/12/11 14:37:01 - mmengine - INFO - Exp name: mask_rcnn_mamba_vision_t_1x_coco_20251211_083835
2025/12/11 14:37:54 - mmengine - INFO - Epoch(train)  [2][4700/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:12:14  time: 1.7855  data_time: 0.0044  memory: 18636  loss: 0.9339  loss_rpn_cls: 0.0514  loss_rpn_bbox: 0.0501  loss_cls: 0.2629  acc: 93.1885  loss_bbox: 0.2895  loss_mask: 0.2800
2025/12/11 14:39:24 - mmengine - INFO - Epoch(train)  [2][4750/7330]  base_lr: 1.0000e-04 lr: 1.0000e-04  eta: 1 day, 12:11:09  time: 1.7834  data_time: 0.0043  memory: 18173  loss: 0.9039  loss_rpn_cls: 0.0458  loss_rpn_bbox: 0.0434  loss_cls: 0.2528  acc: 93.4570  loss_bbox: 0.2769  loss_mask: 0.2850
                                                                                                                                                                                                                                                                                                                